{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c854b12c-3bf5-4378-bff8-7366ad5f1c80",
   "metadata": {},
   "source": [
    "# Simple RAG system\n",
    "\n",
    "In this notebook we will build a simple RAG system using a PDF document, OpenAI embeddings, and FAISS for efficient similarity search. The system will encode a PDF document, split it into chunks, create embeddings, and retrieve relevant sections based on a user query.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08716144-99ab-4b9a-b5f4-46a5e4ba3a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Access the API key\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6aceb8-a85e-4de2-9bda-3d4ab56f13f4",
   "metadata": {},
   "source": [
    "### Load PDF documents\n",
    "\n",
    "We will use `PyPDFLoader` to extract text from the PDF. It reads the PDF page by page and stores the extracted text in a list of document objects, where each document contains the content of a single page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4616de8-fcb5-46a8-9197-0e940349c2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the PDF file\n",
    "path = \"Understanding_Climate_Change.pdf\"\n",
    "\n",
    "loader = PyPDFLoader(path)\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2b2fc6-3a8a-4c27-a721-a60fb5c80405",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "\n",
    "##### Split the document into chunks\n",
    "We use the `RecursiveCharacterTextSplitter` to split the document into smaller chunks. This is ideal when working with large documents to make them manageable for embedding generation and for easier retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "667edbc7-87a1-48d1-8fc0-06d2e1d9d411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split documents into chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200, length_function=len)\n",
    "texts = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681774d3-35ac-40af-9141-5d774fe24a41",
   "metadata": {},
   "source": [
    "we are splitting the document into chunks of size 1000 characters with 200 characters of overlap between chunks.\n",
    "- `chunk_size` makes it more manageable for indexing and retrieval.\n",
    "- `chunk_overlap` ensures that the context is preserved when the text is split. This helps maintain the flow of information between chunks.\n",
    "- `length_function` tells the splitter to calculate the length of the chunks based on the number of characters, ensuring that the chunks are exactly the specified size.\n",
    "\n",
    "##### Replace tabs with spaces\n",
    "In many cases, PDFs may contain tab characters (`\\t`) that were used for indentation but aren't necessary for the final processed text. We will replace these with spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5cbabbc-9b28-474e-a0c2-6f11aedeb1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace tab characters with spaces in the text content\n",
    "for text in texts:\n",
    "    text.page_content = text.page_content.replace('\\t', ' ')  # Replace tabs with spaces"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52aea6e2-18bd-4341-82d3-4f828cde580f",
   "metadata": {},
   "source": [
    "### Generate embeddings using OpenAI\n",
    "Once the text is cleaned and processed, we can create embeddings for each of the chunks using OpenAI API. These embeddings represent the meaning of the text in a high-dimensional vector space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d7d404d-d389-4dc1-a93e-e5a46f4febe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializes the OpenAI embeddings model\n",
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fffab4c-583e-4feb-a7d4-e581738be036",
   "metadata": {},
   "source": [
    "We will also use FAISS to efficiently store and index the embeddings, which allows us to perform similarity search and query efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "034a17f5-069a-44ed-abc0-6adf48d8dc4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create vector store using FAISS\n",
    "vector_store = FAISS.from_documents(texts, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b5906c-f843-4349-b37b-eb22d1c58c28",
   "metadata": {},
   "source": [
    "Here, we create a FAISS vector store by:\n",
    "- Generating embeddings for each chunk of text.\n",
    "- Storing the embeddings in FAISS, which allows fast similarity search later.\n",
    "\n",
    "This function automatically creates a flat (brute-force) index by default.\n",
    "\n",
    "### Setup the retriever\n",
    "Now that we have created the embeddings and stored them in FAISS, we can query the vector store to retrieve relevant information based on user queries. The retriever will help us fetch the top N most relevant document chunks based on a given query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96d89bff-2d12-456e-a240-98857ac70a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a retriever that fetches top 2 relevant documents\n",
    "chunks_query_retriever = vector_store.as_retriever(search_kwargs={\"k\": 2})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc321a41-0df5-414b-b235-78f976321055",
   "metadata": {},
   "source": [
    "### Test querying the system\n",
    "Now, we will query the system with a question and retrieve the most relevant context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6abf4466-a50c-4ffc-acf2-c1341ee6cc2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Retrieved Context:\n",
      "Context 1:\n",
      "Chapter 2: Causes of Climate Change \n",
      "Greenhouse Gases \n",
      "The primary cause of recent climate change is the increase in greenhouse gases in the \n",
      "atmosphere. Greenhouse gases, such as carbon dioxide (CO2), methane (CH4), and nitrous \n",
      "oxide (N2O), trap heat from the sun, creating a \"greenhouse effect.\" This effect is essential \n",
      "for life on Earth, as it keeps the planet warm enough to support life. However, human \n",
      "activities have intensified this natural process, leading to a warmer climate. \n",
      "Fossil Fuels \n",
      "Burning fossil fuels for energy releases large amounts of CO2. This includes coal, oil, and \n",
      "natural gas used for electricity, heating, and transportation. The industrial revolution marked \n",
      "the beginning of a significant increase in fossil fuel consumption, which continues to rise \n",
      "today. \n",
      "Coal\n",
      "\n",
      "\n",
      "Context 2:\n",
      "Most of these climate changes are attributed to very small variations in Earth's orbit that \n",
      "change the amount of solar energy our planet receives. During the Holocene epoch, which \n",
      "began at the end of the last ice age, human societies flourished, but the industrial era has seen \n",
      "unprecedented changes. \n",
      "Modern Observations \n",
      "Modern scientific observations indicate a rapid increase in global temperatures, sea levels, \n",
      "and extreme weather events. The Intergovernmental Panel on Climate Change (IPCC) has \n",
      "documented these changes extensively. Ice core samples, tree rings, and ocean sediments \n",
      "provide a historical record that scientists use to understand past climate conditions and \n",
      "predict future trends. The evidence overwhelmingly shows that recent changes are primarily \n",
      "driven by human activities, particularly the emission of greenhouse gases. \n",
      "Chapter 2: Causes of Climate Change \n",
      "Greenhouse Gases \n",
      "The primary cause of recent climate change is the increase in greenhouse gases in the\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_query = \"What is the main cause of climate change?\"\n",
    "\n",
    "# Retrieve the most relevant documents for the query\n",
    "docs = chunks_query_retriever.invoke(test_query)\n",
    "\n",
    "# Extract content from the relevant documents\n",
    "context = [doc.page_content for doc in docs]\n",
    "\n",
    "# Display the relevant context\n",
    "print(\"Retrieved Context:\")\n",
    "for i, c in enumerate(context):\n",
    "    print(f\"Context {i + 1}:\")\n",
    "    print(c)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6b763c-d973-4c80-a2da-144c65158678",
   "metadata": {},
   "source": [
    "The printed results displayed concise and contextually relevant information that addressed the query, showcasing the effectiveness of the retrieval process."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
