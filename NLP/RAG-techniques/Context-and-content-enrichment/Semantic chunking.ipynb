{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5e12a47-88ce-4a01-b225-4893cb3f9cbc",
   "metadata": {},
   "source": [
    "# Semantic chunking for document processing\n",
    "\n",
    "This notebook demonstrates how to use semantic chunking for processing and retrieving information from a PDF document. Traditional methods for splitting text into chunks are typically based on fixed character or word counts, which may break the text in unnatural places, disrupting the flow of information. This can affect the quality of document retrieval, as the context is lost. Semantic chunking aims to solve this problem by splitting the text at more meaningful breakpoints, ensuring that each chunk retains its semantic coherence.\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16a9e6e3-2c6c-4df2-a58e-670f46dc3822",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "import pymupdf\n",
    "\n",
    "# Load environment variables from a .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Access the API key\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a3e877-81e9-4532-9757-97500a3c96df",
   "metadata": {},
   "source": [
    "## Document preprocessing\n",
    "Let's start by reading the content of a PDF file and splitting it into manageable chunks.\n",
    "\n",
    "### Read PDF to string\n",
    "Here, we read the PDF content and convert it into a string using the `pymupdf` library. This will allow us to process the text further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d16d76a8-9434-4ded-ab51-769d2487fc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the PDF\n",
    "path = \"Understanding_Climate_Change.pdf\"\n",
    "\n",
    "# Open the PDF document\n",
    "doc = pymupdf.open(path)\n",
    "content = \"\"\n",
    "\n",
    "# Iterate over each page and extract text\n",
    "for page_num in range(len(doc)):\n",
    "    # Get the current page\n",
    "    page = doc[page_num]\n",
    "    # Extract the text content from the current page and append it to the content string\n",
    "    content += page.get_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52e5a91-edc4-4d3e-9390-e11e64681a86",
   "metadata": {},
   "source": [
    "The PDF file is opened using `pymupdf.open()`, and we iterate over all pages to extract the text. The extracted text is then concatenated into one large string. This will allow us to process it further and split it into manageable chunks.\n",
    "\n",
    "## Perform semantic chunking\n",
    "Now that we have the full text of the document, we apply semantic chunking using LangChain's `SemanticChunker` with OpenAI embeddings. This will allow us to split the text at more meaningful points based on the semantic content, as opposed to arbitrary word or character breaks.\n",
    "\n",
    "The chunking process works by analyzing the semantic distance between consecutive sentences. If the difference between two consecutive sentences is large (in terms of their meaning), it marks that as a breakpoint where the document should be split into a new chunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1fa5201-33c1-4a3d-88e5-e75766bce030",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the semantic chunker\n",
    "text_splitter = SemanticChunker(OpenAIEmbeddings(), breakpoint_threshold_type='percentile', breakpoint_threshold_amount=90)\n",
    "\n",
    "# Create semantic chunks\n",
    "chunks = text_splitter.create_documents([content])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47889fa0-50ff-4175-9283-d0dd4b7fab63",
   "metadata": {},
   "source": [
    "We configure the `SemanticChunker` with a specific breakpoint type (percentile) and threshold amount (90th percentile). This means that the text will be split where the difference between consecutive sentences exceeds the 90th percentile of sentence differences. In other words, we will consider splitting the document whenever the difference in meaning between two sentences is larger than the 90th percentile of all sentence differences in the document.\n",
    "\n",
    "\r",
    "This means we want to split the text based on a specific percentile threshold. In other words, we will consider splitting the document whenever the difference in meaning between two sentences is larger than the 90th percentile of all sentence differences in the document. The 90th percentile means that we are looking for the sentences where the difference in meaning is larger than what 90% of other sentence differences are. This ensures that the split happens at significant changes in meaning, rather than at minor differences.\n",
    "oWe then call the `create_documents` method, passing the full content of the document to be chunked. The method returns the text split into smaller chunks, where each chunk contains semantically related content.\n",
    "\n",
    "## Vector store creation\n",
    "Now, let's create a vector store where we store the text chunks as vectors. We will convert the text chunks into numerical vector representations using OpenAI's embeddings, and then store them in a FAISS vector store.e.\r\n",
    "\r\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed152c0e-5bb0-469d-a792-f298276e1ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the OpenAI embeddings\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "# Create a FAISS vector store from the document chunks\n",
    "vectorstore = FAISS.from_documents(chunks, embeddings)\n",
    "\n",
    "# Create a retriever for the vector store to fetch relevant documents\n",
    "chunks_query_retriever = vectorstore.as_retriever(search_kwargs={\"k\": 2})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b035ddf7-6ebb-46fc-842e-1d9dcf19a2a7",
   "metadata": {},
   "source": [
    "- Here, we initialize the `OpenAIEmbeddings` class, which loads a model to convert the text of each chunk into a vector.\n",
    "- The `FAISS.from_documents` method takes the list of `chunks` (which contains the document text) and the initialized `embeddings` model to convert each chunk into a vector. These vectors are then stored in a FAISS vector store.\n",
    "- The `as_retriever()` method converts the FAISS vector store into a retriever object. This retriever is used to search for relevant documents based on the vectors stored in the FAISS index. The `search_kwargs={\"k\": 2}` parameter ensures that when we search for a query, only 2 documents (the two most relevant) is returned. We can adjust this number (`k`) to return more documents if needed.\n",
    "\n",
    "## Retrieve context based on query\n",
    "\r\n",
    "Now, we define the query that we will use to search for relevant context in the document. The retriever fetches the top `k=2` most relevant chunks based on their similarity to the querry.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6cf1e6a1-2f7d-4f37-9857-f4e52aca6154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the query to search for relevant context\n",
    "query = \"What is the main cause of climate change?\"\n",
    "\n",
    "# Retrieve the top 2 most relevant document chunks based on the query\n",
    "docs = chunks_query_retriever.invoke(query)\n",
    "\n",
    "# Extract the page content from the retrieved documents\n",
    "context = [doc.page_content for doc in docs]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2155ef4-7c4b-49e3-9489-f5629bb785e6",
   "metadata": {},
   "source": [
    "The retriever works by computing the similarity between the query and the document chunks stored in the FAISS vector store. The top `k` most similar chunks are returned as context for the query.\n",
    "\n",
    "### Display the retrieved context\n",
    "\r\n",
    "Now, we print the retrieved context for the querge.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b03238e9-6532-4155-858e-7348dbbb896e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context 1:\n",
      "The Intergovernmental Panel on Climate Change (IPCC) has \n",
      "documented these changes extensively. Ice core samples, tree rings, and ocean sediments \n",
      "provide a historical record that scientists use to understand past climate conditions and \n",
      "predict future trends. The evidence overwhelmingly shows that recent changes are primarily \n",
      "driven by human activities, particularly the emission of greenhouse gases. Chapter 2: Causes of Climate Change \n",
      "Greenhouse Gases \n",
      "The primary cause of recent climate change is the increase in greenhouse gases in the \n",
      "atmosphere. Greenhouse gases, such as carbon dioxide (CO2), methane (CH4), and nitrous \n",
      "oxide (N2O), trap heat from the sun, creating a \"greenhouse effect.\" This effect is essential \n",
      "for life on Earth, as it keeps the planet warm enough to support life. However, human \n",
      "activities have intensified this natural process, leading to a warmer climate. Fossil Fuels \n",
      "Burning fossil fuels for energy releases large amounts of CO2. This includes coal, oil, and \n",
      "natural gas used for electricity, heating, and transportation. The industrial revolution marked \n",
      "the beginning of a significant increase in fossil fuel consumption, which continues to rise \n",
      "today. Coal \n",
      "Coal is the most carbon-intensive fossil fuel, and its use for electricity generation is a major \n",
      "source of CO2 emissions. Despite a decline in some regions, coal remains a significant \n",
      "energy source globally. It is mined extensively in countries like China, India, and the United \n",
      "States, contributing significantly to their energy supplies and CO2 footprints. Oil \n",
      "Oil is used primarily for transportation fuels, such as gasoline and diesel. The combustion of \n",
      "oil products releases significant amounts of CO2 and other pollutants, contributing to climate \n",
      "change and air quality issues. The global oil industry is vast, involving extraction, refining, \n",
      "and distribution, with significant geopolitical and economic implications. Natural Gas \n",
      "Natural gas is the least carbon-intensive fossil fuel and is often seen as a \"bridge fuel\" to a \n",
      "lower-carbon future. However, its extraction and use still contribute to greenhouse gas \n",
      "emissions, particularly methane, which is a potent greenhouse gas.\n",
      "\n",
      "\n",
      "Context 2:\n",
      "Understanding Climate Change \n",
      "Chapter 1: Introduction to Climate Change \n",
      "Climate change refers to significant, long-term changes in the global climate. The term \n",
      "\"global climate\" encompasses the planet's overall weather patterns, including temperature, \n",
      "precipitation, and wind patterns, over an extended period. Over the past century, human \n",
      "activities, particularly the burning of fossil fuels and deforestation, have significantly \n",
      "contributed to climate change. Historical Context \n",
      "The Earth's climate has changed throughout history. Over the past 650,000 years, there have \n",
      "been seven cycles of glacial advance and retreat, with the abrupt end of the last ice age about \n",
      "11,700 years ago marking the beginning of the modern climate era and human civilization. Most of these climate changes are attributed to very small variations in Earth's orbit that \n",
      "change the amount of solar energy our planet receives. During the Holocene epoch, which \n",
      "began at the end of the last ice age, human societies flourished, but the industrial era has seen \n",
      "unprecedented changes. Modern Observations \n",
      "Modern scientific observations indicate a rapid increase in global temperatures, sea levels, \n",
      "and extreme weather events.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display the relevant context retrieved for the query\n",
    "for i, c in enumerate(context):\n",
    "    print(f\"Context {i + 1}:\")\n",
    "    print(c)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feec551e-7a8a-4d60-ac1c-38fd9fb5d56a",
   "metadata": {},
   "source": [
    "Overall, semantic chunking improves the quality of retrieved information and enhances the performance of downstream NLP tasks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
