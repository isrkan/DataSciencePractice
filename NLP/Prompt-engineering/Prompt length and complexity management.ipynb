{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RdqHNZ1MXUD0"
   },
   "source": [
    "# Prompt length and complexity management with language models\n",
    "\n",
    "In this notebook, we explore how to manage prompt length and complexity when working with LLMs. Two core challenges often arise in AI interactions: ensuring prompts are clear and concise, and handling long or complex text inputs that might exceed the model's token limit. By managing these factors efficiently, we can enhance the quality and relevance of model responses, and ensure that even lengthy or multifaceted queries can be processed effectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "XRanIpbpXZMG"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.docstore.document import Document\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Set up OpenAI API key\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TPU2H_xVXZAs"
   },
   "source": [
    "### Initialize the language model\n",
    "We instantiate a lightweight GPT model from OpenAI using LangChain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "9C2UvvSEXY0I"
   },
   "outputs": [],
   "source": [
    "# Initialize the language model\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini-2024-07-18\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_CirMedjXYoG"
   },
   "source": [
    "## Balancing detail and conciseness in prompts\n",
    "It is often a challenge to decide how much detail to include in a prompt. More detail can improve precision, but too much can overwhelm or limit the model. It is important to find the right balance between providing enough context to guide the model while avoiding excessive verbosity that could confuse or overburden the model.\n",
    "\n",
    "Let’s compare two approaches: one detailed, one concise—for the same topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "HXpwa346XYcB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detailed response:\n",
      "### Definition of Artificial Intelligence\n",
      "\n",
      "Artificial Intelligence (AI) refers to the simulation of human intelligence processes by machines, particularly computer systems. These processes include learning (the acquisition of information and rules for using it), reasoning (using rules to reach approximate or definite conclusions), and self-correction. AI can be categorized into two main types:\n",
      "\n",
      "1. **Narrow AI**: This is AI that is designed and trained for a specific task, such as voice recognition, image processing, or playing chess.\n",
      "2. **General AI**: This refers to a type of AI that possesses the ability to understand, learn, and apply intelligence across a wide range of tasks, similar to human cognitive abilities. General AI remains largely theoretical and has not yet been achieved.\n",
      "\n",
      "### Historical Context\n",
      "\n",
      "The concept of AI dates back to ancient history, but it formally began in the mid-20th century. Key milestones include:\n",
      "\n",
      "- **1950s**: Alan Turing proposed the Turing Test as a measure of machine intelligence.\n",
      "- **1956**: The term \"artificial intelligence\" was coined at the Dartmouth Conference, which is considered the birth of AI as a field of study.\n",
      "- **1960s-1970s**: Early AI research focused on symbolic methods and problem-solving. Programs like ELIZA and SHRDLU showcased early natural language processing.\n",
      "- **1980s**: The rise of expert systems, which were designed to mimic the decision-making abilities of human experts.\n",
      "- **1990s**: Advancements in machine learning and the introduction of neural networks.\n",
      "- **2000s-Present**: The resurgence of interest in AI, driven by increased computational power, the availability of vast amounts of data, and advancements in algorithms. Notable achievements include IBM's Watson winning \"Jeopardy!\" in 2011 and Google DeepMind's AlphaGo defeating a world champion Go player in 2016.\n",
      "\n",
      "### Key Components of AI\n",
      "\n",
      "1. **Machine Learning (ML)**: A subset of AI that enables systems to learn from data and improve over time without being explicitly programmed. ML includes supervised, unsupervised, and reinforcement learning.\n",
      "  \n",
      "2. **Deep Learning**: A subset of ML that employs neural networks with many layers (deep networks) to analyze various factors of data. It has been particularly effective in image and speech recognition.\n",
      "\n",
      "3. **Natural Language Processing (NLP)**: The ability of machines to understand and interpret human language, allowing for applications like chatbots and translation services.\n",
      "\n",
      "4. **Computer Vision**: The field of AI that allows computers to interpret and make decisions based on visual data from the world, enabling applications like facial recognition and autonomous vehicles.\n",
      "\n",
      "5. **Robotics**: The integration of AI with physical robots, allowing them to perform tasks ranging from manufacturing to personal assistance.\n",
      "\n",
      "### Practical Applications\n",
      "\n",
      "AI has a wide range of practical applications across various sectors:\n",
      "\n",
      "1. **Healthcare**: AI algorithms assist in diagnosing diseases, predicting patient outcomes, and personalizing treatment plans. For example, AI models can analyze medical imaging data to detect tumors.\n",
      "\n",
      "2. **Finance**: AI is used for fraud detection, algorithmic trading, and risk management. Robo-advisors provide investment advice based on user data and preferences.\n",
      "\n",
      "3. **Transportation**: Self-driving cars and traffic management systems leverage AI for navigation and safety. Companies like Tesla and Waymo are at the forefront of this technology.\n",
      "\n",
      "4. **Retail**: AI enhances customer experiences through personalized recommendations and inventory management. Amazon's recommendation engine is a well-known example.\n",
      "\n",
      "5. **Entertainment**: Streaming services like Netflix use AI algorithms to recommend shows and movies based on user preferences.\n",
      "\n",
      "### Controversies and Debates\n",
      "\n",
      "AI raises several ethical and societal concerns, including:\n",
      "\n",
      "1. **Job Displacement**: Automation powered by AI could lead to significant job losses across various industries, raising concerns about economic inequality and the future of work.\n",
      "\n",
      "2. **Bias and Fairness**: AI systems can perpetuate or even exacerbate existing biases in data, leading to unfair outcomes in areas like hiring, law enforcement, and lending. There is ongoing debate about how to mitigate these biases.\n",
      "\n",
      "3. **Privacy**: The use of AI in surveillance technologies raises questions about individual privacy rights and data security.\n",
      "\n",
      "4. **Autonomous Weapons**: The development of AI-driven military technologies poses ethical dilemmas regarding the use of force and accountability.\n",
      "\n",
      "5. **Existential Risk**: Some experts warn that the pursuit of General AI could pose existential risks if such systems surpass human intelligence without proper safeguards.\n",
      "\n",
      "### Future Developments and Trends\n",
      "\n",
      "The future of AI is likely to be influenced by several trends:\n",
      "\n",
      "1. **Explainability**: There is a growing demand for AI systems to be transparent and explainable, particularly in high-stakes areas like healthcare and criminal justice.\n",
      "\n",
      "2. **AI Governance**: Governments and organizations are increasingly focusing on creating regulations and ethical guidelines for AI development and deployment.\n",
      "\n",
      "3. **AI and Sustainability**: AI is being leveraged to address environmental challenges, from energy efficiency to conservation efforts.\n",
      "\n",
      "4. **Continued Integration**: AI will continue to be integrated into everyday technologies, enhancing user experiences and automating routine tasks.\n",
      "\n",
      "5. **Advancements in General AI**: Research will persist in the pursuit of General AI, though many experts remain cautious about its implications.\n",
      "\n",
      "In conclusion, artificial intelligence represents a transformative technology with the potential to reshape various aspects of society. While it offers numerous benefits, it also poses significant challenges that require careful consideration and responsible management.\n",
      "\n",
      "Concise response:\n",
      "Artificial intelligence (AI) refers to the simulation of human intelligence processes by machines, particularly computer systems. These processes include learning (the acquisition of information and rules for using it), reasoning (using rules to reach approximate or definite conclusions), and self-correction. AI can be categorized into narrow AI, which is designed for specific tasks, and general AI, which has the ability to understand, learn, and apply knowledge across a wide range of tasks.\n",
      "\n",
      "The main importance of AI lies in its ability to enhance efficiency and productivity across various sectors. It can automate repetitive tasks, analyze large datasets to uncover insights, improve decision-making, and enable innovations in fields such as healthcare, finance, manufacturing, and transportation. AI also has the potential to solve complex problems, drive economic growth, and improve the quality of life by providing personalized services and solutions.\n"
     ]
    }
   ],
   "source": [
    "# A detailed prompt template\n",
    "detailed_prompt = PromptTemplate(\n",
    "    input_variables=[\"topic\"],\n",
    "    template=\"\"\"Please provide a comprehensive explanation of {topic}. Include its definition,\n",
    "    historical context, key components, practical applications, and any relevant examples.\n",
    "    Also, discuss any controversies or debates surrounding the topic, and mention potential\n",
    "    future developments or trends.\"\"\"\n",
    ")\n",
    "\n",
    "# A concise prompt template\n",
    "concise_prompt = PromptTemplate(\n",
    "    input_variables=[\"topic\"],\n",
    "    template=\"Briefly explain {topic} and its main importance.\"\n",
    ")\n",
    "\n",
    "# Evaluate on the same topic\n",
    "topic = \"artificial intelligence\"\n",
    "\n",
    "# Generate responses from both prompts\n",
    "print(\"Detailed response:\")\n",
    "print(llm.invoke(detailed_prompt.format(topic=topic)).content)\n",
    "\n",
    "print(\"\\nConcise response:\")\n",
    "print(llm.invoke(concise_prompt.format(topic=topic)).content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kaHJVLOPXYPH"
   },
   "source": [
    "Here we construct two `PromptTemplate` objects with different levels of verbosity and query the same topic. The output will help us evaluate trade-offs in coverage and clarity.\n",
    "\n",
    "\n",
    "## Analysis of prompt balance\n",
    "Now that we have generated responses from the detailed and concise prompts, we can analyze the differences in the generated answers. We will compare them based on their information coverage, clarity, and potential use cases, and suggest strategies for finding the right balance between detail and conciseness in future prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "7tA0l5XoXYBj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Analysis of Differences\n",
      "\n",
      "#### 1. Information Coverage\n",
      "- **Detailed Response**: This response provides a comprehensive overview of AI, covering its definition, historical context, key components, practical applications, ethical controversies, future developments, and trends. It delves into the evolution of AI, detailing milestones and significant breakthroughs, making it an extensive resource for those seeking in-depth knowledge. The response also mentions various domains where AI is applied, ethical issues, and future considerations, providing a well-rounded perspective.\n",
      "  \n",
      "- **Concise Response**: The concise response offers a high-level summary of AI, defining it and mentioning its processes, categories (narrow and general AI), and overarching importance. It briefly highlights potential applications across various sectors but lacks the depth and detailed historical context found in the detailed response. While it touches on the transformative potential of AI, it does not address ethical concerns or future trends.\n",
      "\n",
      "#### 2. Clarity and Focus\n",
      "- **Detailed Response**: Although thorough, the detailed response may overwhelm some readers due to its complexity and depth. It is well-structured, with clear headings and subheadings that help guide the reader through various sections, but the extensive information requires more time and cognitive effort to digest.\n",
      "  \n",
      "- **Concise Response**: The concise response is clear and focused, delivering essential information without unnecessary elaboration. It effectively communicates the core ideas of AI and its importance in a straightforward manner, making it accessible to a broader audience, including those who may not have a technical background.\n",
      "\n",
      "#### 3. Potential Use Cases for Each Type of Response\n",
      "- **Detailed Response**: This response is best suited for academic or professional settings where in-depth analysis is required. It can be used in research papers, educational materials, or presentations aimed at audiences looking for comprehensive insights into AI's history, applications, and ethical implications.\n",
      "  \n",
      "- **Concise Response**: The concise response is ideal for introductory materials, blog posts, or executive summaries where quick understanding is crucial. It can be used in marketing materials, briefings, or situations where stakeholders need a swift overview of AI without delving into intricate details.\n",
      "\n",
      "### Strategies for Balancing Detail and Conciseness in Prompts\n",
      "1. **Define the Target Audience**: Understanding who will be reading the response can guide the level of detail needed. For technical audiences, more detail may be appropriate, while non-specialists may benefit from a concise overview.\n",
      "\n",
      "2. **Use Structured Outlines**: Create an outline that identifies key points to cover. This helps ensure that essential information is included without going off on tangents, allowing for a more streamlined approach.\n",
      "\n",
      "3. **Employ Summarization Techniques**: After drafting a detailed response, summarize key sections in bullet points or short paragraphs. This allows the core ideas to be communicated efficiently while still providing the option for deeper exploration.\n",
      "\n",
      "4. **Prioritize Information**: Determine which aspects of the topic are most relevant to the audience and focus on those. Omitting less critical information can help keep the response concise without sacrificing the main message.\n",
      "\n",
      "5. **Iterative Feedback**: Share drafts with others to gather feedback on clarity and detail. This can help identify areas where information can be condensed or expanded to better meet the needs of the audience.\n",
      "\n",
      "6. **Use Examples Judiciously**: Provide examples that illustrate key points without overwhelming the reader with too many specifics. A few well-chosen examples can effectively convey concepts without excessive elaboration.\n",
      "\n",
      "By applying these strategies, writers can create responses that are both informative and accessible, striking a balance between detail and conciseness based on the context and audience needs.\n"
     ]
    }
   ],
   "source": [
    "# Analyze the differences between detailed and concise responses\n",
    "analysis_prompt = PromptTemplate(\n",
    "    input_variables=[\"detailed_response\", \"concise_response\"],\n",
    "    template=\"\"\"Compare the following two responses on artificial intelligence:\n",
    "\n",
    "Detailed response:\n",
    "{detailed_response}\n",
    "\n",
    "Concise response:\n",
    "{concise_response}\n",
    "\n",
    "Analyze the differences in terms of:\n",
    "1. Information coverage\n",
    "2. Clarity and focus\n",
    "3. Potential use cases for each type of response\n",
    "\n",
    "Then, suggest strategies for balancing detail and conciseness in prompts.\"\"\"\n",
    ")\n",
    "\n",
    "# Generate both versions again\n",
    "detailed_response = llm.invoke(detailed_prompt.format(topic=topic)).content\n",
    "concise_response = llm.invoke(concise_prompt.format(topic=topic)).content\n",
    "\n",
    "# Run the comparative analysis\n",
    "analysis = llm.invoke(analysis_prompt.format(\n",
    "    detailed_response=detailed_response,\n",
    "    concise_response=concise_response\n",
    ")).content\n",
    "\n",
    "print(analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LvQz-F_tXXz4"
   },
   "source": [
    "The model acts as a meta-evaluator, helping us reflect on when and why we might prefer detailed or brief prompts, and how to strike the right balance in our application. We define an analysis prompt that takes both the detailed and concise responses as inputs and the model suggests strategies for balancing the two types of prompts.\n",
    "\n",
    "\n",
    "##Strategies for handling long contexts\n",
    "Handling long contexts, such as long documents or multiple-step tasks, can exceed the token limits of language models. To address this, we explore three strategies: chunking, summarization, and iterative processing. These techniques can help process large text inputs efficiently while retaining important details.\n",
    "\n",
    "### 1. Chunking\n",
    "When dealing with long documents, one effective approach is to break them down into smaller, manageable chunks. This ensures that each chunk is within the token limit and can be processed independently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "sIeA9PSrXXaI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks: 2\n",
      "First chunk: Artificial intelligence (AI) is a branch of computer science that aims to create intelligent machines that can simulate human cognitive processes.\n",
      "The field of AI has a rich history dating back to the...\n"
     ]
    }
   ],
   "source": [
    "# A long passage about artificial intelligence, its history, applications, and future prospects...\n",
    "long_text = \"\"\"\n",
    "Artificial intelligence (AI) is a branch of computer science that aims to create intelligent machines that can simulate human cognitive processes.\n",
    "The field of AI has a rich history dating back to the 1950s, with key milestones such as the development of the first neural networks and expert systems.\n",
    "AI encompasses a wide range of subfields, including machine learning, natural language processing, computer vision, and robotics.\n",
    "Practical applications of AI include speech recognition, image classification, autonomous vehicles, and medical diagnosis.\n",
    "AI has the potential to revolutionize many industries, from healthcare and finance to transportation and entertainment.\n",
    "However, there are ongoing debates and controversies surrounding AI, such as concerns about job displacement, bias in algorithms, and the ethical implications of autonomous systems.\n",
    "Looking ahead, the future of AI holds promise for advancements in areas like explainable AI, AI ethics, and human-AI collaboration.\n",
    "The intersection of AI with other technologies like blockchain, quantum computing, and biotechnology will likely shape the future of the field.\n",
    "But as AI continues to evolve, it is essential to consider the societal impact and ethical implications of these technologies.\n",
    "One of the key challenges for AI researchers and developers is to strike a balance between innovation and responsibility, ensuring that AI benefits society as\n",
    "a whole while minimizing potential risks.\n",
    "If managed effectively, AI has the potential to transform our world in ways we can only begin to imagine.\n",
    "Though the future of AI is uncertain, one thing is clear: the impact of artificial intelligence will be profound and far-reaching.\n",
    "\"\"\"\n",
    "\n",
    "# Initialize the text splitter with chunk size and overlap configuration\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,  # Maximum chunk size in characters\n",
    "    chunk_overlap=200,  # Overlap between chunks to maintain context\n",
    "    length_function=len  # Function to calculate the length of text\n",
    ")\n",
    "\n",
    "# Split the text into chunks\n",
    "chunks = text_splitter.split_text(long_text)\n",
    "\n",
    "print(f\"Number of chunks: {len(chunks)}\")\n",
    "print(f\"First chunk: {chunks[0][:200]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gxirh7NsXWr_"
   },
   "source": [
    "We use the `RecursiveCharacterTextSplitter` to divide a long text into chunks. This utility ensures that the chunks don’t exceed model input limits while maintaining coherence by using overlapping content.\n",
    "\n",
    "### 2. Summarization\n",
    "Summarization can be used to condense long texts while retaining key information. Let's use LangChain's summarization chain to demonstrate this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "uevHfBpvXSpJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary:\n",
      "Artificial intelligence (AI) is a field of computer science aimed at creating machines that replicate human cognition. Since its inception in the 1950s, AI has progressed through key developments like neural networks and machine learning, enabling applications in areas such as speech recognition and autonomous vehicles. While AI holds promise for transforming industries, it raises concerns about job displacement, algorithmic bias, and ethics. Future advancements are expected to emphasize explainability, ethics, and human-AI collaboration, necessitating careful management of its societal impacts to ensure responsible innovation.\n"
     ]
    }
   ],
   "source": [
    "# Convert text chunks to Document objects\n",
    "doc_chunks = [Document(page_content=chunk) for chunk in chunks]\n",
    "\n",
    "# Load the summarization chain\n",
    "chain = load_summarize_chain(llm, chain_type=\"map_reduce\")\n",
    "\n",
    "# Summarize the long text\n",
    "summary_result = chain.invoke(doc_chunks)\n",
    "\n",
    "print(\"Summary:\")\n",
    "print(summary_result['output_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eNmWy_goX3Yz"
   },
   "source": [
    "We apply a map-reduce summarization approach that processes chunks in parallel, then combines the outputs into a coherent summary. This is ideal for working with longer texts efficiently.\n",
    "\n",
    "### 3. Iterative processing\n",
    "For tasks that require multiple steps of analysis or processing, iterative processing allows us to handle each step sequentially. This method ensures that complex tasks are broken down into smaller, manageable parts. Let's demonstrate this with a multi-step analysis task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "FGikBuDvX3KN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Analysis:\n",
      "The text offers a comprehensive overview of artificial intelligence (AI), covering its definition, historical development, and various subfields. It highlights practical applications across multiple industries, discusses ongoing debates surrounding ethical considerations and societal impacts, and addresses the challenges faced by researchers and developers. Importantly, the text emphasizes the need for responsible innovation as AI continues to evolve and integrate with other technologies.\n",
      "\n",
      "**Conclusion**: Overall, the text underscores the transformative potential of AI while also acknowledging the complexities and ethical dilemmas associated with its advancement. It calls for a balanced approach that prioritizes societal benefits and ethical responsibility, reflecting a nuanced understanding of AI's future implications.\n"
     ]
    }
   ],
   "source": [
    "def iterative_analysis(text, steps):\n",
    "    \"\"\"\n",
    "    Perform iterative analysis on a given text.\n",
    "\n",
    "    Args:\n",
    "    text (str): The text to analyze.\n",
    "    steps (list): List of analysis steps to perform.\n",
    "\n",
    "    Returns:\n",
    "    str: The final analysis result.\n",
    "    \"\"\"\n",
    "    result = text\n",
    "    for step in steps:\n",
    "        prompt = PromptTemplate(\n",
    "            input_variables=[\"text\"],\n",
    "            template=f\"Analyze the following text. {step}\\n\\nText: {{text}}\\n\\nAnalysis:\"\n",
    "        )\n",
    "        result = llm.invoke(prompt.format(text=result)).content\n",
    "    return result\n",
    "\n",
    "# Define the analysis steps\n",
    "analysis_steps = [\n",
    "    \"Identify the main topics discussed.\",\n",
    "    \"Summarize the key points for each topic.\",\n",
    "    \"Provide a brief conclusion based on the analysis.\"\n",
    "]\n",
    "\n",
    "# Perform the iterative analysis\n",
    "final_analysis = iterative_analysis(long_text, analysis_steps)\n",
    "print(\"Final Analysis:\")\n",
    "print(final_analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5zRUE4JcX23u"
   },
   "source": [
    "We define a function iterative_analysis that processes the text through multiple steps, such as identifying topics, summarizing key points, and providing a conclusion. The function applies each step sequentially, updating the text after each analysis.\n",
    "\n",
    "Here we simulate a pipeline that mimics how a human might analyze complex content step by step. This technique is useful for document review, report writing, and case analysis.\n",
    "\n",
    "## Practical tips for nanaging prompt length and complexity\n",
    "Let's conclude with some practical tips for managing prompt length and complexity in real-world applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "bSjmmzCnX_xg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are five practical tips for developers working with large language models:\n",
      "\n",
      "1. **Chunk Input Data**: Break down large inputs into smaller, manageable chunks. This helps the model process information more efficiently and reduces the risk of exceeding token limits.\n",
      "\n",
      "2. **Use Clear and Specific Prompts**: Formulate prompts that are direct and unambiguous. Clearly define the task or question to minimize confusion and improve the relevance of the model's responses.\n",
      "\n",
      "3. **Iterative Refinement**: Start with a broad prompt and iteratively refine your queries based on the model's outputs. This approach helps hone in on the desired responses without overwhelming the model.\n",
      "\n",
      "4. **Leverage Contextual Cues**: Provide context where necessary by including relevant information or examples in the prompt. This can improve the model's understanding and output quality.\n",
      "\n",
      "5. **Monitor Token Usage**: Keep track of token counts in both inputs and outputs to avoid hitting limits. Use tools or libraries that help visualize and manage tokenization effectively.\n"
     ]
    }
   ],
   "source": [
    "# Generate practical tips for handling prompt length and complexity\n",
    "tips_prompt = \"\"\"\n",
    "Based on the examples and strategies we've explored for managing prompt length and complexity,\n",
    "provide a list of 5 practical tips for developers working with large language models.\n",
    "Each tip should be concise and actionable.\n",
    "\"\"\"\n",
    "\n",
    "# Generate the tips\n",
    "tips = llm.invoke(tips_prompt).content\n",
    "print(tips)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ltz4_9EYAZn"
   },
   "source": [
    "Here, we use a prompt to ask the model for five practical tips on managing prompt length and complexity. This gives us a distilled list of best practices that we can apply in production scenarios or prompt design workflows."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
