{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nrW23HoqtWlS"
   },
   "source": [
    "# Evaluating prompt effectiveness\n",
    "\n",
    "Evaluating how well a prompt performs is crucial for any application that uses language models. The quality of the prompt directly affects the model's output in terms of relevance, consistency, specificity, and clarity. In this notebook, we aim to build a toolkit that allows us to evaluate prompts using both manual and automated methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "zoDgYde4tQLf"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Set up OpenAI API key\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HBBiY1anLPMZ"
   },
   "source": [
    "### Initialize the language model\n",
    "We instantiate a lightweight GPT model from OpenAI using LangChain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "CHwXGxEKLPAC"
   },
   "outputs": [],
   "source": [
    "# Initialize the language model\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini-2024-07-18\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L5EmGe4jtc6D"
   },
   "source": [
    "### Semantic similarity calculation\n",
    "\n",
    "One of the core tools in our evaluation is the ability to compare how semantically similar two responses are. We will use cosine similarity over embeddings for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "HpteuSKqtcf3"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05c70e6f8476462681298d903259383f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       ".gitattributes:   0%|          | 0.00/1.23k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "626fa27cbb484733bfcbd15b88190403",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05e7517599594d36bc546943da8f3c20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21e1bb1ed4c141ccb611d2cb9448e0dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e8d58c4d8264922bab43f81fdd93a07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fe89bbcb62f4ae0826f38c0ad2d0609",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data_config.json:   0%|          | 0.00/39.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9543c8c70c7c4a77a73afef579381505",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b15a560d0e94e0b92494595a04985cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.onnx:   0%|          | 0.00/90.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b753d557057c4db78507dbbddfd1395b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model_O1.onnx:   0%|          | 0.00/90.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0952b5abbf884501a6e1070b84133515",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model_O2.onnx:   0%|          | 0.00/90.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12bc8e7e29cc4e319f416b6c27a24d89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model_O3.onnx:   0%|          | 0.00/90.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5abf5a9f83cd4bfc9ae3e8c1af65debc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model_O4.onnx:   0%|          | 0.00/45.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10f869cffe024a2ea93ca1da6bc16b89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model_qint8_arm64.onnx:   0%|          | 0.00/23.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bae8093c11f483b8c9cb050db171fd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model_qint8_arm64.onnx:   0%|          | 0.00/23.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52cb145e299a4281aa42b27f9dd8e738",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model_qint8_arm64.onnx:   0%|          | 0.00/23.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "198085ca3a29435d8b588f407f605305",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model_quint8_avx2.onnx:   0%|          | 0.00/23.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb914fc726cc4c289faed77894a34da2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "openvino_model.bin:   0%|          | 0.00/90.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14172182be1b461eb8560e94de58d415",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "openvino_model.xml:   0%|          | 0.00/211k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41bc9fd7504841af885395b2f7100408",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "openvino_model_qint8_quantized.bin:   0%|          | 0.00/22.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b339dfcaec94ebaa1a09f4378673fbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "openvino_model_qint8_quantized.xml:   0%|          | 0.00/368k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6580bfc5b7b24238b12f7403ffa277c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e62e51a4b96745e29ae5b26ef8e435f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c64f321d60a4a8ab600a5ab9a30b3ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f4e90a8cd2341b09cc84239bfce2439",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6825aaea2bb54e5ab129ec7544582dfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4ff6038cbb64baa8138c1ebe7c61060",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train_script.py:   0%|          | 0.00/13.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "352c2c9f14914a39a69ccdf373dcb28e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b820ed748c694568a7a551788dd089b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize sentence transformer for semantic similarity\n",
    "sentence_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "def semantic_similarity(text1, text2):\n",
    "    \"\"\"Calculate semantic similarity between two texts using cosine similarity.\"\"\"\n",
    "    # Encode both texts into embeddings\n",
    "    embeddings = sentence_model.encode([text1, text2])\n",
    "    # Return cosine similarity between the two vectors\n",
    "    return cosine_similarity([embeddings[0]], [embeddings[1]])[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9l1_sLbBtcS-"
   },
   "source": [
    "This function encodes both input texts using the `sentence-transformers` model and returns a similarity score between 0 and 1 based on cosine distance. Higher values indicate closer semantic meaning.\n",
    "\n",
    "\n",
    "### Metrics for measuring prompt performance\n",
    "We will define three automated metrics to assess response quality:\n",
    "- Relevance: Measures semantic similarity to a reference/expected answer.\n",
    "- Consistency: Measures similarity across multiple responses to the same prompt.\n",
    "- Specificity: Measures how detailed or generic a response is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "-enfACdktcGl"
   },
   "outputs": [],
   "source": [
    "def relevance_score(response, expected_content):\n",
    "    \"\"\"Calculate relevance score based on semantic similarity to expected content.\"\"\"\n",
    "    return semantic_similarity(response, expected_content)\n",
    "\n",
    "def consistency_score(responses):\n",
    "    \"\"\"Calculate consistency score based on similarity between multiple responses.\"\"\"\n",
    "    if len(responses) < 2:\n",
    "        return 1.0  # Perfect consistency if there's only one response\n",
    "    similarities = []\n",
    "    for i in range(len(responses)):\n",
    "        for j in range(i+1, len(responses)):\n",
    "            similarities.append(semantic_similarity(responses[i], responses[j]))\n",
    "    return np.mean(similarities)\n",
    "\n",
    "def specificity_score(response):\n",
    "    \"\"\"Calculate specificity score based on response length and unique word count.\"\"\"\n",
    "    words = response.split()\n",
    "    unique_words = set(words)\n",
    "    return len(unique_words) / len(words) if words else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wjoZnSultb6u"
   },
   "source": [
    "These functions offer a quick, objective way to rate response quality. Specificity favors responses that are both long and rich in vocabulary, while relevance requires a reference answer to compare against.\n",
    "\n",
    "## Manual evaluation techniques\n",
    "Although automation helps scale evaluations, human feedback is still important for subjective qualities like clarity, tone, or factuality. The following function supports manual scoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "whS9xLYUtbuz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: Explain the concept of machine learning in simple terms.\n",
      "Response: Machine learning is a type of technology that allows computers to learn from data and improve their performance over time without being explicitly programmed. \n",
      "\n",
      "Here’s a simple way to think about it:\n",
      "\n",
      "1. **Learning from Examples**: Just like how a child learns to recognize animals by looking at pictures and hearing names, a machine learning model learns by being fed lots of examples. For instance, if you show it many pictures of cats and dogs, it learns to distinguish between the two.\n",
      "\n",
      "2. **Patterns and Predictions**: As it processes these examples, the machine finds patterns or features that help it tell the difference. Once it's learned enough, it can make predictions or decisions based on new data it hasn't seen before. For example, it can look at a new picture and say whether it’s a cat or a dog.\n",
      "\n",
      "3. **Improvement Over Time**: The more data the machine learns from, the better it gets at making accurate predictions. If it makes a mistake, it can adjust its understanding based on feedback, just like how a person learns from their errors.\n",
      "\n",
      "In summary, machine learning is about teaching computers to learn from data and improve their abilities to make decisions or predictions on their own.\n",
      "\n",
      "Evaluation Criteria:\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Score for Clarity (0-10):  5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clarity: 5.0/10\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Score for Accuracy (0-10):  5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 5.0/10\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Score for Simplicity (0-10):  5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simplicity: 5.0/10\n",
      "\n",
      "Additional Comments:\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter any additional comments:  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comments: \n"
     ]
    }
   ],
   "source": [
    "def manual_evaluation(prompt, response, criteria):\n",
    "    \"\"\"Simulate manual evaluation of a prompt-response pair.\"\"\"\n",
    "    print(f\"Prompt: {prompt}\")\n",
    "    print(f\"Response: {response}\")\n",
    "    print(\"\\nEvaluation Criteria:\")\n",
    "\n",
    "    # Iterate through each manual criterion\n",
    "    for criterion in criteria:\n",
    "        score = float(input(f\"Score for {criterion} (0-10): \"))\n",
    "        print(f\"{criterion}: {score}/10\")\n",
    "\n",
    "    print(\"\\nAdditional Comments:\")\n",
    "    comments = input(\"Enter any additional comments: \")\n",
    "    print(f\"Comments: {comments}\")\n",
    "\n",
    "# Example usage\n",
    "prompt = \"Explain the concept of machine learning in simple terms.\"\n",
    "response = llm.invoke(prompt).content\n",
    "criteria = [\"Clarity\", \"Accuracy\", \"Simplicity\"]\n",
    "manual_evaluation(prompt, response, criteria)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FUl4pJGetbjG"
   },
   "source": [
    "The function `manual_evaluation` prints a prompt-response pair and prompts the evaluator for numerical scores. It also allows capturing free-form feedback. This would typically be used in a controlled annotation environment. After running this, we will manually rate how well the model explains the topic based on clarity, correctness, and ease of understanding.\n",
    "\n",
    "## Automated evaluation techniques\n",
    "Next, let’s combine our automated metrics into a single evaluation function that prints and returns the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "BO4MPyvQtbXa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: What are the three main types of machine learning?\n",
      "Response: The three main types of machine learning are:\n",
      "\n",
      "1. **Supervised Learning**: In supervised learning, the model is trained on a labeled dataset, which means that each training example is paired with an output label. The goal is to learn a mapping from inputs to outputs so that the model can predict the output for new, unseen data. Common applications include classification (e.g., spam detection) and regression (e.g., predicting house prices).\n",
      "\n",
      "2. **Unsupervised Learning**: In unsupervised learning, the model is trained on data without labeled outputs. The goal is to identify patterns or structures within the data. Common techniques include clustering (e.g., grouping similar customers) and dimensionality reduction (e.g., reducing the number of features while retaining important information).\n",
      "\n",
      "3. **Reinforcement Learning**: In reinforcement learning, an agent learns to make decisions by taking actions in an environment to maximize some notion of cumulative reward. The agent receives feedback in the form of rewards or penalties based on its actions and learns to optimize its strategy over time. This type of learning is commonly used in applications like game playing (e.g., AlphaGo) and robotics.\n",
      "\n",
      "These three types of machine learning cover a wide range of applications and methods in the field.\n",
      "\n",
      "Relevance Score: 0.73\n",
      "Specificity Score: 0.64\n",
      "Consistency Score (across 3 responses): 0.96\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'relevance': 0.73353064,\n",
       " 'specificity': 0.6414141414141414,\n",
       " 'consistency': 0.9613181}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def automated_evaluation(prompt, response, expected_content, n_additional_responses=2):\n",
    "    \"\"\"Perform automated evaluation of a prompt-response pair.\"\"\"\n",
    "    # Generate multiple responses to assess consistency\n",
    "    other_responses = [llm.invoke(prompt).content for _ in range(n_additional_responses)]\n",
    "    # Include the original response\n",
    "    all_responses = [response] + other_responses\n",
    "\n",
    "    # Relevance: how close is this response to the expected answer?\n",
    "    relevance = relevance_score(response, expected_content)\n",
    "\n",
    "    # Specificity: how non-generic is this response?\n",
    "    specificity = specificity_score(response)\n",
    "\n",
    "    # Consistency: compare main response with N additional responses\n",
    "    consistency = consistency_score(all_responses)\n",
    "\n",
    "    print(f\"Prompt: {prompt}\")\n",
    "    print(f\"Response: {response}\")\n",
    "    print(f\"\\nRelevance Score: {relevance:.2f}\")\n",
    "    print(f\"Specificity Score: {specificity:.2f}\")\n",
    "    print(f\"Consistency Score (across {n_additional_responses + 1} responses): {consistency:.2f}\")\n",
    "\n",
    "    return {\"relevance\": relevance, \"specificity\": specificity, \"consistency\": consistency}\n",
    "\n",
    "# Example usage\n",
    "prompt = \"What are the three main types of machine learning?\"\n",
    "expected_content = \"The three main types of machine learning are supervised learning, unsupervised learning, and reinforcement learning.\"\n",
    "response = llm.invoke(prompt).content\n",
    "automated_evaluation(prompt, response, expected_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oSRnDda0tbLi"
   },
   "source": [
    "This evaluation prints prompt and response text, followed by the scores. It also returns the scores for possible logging or further analysis.\n",
    "\n",
    "## Comparing multiple prompts\n",
    "To improve prompts, we often test several variations. The following function automates this comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "yuOhtSgvta_G"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: List the types of machine learning.\n",
      "Response: Machine learning can be broadly categorized into several types based on the nature of the learning process and the types of data used. Here are the main types of machine learning:\n",
      "\n",
      "1. **Supervised Learning**: In this approach, the model is trained on a labeled dataset, which means that the input data is paired with the correct output. The goal is to learn a mapping from inputs to outputs. Examples include:\n",
      "   - Classification (e.g., spam detection, image classification)\n",
      "   - Regression (e.g., predicting house prices, stock prices)\n",
      "\n",
      "2. **Unsupervised Learning**: This type involves training on data that does not have labeled responses. The model tries to learn the underlying structure or distribution in the data. Examples include:\n",
      "   - Clustering (e.g., customer segmentation, grouping similar items)\n",
      "   - Dimensionality Reduction (e.g., PCA, t-SNE for data visualization)\n",
      "   - Association (e.g., market basket analysis)\n",
      "\n",
      "3. **Semi-Supervised Learning**: This approach is a combination of supervised and unsupervised learning. It uses a small amount of labeled data along with a large amount of unlabeled data. This is particularly useful when labeling data is expensive or time-consuming.\n",
      "\n",
      "4. **Reinforcement Learning**: In this type, an agent learns to make decisions by taking actions in an environment to maximize cumulative rewards. The learning process is based on the feedback received from the environment. Examples include:\n",
      "   - Game playing (e.g., AlphaGo)\n",
      "   - Robotics (e.g., robotic control tasks)\n",
      "\n",
      "5. **Self-Supervised Learning**: This is a subset of unsupervised learning where the system generates labels from the input data itself. It is often used in natural language processing and computer vision.\n",
      "\n",
      "6. **Transfer Learning**: This technique involves taking a pre-trained model on one task and fine-tuning it for a different but related task. This is particularly useful when there is limited data for the new task.\n",
      "\n",
      "7. **Multi-Instance Learning**: In this scenario, instead of individual instances being labeled, sets of instances (bags) are labeled. The model learns from the bags rather than individual instances.\n",
      "\n",
      "These categories can often overlap, and many practical applications may involve a combination of these learning types.\n",
      "\n",
      "Relevance Score: 0.71\n",
      "Specificity Score: 0.59\n",
      "Consistency Score (across 3 responses): 0.92\n",
      "Prompt: What are the main categories of machine learning algorithms?\n",
      "Response: Machine learning algorithms can be broadly categorized into several main categories based on their learning paradigms and objectives. Here are the primary categories:\n",
      "\n",
      "1. **Supervised Learning**:\n",
      "   - In supervised learning, the algorithm is trained on labeled data, meaning that each training example is paired with an output label. The goal is to learn a mapping from inputs to outputs.\n",
      "   - Common algorithms include:\n",
      "     - Linear Regression\n",
      "     - Logistic Regression\n",
      "     - Decision Trees\n",
      "     - Random Forests\n",
      "     - Support Vector Machines (SVM)\n",
      "     - Neural Networks\n",
      "\n",
      "2. **Unsupervised Learning**:\n",
      "   - Unsupervised learning involves training on data without labeled outputs. The goal is to identify patterns or structures within the data.\n",
      "   - Common algorithms include:\n",
      "     - K-Means Clustering\n",
      "     - Hierarchical Clustering\n",
      "     - Principal Component Analysis (PCA)\n",
      "     - t-Distributed Stochastic Neighbor Embedding (t-SNE)\n",
      "     - Autoencoders\n",
      "\n",
      "3. **Semi-Supervised Learning**:\n",
      "   - This category combines aspects of both supervised and unsupervised learning, using a small amount of labeled data and a large amount of unlabeled data to improve learning accuracy.\n",
      "   - Common approaches include:\n",
      "     - Self-training\n",
      "     - Co-training\n",
      "     - Graph-based methods\n",
      "\n",
      "4. **Reinforcement Learning**:\n",
      "   - In reinforcement learning, an agent learns to make decisions by taking actions in an environment to maximize a reward signal. The learning is based on the consequences of actions rather than on labeled data.\n",
      "   - Key components include:\n",
      "     - Q-Learning\n",
      "     - Deep Q-Networks (DQN)\n",
      "     - Policy Gradient Methods\n",
      "     - Proximal Policy Optimization (PPO)\n",
      "\n",
      "5. **Self-Supervised Learning**:\n",
      "   - A form of unsupervised learning where the model generates its own supervisory signal from the input data itself. It is often used in natural language processing and computer vision.\n",
      "   - Examples include contrastive learning and masked language modeling (e.g., BERT).\n",
      "\n",
      "6. **Transfer Learning**:\n",
      "   - Transfer learning involves taking a pre-trained model from one task and fine-tuning it on a related task. This is particularly useful when labeled data for the target task is scarce.\n",
      "\n",
      "7. **Multi-Task Learning**:\n",
      "   - This approach involves training a model on multiple tasks simultaneously, leveraging shared representations to improve performance across all tasks.\n",
      "\n",
      "These categories highlight the diverse approaches to model training and data utilization in machine learning, each suited to different types of problems and datasets.\n",
      "\n",
      "Relevance Score: 0.65\n",
      "Specificity Score: 0.59\n",
      "Consistency Score (across 3 responses): 0.96\n",
      "Prompt: Explain the different approaches to machine learning.\n",
      "Response: Machine learning (ML) can be broadly categorized into several approaches based on how learning occurs, the type of data involved, and the specific tasks being performed. Here are the main approaches to machine learning:\n",
      "\n",
      "### 1. **Supervised Learning**\n",
      "In supervised learning, the model is trained on a labeled dataset, which means that each training example is paired with an output label. The goal is to learn a mapping from inputs to outputs.\n",
      "\n",
      "- **Examples:**\n",
      "  - Classification: Predicting discrete labels (e.g., spam detection, image recognition).\n",
      "  - Regression: Predicting continuous values (e.g., house prices, stock prices).\n",
      "\n",
      "- **Techniques:**\n",
      "  - Linear Regression\n",
      "  - Logistic Regression\n",
      "  - Decision Trees\n",
      "  - Support Vector Machines (SVM)\n",
      "  - Neural Networks\n",
      "\n",
      "### 2. **Unsupervised Learning**\n",
      "Unsupervised learning involves training a model on data without labeled outputs. The goal is to find hidden patterns or intrinsic structures in the input data.\n",
      "\n",
      "- **Examples:**\n",
      "  - Clustering: Grouping similar data points (e.g., customer segmentation).\n",
      "  - Dimensionality Reduction: Reducing the number of features while preserving important information (e.g., Principal Component Analysis, t-SNE).\n",
      "\n",
      "- **Techniques:**\n",
      "  - K-Means Clustering\n",
      "  - Hierarchical Clustering\n",
      "  - DBSCAN\n",
      "  - Autoencoders\n",
      "\n",
      "### 3. **Semi-Supervised Learning**\n",
      "Semi-supervised learning is a hybrid approach that uses a small amount of labeled data and a large amount of unlabeled data. This approach is particularly useful when labeling data is expensive or time-consuming.\n",
      "\n",
      "- **Examples:**\n",
      "  - Training a model with a few labeled images and many unlabeled images to improve image classification accuracy.\n",
      "\n",
      "- **Techniques:**\n",
      "  - Self-training\n",
      "  - Co-training\n",
      "  - Graph-based methods\n",
      "\n",
      "### 4. **Reinforcement Learning**\n",
      "Reinforcement learning is a type of learning where an agent learns to make decisions by taking actions in an environment to maximize cumulative reward. The learning process is based on feedback from the environment.\n",
      "\n",
      "- **Examples:**\n",
      "  - Game playing (e.g., AlphaGo, OpenAI's Dota 2 bot).\n",
      "  - Robotics (e.g., training robots to walk or manipulate objects).\n",
      "\n",
      "- **Techniques:**\n",
      "  - Q-Learning\n",
      "  - Deep Q-Networks (DQN)\n",
      "  - Policy Gradients\n",
      "  - Proximal Policy Optimization (PPO)\n",
      "\n",
      "### 5. **Self-Supervised Learning**\n",
      "Self-supervised learning is a form of unsupervised learning where the model generates its own labels from the input data. This approach is particularly popular in natural language processing and computer vision.\n",
      "\n",
      "- **Examples:**\n",
      "  - Training models on the context of words in sentences (e.g., BERT, GPT).\n",
      "  - Predicting missing parts of images.\n",
      "\n",
      "### 6. **Transfer Learning**\n",
      "Transfer learning involves taking a pre-trained model (trained on one task) and fine-tuning it on a different but related task. This approach is useful when there is a limited amount of data for the target task.\n",
      "\n",
      "- **Examples:**\n",
      "  - Using a model trained on ImageNet for a specific image classification task.\n",
      "  - Fine-tuning language models for specific text classification tasks.\n",
      "\n",
      "### 7. **Ensemble Learning**\n",
      "Ensemble learning combines multiple models to improve overall performance. The idea is that a group of models can often outperform any individual model.\n",
      "\n",
      "- **Examples:**\n",
      "  - Random Forests: An ensemble of decision trees.\n",
      "  - Gradient Boosting: Sequentially building models that correct the errors of the previous ones.\n",
      "\n",
      "### Conclusion\n",
      "These approaches reflect the diverse methods and strategies employed in machine learning to address various types of problems and data. The choice of approach often depends on the nature of the data, the specific task, and the desired outcomes.\n",
      "\n",
      "Relevance Score: 0.65\n",
      "Specificity Score: 0.53\n",
      "Consistency Score (across 3 responses): 0.90\n",
      "Prompt Comparison Results:\n",
      "\n",
      "1. Prompt: List the types of machine learning.\n",
      "   Relevance: 0.71\n",
      "   Specificity: 0.59\n",
      "   Consistency: 0.92\n",
      "\n",
      "2. Prompt: Explain the different approaches to machine learning.\n",
      "   Relevance: 0.65\n",
      "   Specificity: 0.53\n",
      "   Consistency: 0.90\n",
      "\n",
      "3. Prompt: What are the main categories of machine learning algorithms?\n",
      "   Relevance: 0.65\n",
      "   Specificity: 0.59\n",
      "   Consistency: 0.96\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'prompt': 'List the types of machine learning.',\n",
       "  'relevance': 0.70720327,\n",
       "  'specificity': 0.5922619047619048,\n",
       "  'consistency': 0.92151624},\n",
       " {'prompt': 'Explain the different approaches to machine learning.',\n",
       "  'relevance': 0.65206325,\n",
       "  'specificity': 0.5345794392523364,\n",
       "  'consistency': 0.89919156},\n",
       " {'prompt': 'What are the main categories of machine learning algorithms?',\n",
       "  'relevance': 0.6494788,\n",
       "  'specificity': 0.5943661971830986,\n",
       "  'consistency': 0.9645951}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compare_prompts(prompts, expected_content, n_additional_responses=2):\n",
    "    \"\"\"Compare the effectiveness of multiple prompts for the same task.\"\"\"\n",
    "    results = []\n",
    "    for prompt in prompts:\n",
    "        # Generate an initial response\n",
    "        response = llm.invoke(prompt).content\n",
    "        # Evaluate using all metrics\n",
    "        evaluation = automated_evaluation(prompt, response, expected_content, n_additional_responses=n_additional_responses)\n",
    "        # Store results with prompt\n",
    "        results.append({\"prompt\": prompt, **evaluation})\n",
    "\n",
    "    # Sort results by relevance score descending\n",
    "    sorted_results = sorted(results, key=lambda x: x['relevance'], reverse=True)\n",
    "\n",
    "    # Display all sorted results\n",
    "    print(\"Prompt Comparison Results:\")\n",
    "    for i, result in enumerate(sorted_results, 1):\n",
    "        print(f\"\\n{i}. Prompt: {result['prompt']}\")\n",
    "        print(f\"   Relevance: {result['relevance']:.2f}\")\n",
    "        print(f\"   Specificity: {result['specificity']:.2f}\")\n",
    "        print(f\"   Consistency: {result['consistency']:.2f}\")\n",
    "\n",
    "    return sorted_results\n",
    "\n",
    "# Example usage\n",
    "prompts = [\n",
    "    \"List the types of machine learning.\",\n",
    "    \"What are the main categories of machine learning algorithms?\",\n",
    "    \"Explain the different approaches to machine learning.\"\n",
    "]\n",
    "expected_content = \"The main types of machine learning are supervised learning, unsupervised learning, and reinforcement learning.\"\n",
    "compare_prompts(prompts, expected_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1lLtFDqptawF"
   },
   "source": [
    "This is especially helpful during prompt tuning. It evaluates each prompt on the same task and ranks them by relevance, helping us decide which formulation yields the most useful outputs. We compare different phrasings to determine which is most likely to yield a high-quality, informative response.\n",
    "\n",
    "### Putting it all together\n",
    "Lastly, let’s combine both automated and manual evaluations into a unified function that gives us a comprehensive prompt evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "3YzYVMWuuNXc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automated Evaluation:\n",
      "Prompt: Explain the concept of overfitting in machine learning.\n",
      "Response: Overfitting is a common problem in machine learning where a model learns to capture the noise and details of the training data to an extent that it performs poorly on new, unseen data. Essentially, the model becomes too complex and tailored to the training dataset, which limits its ability to generalize to other datasets.\n",
      "\n",
      "### Key Points about Overfitting:\n",
      "\n",
      "1. **Complexity of the Model**: Overfitting often occurs when a model is too complex relative to the amount of training data available. For instance, deep neural networks with many layers can fit very intricate patterns in the training data, including noise that doesn't represent the underlying distribution.\n",
      "\n",
      "2. **Training vs. Validation Performance**: In overfitting, a model shows excellent performance (low error) on the training data but significantly poorer performance on validation or test datasets. This disparity indicates that the model has learned specific details about the training data rather than the general patterns.\n",
      "\n",
      "3. **Causes of Overfitting**:\n",
      "   - **Insufficient Data**: When there is not enough training data to capture the underlying distribution, the model may learn from noise.\n",
      "   - **High Model Complexity**: Using a model with too many parameters (like deep neural networks with many layers) relative to the amount of data.\n",
      "   - **Inadequate Regularization**: Lack of techniques to constrain the model can lead to overfitting.\n",
      "\n",
      "4. **Detection of Overfitting**: \n",
      "   - Monitor training and validation loss/accuracy. If training loss decreases while validation loss begins to increase, overfitting is likely occurring.\n",
      "   - Use techniques like cross-validation to get a better estimate of how well the model will perform on unseen data.\n",
      "\n",
      "5. **Strategies to Mitigate Overfitting**:\n",
      "   - **Regularization**: Techniques such as L1 (Lasso) and L2 (Ridge) regularization add penalties for larger coefficients in the loss function, discouraging overly complex models.\n",
      "   - **Early Stopping**: Monitor the model's performance on a validation set and stop training once performance begins to degrade.\n",
      "   - **Pruning**: For decision trees, this involves removing branches that have little importance or predictive power.\n",
      "   - **Data Augmentation**: Increasing the size and diversity of the training dataset through transformations (like rotation, scaling, etc.) can help the model generalize better.\n",
      "   - **Dropout**: In neural networks, randomly dropping units during training can prevent co-adaptation of hidden units.\n",
      "\n",
      "### Conclusion\n",
      "Overfitting is a critical issue that affects the generalization ability of machine learning models. Understanding and recognizing overfitting, along with employing strategies to mitigate it, is essential for building robust and effective machine learning systems.\n",
      "\n",
      "Relevance Score: 0.79\n",
      "Specificity Score: 0.59\n",
      "Consistency Score (across 3 responses): 0.89\n",
      "\n",
      "Manual Evaluation:\n",
      "Prompt: Explain the concept of overfitting in machine learning.\n",
      "Response: Overfitting is a common problem in machine learning where a model learns to capture the noise and details of the training data to an extent that it performs poorly on new, unseen data. Essentially, the model becomes too complex and tailored to the training dataset, which limits its ability to generalize to other datasets.\n",
      "\n",
      "### Key Points about Overfitting:\n",
      "\n",
      "1. **Complexity of the Model**: Overfitting often occurs when a model is too complex relative to the amount of training data available. For instance, deep neural networks with many layers can fit very intricate patterns in the training data, including noise that doesn't represent the underlying distribution.\n",
      "\n",
      "2. **Training vs. Validation Performance**: In overfitting, a model shows excellent performance (low error) on the training data but significantly poorer performance on validation or test datasets. This disparity indicates that the model has learned specific details about the training data rather than the general patterns.\n",
      "\n",
      "3. **Causes of Overfitting**:\n",
      "   - **Insufficient Data**: When there is not enough training data to capture the underlying distribution, the model may learn from noise.\n",
      "   - **High Model Complexity**: Using a model with too many parameters (like deep neural networks with many layers) relative to the amount of data.\n",
      "   - **Inadequate Regularization**: Lack of techniques to constrain the model can lead to overfitting.\n",
      "\n",
      "4. **Detection of Overfitting**: \n",
      "   - Monitor training and validation loss/accuracy. If training loss decreases while validation loss begins to increase, overfitting is likely occurring.\n",
      "   - Use techniques like cross-validation to get a better estimate of how well the model will perform on unseen data.\n",
      "\n",
      "5. **Strategies to Mitigate Overfitting**:\n",
      "   - **Regularization**: Techniques such as L1 (Lasso) and L2 (Ridge) regularization add penalties for larger coefficients in the loss function, discouraging overly complex models.\n",
      "   - **Early Stopping**: Monitor the model's performance on a validation set and stop training once performance begins to degrade.\n",
      "   - **Pruning**: For decision trees, this involves removing branches that have little importance or predictive power.\n",
      "   - **Data Augmentation**: Increasing the size and diversity of the training dataset through transformations (like rotation, scaling, etc.) can help the model generalize better.\n",
      "   - **Dropout**: In neural networks, randomly dropping units during training can prevent co-adaptation of hidden units.\n",
      "\n",
      "### Conclusion\n",
      "Overfitting is a critical issue that affects the generalization ability of machine learning models. Understanding and recognizing overfitting, along with employing strategies to mitigate it, is essential for building robust and effective machine learning systems.\n",
      "\n",
      "Evaluation Criteria:\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Score for Clarity (0-10):  5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clarity: 5.0/10\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Score for Accuracy (0-10):  5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 5.0/10\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Score for Relevance (0-10):  5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relevance: 5.0/10\n",
      "\n",
      "Additional Comments:\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter any additional comments:  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comments: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'prompt': 'Explain the concept of overfitting in machine learning.',\n",
       " 'response': \"Overfitting is a common problem in machine learning where a model learns to capture the noise and details of the training data to an extent that it performs poorly on new, unseen data. Essentially, the model becomes too complex and tailored to the training dataset, which limits its ability to generalize to other datasets.\\n\\n### Key Points about Overfitting:\\n\\n1. **Complexity of the Model**: Overfitting often occurs when a model is too complex relative to the amount of training data available. For instance, deep neural networks with many layers can fit very intricate patterns in the training data, including noise that doesn't represent the underlying distribution.\\n\\n2. **Training vs. Validation Performance**: In overfitting, a model shows excellent performance (low error) on the training data but significantly poorer performance on validation or test datasets. This disparity indicates that the model has learned specific details about the training data rather than the general patterns.\\n\\n3. **Causes of Overfitting**:\\n   - **Insufficient Data**: When there is not enough training data to capture the underlying distribution, the model may learn from noise.\\n   - **High Model Complexity**: Using a model with too many parameters (like deep neural networks with many layers) relative to the amount of data.\\n   - **Inadequate Regularization**: Lack of techniques to constrain the model can lead to overfitting.\\n\\n4. **Detection of Overfitting**: \\n   - Monitor training and validation loss/accuracy. If training loss decreases while validation loss begins to increase, overfitting is likely occurring.\\n   - Use techniques like cross-validation to get a better estimate of how well the model will perform on unseen data.\\n\\n5. **Strategies to Mitigate Overfitting**:\\n   - **Regularization**: Techniques such as L1 (Lasso) and L2 (Ridge) regularization add penalties for larger coefficients in the loss function, discouraging overly complex models.\\n   - **Early Stopping**: Monitor the model's performance on a validation set and stop training once performance begins to degrade.\\n   - **Pruning**: For decision trees, this involves removing branches that have little importance or predictive power.\\n   - **Data Augmentation**: Increasing the size and diversity of the training dataset through transformations (like rotation, scaling, etc.) can help the model generalize better.\\n   - **Dropout**: In neural networks, randomly dropping units during training can prevent co-adaptation of hidden units.\\n\\n### Conclusion\\nOverfitting is a critical issue that affects the generalization ability of machine learning models. Understanding and recognizing overfitting, along with employing strategies to mitigate it, is essential for building robust and effective machine learning systems.\",\n",
       " 'relevance': 0.79009473,\n",
       " 'specificity': 0.59,\n",
       " 'consistency': 0.8887844}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def evaluate_prompt(prompt, expected_content, manual_criteria=['Clarity', 'Accuracy', 'Relevance']):\n",
    "    \"\"\"Perform a comprehensive evaluation of a prompt using both manual and automated techniques.\"\"\"\n",
    "    response = llm.invoke(prompt).content\n",
    "\n",
    "    print(\"Automated Evaluation:\")\n",
    "    auto_results = automated_evaluation(prompt, response, expected_content)\n",
    "\n",
    "    print(\"\\nManual Evaluation:\")\n",
    "    manual_evaluation(prompt, response, manual_criteria)\n",
    "\n",
    "    return {\"prompt\": prompt, \"response\": response, **auto_results}\n",
    "\n",
    "# Example usage\n",
    "prompt = \"Explain the concept of overfitting in machine learning.\"\n",
    "expected_content = \"Overfitting occurs when a model learns the training data too well, including its noise and fluctuations, leading to poor generalization on new, unseen data.\"\n",
    "evaluate_prompt(prompt, expected_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ogz3au1JuM7k"
   },
   "source": [
    "This approach is ideal for final validation before deploying a prompt in production. It combines objective metrics with subjective assessment, enabling a more nuanced understanding of prompt behavior."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
