{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V6bFB_LcXuIM"
   },
   "source": [
    "# Chain of thought (CoT) prompting\n",
    "\n",
    "This notebook introduces chain of thought (CoT) prompting — an powerful prompt engineering technique that guides LLMs to solve problems by reasoning through them step-by-step. Much like how a human would “show their work” in math or logic, CoT prompting encourages the model to think aloud before arriving at a final answer.\n",
    "\n",
    "As language models grow more powerful, our expectations shift from just correct outputs to transparent and trustworthy reasoning. CoT prompting directly addresses this need by structuring the model’s internal reasoning process in the prompt itself. CoT prompting is useful because it helps with:\n",
    "- Accuracy — by making the reasoning process more structured.\n",
    "- Transparency — because we can see and verify each step.\n",
    "- Debugging — since it’s easier to spot where things might have gone wrong in the model’s thought process.\n",
    "\n",
    "This approach is especially helpful for tasks that involve multiple steps, like math problems, logic puzzles, or anything that requires reasoning beyond a simple lookup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "4LRxxOrIXvY6"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Set up OpenAI API key\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s5clGLzwXvrB"
   },
   "source": [
    "### Initialize the language model\n",
    "We instantiate a lightweight GPT model from OpenAI using LangChain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "oGK7ZYRPXpru"
   },
   "outputs": [],
   "source": [
    "# Initialize the language model\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini-2024-07-18\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j_Tdn0PgX3xQ"
   },
   "source": [
    "## Basic chain of thought Prompting\n",
    "To understand how CoT prompting works, we will start with a simple example: calculating average speed. The goal is to compare a standard direct prompt with a CoT-style prompt that encourages the model to reason through each step before answering.\n",
    "\n",
    "In traditional prompting, we ask the model for an answer directly. With CoT prompting, we add an instruction to reason \"step by step,\" nudging the model to walk through the logic before producing the final answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "HVz2etPQX4Ha"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard Response:\n",
      "The average speed of the train is 60 km/h.\n",
      "\n",
      "Chain of Thought Response:\n",
      "To find the average speed, you can use the formula:\n",
      "\n",
      "\\[ \\text{Average Speed} = \\frac{\\text{Total Distance}}{\\text{Total Time}} \\]\n",
      "\n",
      "1. **Identify the total distance**: The train travels 120 km.\n",
      "2. **Identify the total time**: The time taken is 2 hours.\n",
      "3. **Apply the formula**:\n",
      "\n",
      "   \\[ \\text{Average Speed} = \\frac{120 \\text{ km}}{2 \\text{ hours}} \\]\n",
      "\n",
      "4. **Calculate**:\n",
      "\n",
      "   \\[ \\text{Average Speed} = 60 \\text{ km/h} \\]\n",
      "\n",
      "Therefore, the average speed of the train is **60 km/h**.\n"
     ]
    }
   ],
   "source": [
    "# Standard prompt: Asks for a concise answer without elaboration\n",
    "standard_prompt = PromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    template=\"Answer the following question concisely: {question}.\"\n",
    ")\n",
    "\n",
    "# Chain of Thought prompt: Adds an instruction to reason step by step\n",
    "cot_prompt = PromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    template=\"Answer the following question step by step concisely: {question}\"\n",
    ")\n",
    "\n",
    "# Create chains\n",
    "standard_chain = standard_prompt | llm\n",
    "cot_chain = cot_prompt | llm\n",
    "\n",
    "# Define a simple math question to test both prompts\n",
    "question = \"If a train travels 120 km in 2 hours, what is its average speed in km/h?\"\n",
    "\n",
    "# Run both prompts through the chains and collect responses\n",
    "standard_response = standard_chain.invoke(question).content\n",
    "cot_response = cot_chain.invoke(question).content\n",
    "\n",
    "print(\"Standard Response:\")\n",
    "print(standard_response)\n",
    "print(\"\\nChain of Thought Response:\")\n",
    "print(cot_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t3diU0exX4Vf"
   },
   "source": [
    "This side-by-side comparison demonstrates how a minor change in prompt wording can lead to more thoughtful, transparent outputs.\n",
    "1. Prompt definition - We define two `PromptTemplate`s:\n",
    "   - The standard prompt simply asks the model to answer the question concisely.\n",
    "   - The CoT prompt adds the phrase “step by step,” signaling the model to work through the reasoning process.\n",
    "2. Prompt execution - Using LangChain’s `|` operator, we pipe each prompt into the language model (`llm`), creating two chains — `standard_chain` and `cot_chain`. These chains handle prompt formatting and response generation.\n",
    "3. Inference - We provide both chains with the same input question.\n",
    "\n",
    "This basic comparison illustrates a key idea behind CoT prompting: even small prompt changes can significantly affect how the model reasons and communicates. In more complex problems, this difference becomes even more valuable — CoT prompting helps the model avoid mistakes by breaking the problem into smaller, more manageable parts.\n",
    "\n",
    "## Advanced chain of thought techniques\n",
    "Let’s now extend the CoT idea by introducing a more structured format that explicitly encourages multi-step reasoning. Instead of simply asking the model to \"think step by step,\" we guide it through a defined sequence: first stating what needs to be calculated, then identifying the relevant formula, performing the computation, and finally explaining the result.\n",
    "\n",
    "This kind of structured reasoning closely mirrors how humans approach problem-solving — particularly in domains where precision is critical, such as mathematics, finance and decision support tools. By making each reasoning step explicit, we reduce the likelihood of the model skipping over important details or making silent mistakes.\n",
    "\n",
    "The result is not only greater reliability and accuracy, but also improved interpretability. Each step is clearly laid out, making it easier for users to verify the model’s logic and understand how it arrived at its final answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "FiYrnJP7X4is"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To find the average speed for the entire journey, we will use the following steps.\n",
      "\n",
      "### Step 1: Calculate the time taken for each segment of the journey.\n",
      "**What I'm going to calculate:** The time taken to travel each segment of the journey.\n",
      "\n",
      "**Formula:** \n",
      "\\[\n",
      "\\text{Time} = \\frac{\\text{Distance}}{\\text{Speed}}\n",
      "\\]\n",
      "\n",
      "#### Segment 1:\n",
      "- Distance = 150 km\n",
      "- Speed = 60 km/h\n",
      "\n",
      "**Calculation:**\n",
      "\\[\n",
      "\\text{Time}_1 = \\frac{150 \\text{ km}}{60 \\text{ km/h}} = 2.5 \\text{ hours}\n",
      "\\]\n",
      "\n",
      "#### Segment 2:\n",
      "- Distance = 100 km\n",
      "- Speed = 50 km/h\n",
      "\n",
      "**Calculation:**\n",
      "\\[\n",
      "\\text{Time}_2 = \\frac{100 \\text{ km}}{50 \\text{ km/h}} = 2 \\text{ hours}\n",
      "\\]\n",
      "\n",
      "### Explanation of result for Step 1:\n",
      "The time taken for the first segment of the journey is 2.5 hours, and for the second segment, it is 2 hours. This means it took a total of 4.5 hours for the entire journey.\n",
      "\n",
      "---\n",
      "\n",
      "### Step 2: Calculate the total distance traveled.\n",
      "**What I'm going to calculate:** The total distance traveled during the journey.\n",
      "\n",
      "**Formula:** \n",
      "\\[\n",
      "\\text{Total Distance} = \\text{Distance}_1 + \\text{Distance}_2\n",
      "\\]\n",
      "\n",
      "**Calculation:**\n",
      "\\[\n",
      "\\text{Total Distance} = 150 \\text{ km} + 100 \\text{ km} = 250 \\text{ km}\n",
      "\\]\n",
      "\n",
      "### Explanation of result for Step 2:\n",
      "The total distance traveled during the journey is 250 km.\n",
      "\n",
      "---\n",
      "\n",
      "### Step 3: Calculate the average speed for the entire journey.\n",
      "**What I'm going to calculate:** The average speed for the entire journey.\n",
      "\n",
      "**Formula:** \n",
      "\\[\n",
      "\\text{Average Speed} = \\frac{\\text{Total Distance}}{\\text{Total Time}}\n",
      "\\]\n",
      "\n",
      "**Calculation:**\n",
      "\\[\n",
      "\\text{Average Speed} = \\frac{250 \\text{ km}}{4.5 \\text{ hours}} \\approx 55.56 \\text{ km/h}\n",
      "\\]\n",
      "\n",
      "### Explanation of result for Step 3:\n",
      "The average speed for the entire journey is approximately 55.56 km/h. This value represents the overall speed of the car when considering the entire distance and total time taken for the trip. \n",
      "\n",
      "---\n",
      "\n",
      "### Final Conclusion:\n",
      "The average speed for the car's journey, after traveling 150 km at 60 km/h and then 100 km at 50 km/h, is approximately 55.56 km/h.\n"
     ]
    }
   ],
   "source": [
    "# Define a structured CoT prompt for multi-step quantitative reasoning\n",
    "advanced_cot_prompt = PromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    template=\"\"\"Solve the following problem step by step. For each step:\n",
    "1. State what you're going to calculate\n",
    "2. Write the formula you'll use (if applicable)\n",
    "3. Perform the calculation\n",
    "4. Explain the result\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Solution:\"\"\"\n",
    ")\n",
    "\n",
    "# Pipe the prompt into the language model to create a CoT chain\n",
    "advanced_cot_chain = advanced_cot_prompt | llm\n",
    "\n",
    "# Example: Multi-leg trip average speed problem\n",
    "complex_question = \"A car travels 150 km at 60 km/h, then another 100 km at 50 km/h. What is the average speed for the entire journey?\"\n",
    "\n",
    "# Run the advanced CoT chain with the complex question\n",
    "advanced_cot_response = advanced_cot_chain.invoke(complex_question).content\n",
    "print(advanced_cot_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UQ4lKKybX4wd"
   },
   "source": [
    "- We first define a detailed CoT-style prompt that gives the model a reasoning structure to follow — not just a hint, but a full step-by-step scaffold.\n",
    "- We then create a LangChain pipeline (`advanced_cot_chain`) by combining the prompt and the model.\n",
    "- A more complex math question is passed into this chain: the average speed of a car with two legs of different distances and speeds.\n",
    "- The model walks through the problem using the structure we provided, showing its full reasoning process along the way.\n",
    "\n",
    "## Comparative analysis\n",
    "Now that we have explored both basic and advanced Chain of Thought prompting, let’s put it to the test. In this section, we compare how standard prompting and CoT prompting perform on a more complex, real-world problem — one that involves volume calculations, unit conversions, and reasoning over rates.\n",
    "\n",
    "This kind of problem is often where large language models can struggle. Without a structured approach, the model may:\n",
    "- Misapply formulas.\n",
    "- Skip key unit conversions.\n",
    "- Give a final answer without showing the necessary steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "KmE4Znu2X4-d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard Response:\n",
      "First, we calculate the volume of the cylindrical tank using the formula for the volume of a cylinder: \n",
      "\n",
      "\\[ V = \\pi r^2 h \\]\n",
      "\n",
      "Where:\n",
      "- \\( r = 1.5 \\) meters\n",
      "- \\( h = 4 \\) meters\n",
      "\n",
      "Calculating the volume:\n",
      "\n",
      "\\[ V = 3.14159 \\times (1.5)^2 \\times 4 \\]\n",
      "\\[ V = 3.14159 \\times 2.25 \\times 4 \\]\n",
      "\\[ V = 3.14159 \\times 9 = 28.27436 \\text{ cubic meters} \\]\n",
      "\n",
      "Since the tank is 2/3 full, we find the current volume of water:\n",
      "\n",
      "\\[ \\text{Current Volume} = \\frac{2}{3} \\times 28.27436 = 18.84957 \\text{ cubic meters} \\]\n",
      "\n",
      "The volume of the tank when full is:\n",
      "\n",
      "\\[ 28.27436 \\text{ cubic meters} \\]\n",
      "\n",
      "The volume needed to fill the tank to the top is:\n",
      "\n",
      "\\[ \\text{Volume to fill} = 28.27436 - 18.84957 = 9.42479 \\text{ cubic meters} \\]\n",
      "\n",
      "Converting cubic meters to liters (1 cubic meter = 1000 liters):\n",
      "\n",
      "\\[ \\text{Volume to fill in liters} = 9.42479 \\times 1000 = 9424.79 \\text{ liters} \\]\n",
      "\n",
      "Water is being added at a rate of 10 liters per minute. To find the time it takes to fill the tank to the top, we use:\n",
      "\n",
      "\\[ \\text{Time (in minutes)} = \\frac{\\text{Volume to fill in liters}}{\\text{Rate}} = \\frac{9424.79}{10} = 942.479 \\text{ minutes} \\]\n",
      "\n",
      "Rounding to the nearest minute:\n",
      "\n",
      "\\[ \\text{Time} \\approx 942 \\text{ minutes} \\]\n",
      "\n",
      "Now, converting minutes to hours and minutes:\n",
      "\n",
      "\\[ 942 \\div 60 = 15 \\text{ hours and } 42 \\text{ minutes} \\]\n",
      "\n",
      "Thus, it will take approximately **15 hours and 42 minutes** for the tank to overflow.\n",
      "\n",
      "Chain of Thought Response:\n",
      "To solve the problem, we will follow the steps outlined:\n",
      "\n",
      "### Step 1: Calculate the volume of the cylindrical tank.\n",
      "1. **What we're going to calculate:** The total volume of the cylindrical tank.\n",
      "2. **Formula:** The volume \\( V \\) of a cylinder is given by the formula:  \n",
      "   \\[\n",
      "   V = \\pi r^2 h\n",
      "   \\]\n",
      "   where \\( r \\) is the radius and \\( h \\) is the height.\n",
      "3. **Perform the calculation:**  \n",
      "   Given \\( r = 1.5 \\) meters and \\( h = 4 \\) meters,  \n",
      "   \\[\n",
      "   V = \\pi (1.5)^2 (4) = 3.14159 \\times 2.25 \\times 4\n",
      "   \\]\n",
      "   \\[\n",
      "   V = 3.14159 \\times 9 = 28.27432 \\text{ cubic meters}\n",
      "   \\]\n",
      "4. **Explain the result:** The total volume of the tank is approximately 28.27 cubic meters.\n",
      "\n",
      "### Step 2: Calculate the volume when the tank is 2/3 full.\n",
      "1. **What we're going to calculate:** The volume of water when the tank is 2/3 full.\n",
      "2. **Formula:**  \n",
      "   \\[\n",
      "   V_{\\text{full}} = \\frac{2}{3} V\n",
      "   \\]\n",
      "3. **Perform the calculation:**  \n",
      "   \\[\n",
      "   V_{\\text{full}} = \\frac{2}{3} \\times 28.27432 = 18.84955 \\text{ cubic meters}\n",
      "   \\]\n",
      "4. **Explain the result:** The volume of water currently in the tank, when it is 2/3 full, is approximately 18.85 cubic meters.\n",
      "\n",
      "### Step 3: Calculate the volume of the tank when full in liters.\n",
      "1. **What we're going to calculate:** Convert the total volume of the tank to liters.\n",
      "2. **Formula:**  \n",
      "   \\[\n",
      "   V_{\\text{liters}} = V_{\\text{cubic meters}} \\times 1000\n",
      "   \\]\n",
      "3. **Perform the calculation:**  \n",
      "   \\[\n",
      "   V_{\\text{liters}} = 28.27432 \\times 1000 = 28274.32 \\text{ liters}\n",
      "   \\]\n",
      "4. **Explain the result:** The tank can hold approximately 28,274.32 liters when full.\n",
      "\n",
      "### Step 4: Calculate the current volume of water in liters.\n",
      "1. **What we're going to calculate:** Convert the volume of water currently in the tank to liters.\n",
      "2. **Formula:**  \n",
      "   \\[\n",
      "   V_{\\text{current liters}} = V_{\\text{current cubic meters}} \\times 1000\n",
      "   \\]\n",
      "3. **Perform the calculation:**  \n",
      "   \\[\n",
      "   V_{\\text{current liters}} = 18.84955 \\times 1000 = 18849.55 \\text{ liters}\n",
      "   \\]\n",
      "4. **Explain the result:** The current volume of water in the tank is approximately 18,849.55 liters.\n",
      "\n",
      "### Step 5: Calculate the volume needed to fill the tank to overflow.\n",
      "1. **What we're going to calculate:** The volume of water needed to fill the tank completely.\n",
      "2. **Formula:**  \n",
      "   \\[\n",
      "   V_{\\text{needed}} = V_{\\text{full liters}} - V_{\\text{current liters}}\n",
      "   \\]\n",
      "3. **Perform the calculation:**  \n",
      "   \\[\n",
      "   V_{\\text{needed}} = 28274.32 - 18849.55 = 9414.77 \\text{ liters}\n",
      "   \\]\n",
      "4. **Explain the result:** Approximately 9,414.77 liters of water are needed to fill the tank to the overflow point.\n",
      "\n",
      "### Step 6: Calculate the time it takes to add this volume of water.\n",
      "1. **What we're going to calculate:** The time required to add 9,414.77 liters at a rate of 10 liters per minute.\n",
      "2. **Formula:**  \n",
      "   \\[\n",
      "   t = \\frac{V_{\\text{needed}}}{\\text{Rate}}\n",
      "   \\]\n",
      "3. **Perform the calculation:**  \n",
      "   \\[\n",
      "   t = \\frac{9414.77}{10} = 941.477 \\text{ minutes}\n",
      "   \\]\n",
      "4. **Explain the result:** It will take approximately 941.48 minutes to fill the tank to the overflow point.\n",
      "\n",
      "### Step 7: Convert the time from minutes to hours and minutes.\n",
      "1. **What we're going to calculate:** Convert 941.48 minutes to hours and minutes.\n",
      "2. **Formula:**  \n",
      "   \\[\n",
      "   \\text{Hours} = \\left\\lfloor \\frac{t}{60} \\right\\rfloor, \\quad \\text{Minutes} = t \\mod 60\n",
      "   \\]\n",
      "3. **Perform the calculation:**  \n",
      "   \\[\n",
      "   \\text{Hours} = \\left\\lfloor \\frac{941.477}{60} \\right\\rfloor = 15 \\text{ hours} \n",
      "   \\]\n",
      "   \\[\n",
      "   \\text{Minutes} = 941.477 - (15 \\times 60) = 941.477 - 900 = 41.477 \\approx 41 \\text{ minutes}\n",
      "   \\]\n",
      "4. **Explain the result:** It will take approximately 15 hours and 41 minutes for the tank to overflow when water is added at a rate of 10 liters per minute.\n",
      "\n",
      "### Final Answer:\n",
      "**It will take approximately 15 hours and 41 minutes for the tank to overflow.**\n"
     ]
    }
   ],
   "source": [
    "# Define a challenging question to test both prompts\n",
    "challenging_question = \"\"\"\n",
    "A cylindrical water tank with a radius of 1.5 meters and a height of 4 meters is 2/3 full.\n",
    "If water is being added at a rate of 10 liters per minute, how long will it take for the tank to overflow?\n",
    "Give your answer in hours and minutes, rounded to the nearest minute.\n",
    "(Use 3.14159 for π and 1000 liters = 1 cubic meter)\"\"\"\n",
    "\n",
    "# Invoke the standard prompting chain\n",
    "standard_response = standard_chain.invoke(challenging_question).content\n",
    "# Invoke the advanced CoT prompting chain\n",
    "cot_response = advanced_cot_chain.invoke(challenging_question).content\n",
    "\n",
    "print(\"Standard Response:\")\n",
    "print(standard_response)\n",
    "print(\"\\nChain of Thought Response:\")\n",
    "print(cot_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0DnPCdzqX5Lc"
   },
   "source": [
    "- Defines a challenging problem: This question requires understanding geometry (volume of a cylinder), fractional values (2/3 full), unit conversion (cubic meters to liters), and applying a rate (liters per minute).\n",
    "- Sends the same input to both chains:\n",
    "  - The `standard_chain` uses a direct prompt that asks for the answer.\n",
    "  - The `advanced_cot_chain` walks the model through a multi-step reasoning process.\n",
    "- Prints and compares the results: This allows us to assess not just the correctness of the answer, but also the transparency of the model’s thinking.\n",
    "\n",
    "Real-world tasks often require layered reasoning. Standard prompting may suffice for straightforward queries, but when multiple steps are involved, CoT prompting helps ensure that each part of the logic is processed carefully and correctly. By observing the two outputs side by side, we can clearly see the benefits of CoT in action — particularly when the problem requires mathematical precision and logical sequencing.\n",
    "\n",
    "## Problem-solving applications: Logical reasoning\n",
    "Now, let's apply CoT prompting to a more complex logical reasoning task. CoT prompting is not just for math — it excels in logical reasoning and deduction tasks too.\n",
    "\n",
    "**Why use CoT for logical reasoning?**\n",
    "\n",
    "CoT prompting encourages the model to approach the problem step-by-step. Instead of simply asking for an answer, we guide the model through a structured process that mirrors how humans solve logical puzzles:\n",
    "1. List the facts: Summarize the given information clearly.\n",
    "2. Identify possible roles: Determine what roles could be assigned to each person (truth-teller, liar, alternator).\n",
    "3. Generate scenarios: Consider all possible combinations of roles.\n",
    "4. Test each scenario: Analyze each scenario based on the statements provided.\n",
    "5. Eliminate inconsistent scenarios: Discard any scenarios that lead to contradictions.\n",
    "6. Conclude the solution: Identify the correct roles and explain the reasoning behind the solution.\n",
    "\n",
    "This method ensures a transparent and thorough reasoning process, which is important for solving complex logical problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "p72YgxhLX5Zk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's analyze the logical puzzle step-by-step as requested.\n",
      "\n",
      "### List the Facts:\n",
      "\n",
      "1. **Characters Involved**: \n",
      "   - Amy\n",
      "   - Bob\n",
      "   - Charlie\n",
      "\n",
      "2. **Statements Made**:\n",
      "   - **Amy**: \"Bob is a liar.\"\n",
      "   - **Bob**: \"Charlie alternates between truth and lies.\"\n",
      "   - **Charlie**: \"Amy and I are both liars.\"\n",
      "\n",
      "### Identify Possible Roles or Conditions:\n",
      "\n",
      "- **Roles**: There are three roles:\n",
      "  - Truth-teller (always tells the truth)\n",
      "  - Liar (always lies)\n",
      "  - Alternator (alternates between truth and lies)\n",
      "\n",
      "### Note the Constraints:\n",
      "\n",
      "1. One of the three characters must be a truth-teller.\n",
      "2. One must be a liar.\n",
      "3. One must be an alternator.\n",
      "4. The statements made must be evaluated based on their assigned roles.\n",
      "\n",
      "### Generate Possible Scenarios:\n",
      "\n",
      "Let's denote the roles as follows:\n",
      "- T = Truth-teller\n",
      "- L = Liar\n",
      "- A = Alternator\n",
      "\n",
      "We will evaluate all permutations of roles for the three characters (Amy, Bob, Charlie).\n",
      "\n",
      "**Possible Role Combinations**:\n",
      "1. Amy (T), Bob (L), Charlie (A)\n",
      "2. Amy (T), Bob (A), Charlie (L)\n",
      "3. Amy (L), Bob (T), Charlie (A)\n",
      "4. Amy (L), Bob (A), Charlie (T)\n",
      "5. Amy (A), Bob (T), Charlie (L)\n",
      "6. Amy (A), Bob (L), Charlie (T)\n",
      "\n",
      "### Test Each Scenario:\n",
      "\n",
      "#### Scenario 1: Amy (T), Bob (L), Charlie (A)\n",
      "- **Amy** (T): \"Bob is a liar.\" (True)\n",
      "- **Bob** (L): \"Charlie alternates.\" (False, Charlie does not alternate; he is A)\n",
      "- **Charlie** (A): \"Amy and I are both liars.\" (Alternates, so he could say this as true or false)\n",
      "\n",
      "**Inconsistency**: Bob’s statement contradicts the fact he is a liar. This scenario does not hold.\n",
      "\n",
      "#### Scenario 2: Amy (T), Bob (A), Charlie (L)\n",
      "- **Amy** (T): \"Bob is a liar.\" (True)\n",
      "- **Bob** (A): \"Charlie alternates.\" (This could be True or False, but Charlie is L)\n",
      "- **Charlie** (L): \"Amy and I are both liars.\" (False, as Amy is T)\n",
      "\n",
      "**Inconsistency**: Charlie's statement contradicts Amy's truth. This scenario does not hold.\n",
      "\n",
      "#### Scenario 3: Amy (L), Bob (T), Charlie (A)\n",
      "- **Amy** (L): \"Bob is a liar.\" (False, Bob is T)\n",
      "- **Bob** (T): \"Charlie alternates.\" (True)\n",
      "- **Charlie** (A): \"Amy and I are both liars.\" (Could say true or false)\n",
      "\n",
      "**Inconsistency**: Amy's statement contradicts her being a liar. This scenario does not hold.\n",
      "\n",
      "#### Scenario 4: Amy (L), Bob (A), Charlie (T)\n",
      "- **Amy** (L): \"Bob is a liar.\" (False)\n",
      "- **Bob** (A): \"Charlie alternates.\" (Alternates, could be either True or False)\n",
      "- **Charlie** (T): \"Amy and I are both liars.\" (False, as Charlie is T)\n",
      "\n",
      "**Inconsistency**: Charlie's truthfulness contradicts his statement. This scenario does not hold.\n",
      "\n",
      "#### Scenario 5: Amy (A), Bob (T), Charlie (L)\n",
      "- **Amy** (A): \"Bob is a liar.\" (Could alternate)\n",
      "- **Bob** (T): \"Charlie alternates.\" (False, Charlie is L)\n",
      "- **Charlie** (L): \"Amy and I are both liars.\" (False, since Amy is A)\n",
      "\n",
      "**Inconsistency**: Bob's statement being True contradicts Charlie's role. This scenario does not hold.\n",
      "\n",
      "#### Scenario 6: Amy (A), Bob (L), Charlie (T)\n",
      "- **Amy** (A): \"Bob is a liar.\" (Could say true or false)\n",
      "- **Bob** (L): \"Charlie alternates.\" (False)\n",
      "- **Charlie** (T): \"Amy and I are both liars.\" (False)\n",
      "\n",
      "**Consistency**: This scenario holds. Bob is indeed a liar, and Charlie is telling the truth.\n",
      "\n",
      "### Eliminate Inconsistent Scenarios:\n",
      "\n",
      "From our testing:\n",
      "- Scenarios 1, 2, 3, 4, and 5 all led to contradictions.\n",
      "- Only Scenario 6 remains consistent.\n",
      "\n",
      "### Conclude the Solution:\n",
      "\n",
      "After analyzing all scenarios, the consistent roles identified are:\n",
      "- **Amy**: Alternator (A)\n",
      "- **Bob**: Liar (L)\n",
      "- **Charlie**: Truth-teller (T)\n",
      "\n",
      "### Provide a Clear Answer:\n",
      "\n",
      "**Final Roles**:\n",
      "- Amy is the Alternator.\n",
      "- Bob is the Liar.\n",
      "- Charlie is the Truth-teller.\n",
      "\n",
      "This is the only possible solution based on the analysis, as all other combinations resulted in contradictions.\n"
     ]
    }
   ],
   "source": [
    "# Define the prompt template\n",
    "logical_reasoning_prompt = PromptTemplate(\n",
    "    input_variables=[\"scenario\"],\n",
    "    template=\"\"\"Analyze the following logical puzzle thoroughly. Follow these steps in your analysis:\n",
    "\n",
    "List the Facts:\n",
    "\n",
    "Summarize all the given information and statements clearly.\n",
    "Identify all the characters or elements involved.\n",
    "Identify Possible Roles or Conditions:\n",
    "\n",
    "Determine all possible roles, behaviors, or states applicable to the characters or elements (e.g., truth-teller, liar, alternator).\n",
    "Note the Constraints:\n",
    "\n",
    "Outline any rules, constraints, or relationships specified in the puzzle.\n",
    "Generate Possible Scenarios:\n",
    "\n",
    "Systematically consider all possible combinations of roles or conditions for the characters or elements.\n",
    "Ensure that all permutations are accounted for.\n",
    "Test Each Scenario:\n",
    "\n",
    "For each possible scenario:\n",
    "Assume the roles or conditions you've assigned.\n",
    "Analyze each statement based on these assumptions.\n",
    "Check for consistency or contradictions within the scenario.\n",
    "Eliminate Inconsistent Scenarios:\n",
    "\n",
    "Discard any scenarios that lead to contradictions or violate the constraints.\n",
    "Keep track of the reasoning for eliminating each scenario.\n",
    "Conclude the Solution:\n",
    "\n",
    "Identify the scenario(s) that remain consistent after testing.\n",
    "Summarize the findings.\n",
    "Provide a Clear Answer:\n",
    "\n",
    "State definitively the role or condition of each character or element.\n",
    "Explain why this is the only possible solution based on your analysis.\n",
    "Scenario:\n",
    "\n",
    "{scenario}\n",
    "\n",
    "Analysis:\"\"\")\n",
    "\n",
    "# Pipe the prompt into the language model to create a logical reasoning chain\n",
    "logical_reasoning_chain = logical_reasoning_prompt | llm\n",
    "\n",
    "# Define a logucal challenging question to test the prompt\n",
    "logical_puzzle = \"\"\"In a room, there are three people: Amy, Bob, and Charlie.\n",
    "One of them always tells the truth, one always lies, and one alternates between truth and lies.\n",
    "Amy says, 'Bob is a liar.'\n",
    "Bob says, 'Charlie alternates between truth and lies.'\n",
    "Charlie says, 'Amy and I are both liars.'\n",
    "Determine the nature (truth-teller, liar, or alternator) of each person.\"\"\"\n",
    "\n",
    "# Invoke the logical reasoning chain\n",
    "logical_reasoning_response = logical_reasoning_chain.invoke(logical_puzzle).content\n",
    "print(logical_reasoning_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lFOT01U9YXgc"
   },
   "source": [
    "1. Define the prompt template: The `logical_reasoning_prompt` is a CoT prompt template that guides the model through the logical puzzle. This template breaks down the problem into a structured series of steps, ensuring the model does not just give an answer, but explains the reasoning behind its solution.\n",
    "   - The **facts** are listed first, helping the model clarify what information is provided.\n",
    "   - The **roles** are considered next (truth-teller, liar, alternator), which is a critical part of solving the puzzle.\n",
    "   - The **constraints** are noted, which describe how each role behaves.\n",
    "   - The model then **generates all possible scenarios**, assuming different roles for Amy, Bob, and Charlie.\n",
    "   - Each **scenario is tested** by analyzing the statements made by each individual based on the assumed roles.\n",
    "   - **Inconsistent scenarios** are eliminated (for example, if a contradiction arises when assuming someone is the truth-teller, that scenario is discarded).\n",
    "   - Finally, the model **concludes the solution** by identifying the correct roles and explaining why those are the only valid solutions.\n",
    "\n",
    "2. Create the chain: The next line creates the `logical_reasoning_chain` by combining the `logical_reasoning_prompt` with the language model (`llm`). This chain enables the model to apply the reasoning process described in the prompt template to the puzzle.\n",
    "3. Define the puzzle: The `logical_puzzle` variable holds the actual puzzle text. It describes the scenario which the model will analyze.\n",
    "4. Invoke the chain: The next line invokes the `logical_reasoning_chain` on the puzzle, causing the model to follow the reasoning process outlined in the template and analyze the puzzle. The `.content` extracts the text of the model's response, which will include the logical steps and the final answer."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
