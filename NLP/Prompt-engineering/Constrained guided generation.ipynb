{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QXdFgITQNerI"
   },
   "source": [
    "# Constrained and guided generation with language models\n",
    "\n",
    "This notebook explores the concepts of constrained and guided generation using large language models. Instead of letting the model freely generate text, we structure and restrict the generation process to produce more precise, rule-abiding, and goal-oriented outputs.\n",
    "\n",
    "While LLMs like GPT are flexible and creative, that flexibility can sometimes be a drawback. Left to generate text freely, the model may:\n",
    "- Drift off-topic.\n",
    "- Produce verbose or inconsistent content.\n",
    "- Fail to meet specific format or length requirements.\n",
    "- Can be too creative when we need something structured.\n",
    "\n",
    "This becomes especially problematic in real-world use cases where consistency, structure, and clarity are essential â€” such as in product descriptions, job postings, data extraction, and UI text generation.\n",
    "\n",
    "This is where constrained generation shines â€” it helps us steer the model with a clear format, rules, and validation mechanisms. This approach not only improves the usability and accuracy of the generated text, but also makes LLMs better suited for integration into structured workflows and applications where format adherence is non-negotiable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "snjYGSaoNWLp"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.output_parsers import RegexParser\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Set up the OpenAI API key\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tkp64TwbNlBF"
   },
   "source": [
    "### Initialize the language model\n",
    "We instantiate a lightweight GPT model from OpenAI using LangChain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "jojIGs4eNkEy"
   },
   "outputs": [],
   "source": [
    "# Initialize the language model\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini-2024-07-18\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9gfPiPnhNj2P"
   },
   "source": [
    "We will also define a helper function to neatly display outputs from the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "CkvNCOEJNjpJ"
   },
   "outputs": [],
   "source": [
    "# Function to display model outputs\n",
    "def display_output(output):\n",
    "    \"\"\"Display the model's output in a formatted manner.\"\"\"\n",
    "    print(\"Model Output:\")\n",
    "    print(\"-\" * 40)\n",
    "    print(output)\n",
    "    print(\"-\" * 40)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3PQbMGBANjbB"
   },
   "source": [
    "## Setting up constraints for model outputs\n",
    "The primary goal of constrained generation is to provide the model with a clear structure and specific guidelines that help produce outputs aligned with predefined requirements. This technique is particularly valuable when we need to generate text that adheres to certain formats or constraints, such as word count, tone, or specific content elements.\n",
    "\n",
    "In this section, we will start by demonstrating how to create a constrained prompt that generates a product description with specific requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "9UUpaBNSNjLt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Output:\n",
      "----------------------------------------\n",
      "**Stay Hydrated, Stay Awesome!**  \n",
      "\n",
      "Meet your new hydration buddy! This smart water bottle tracks your intake, reminds you to drink up, and syncs with your favorite health apps. Made from eco-friendly materials, it keeps your drinks cold or hot for hours. Ready to level up your hydration game? Grab yours today and toast to your health! ðŸ¥¤âœ¨\n",
      "----------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define a prompt that constrains the model to follow a specific structure and tone\n",
    "constrained_prompt = PromptTemplate(\n",
    "    input_variables=[\"product\", \"target_audience\", \"tone\", \"word_limit\"],\n",
    "    template=\"\"\"Create a product description for {product} targeted at {target_audience}.\n",
    "    Use a {tone} tone and keep it under {word_limit} words.\n",
    "    The description should include:\n",
    "    1. A catchy headline\n",
    "    2. Three key features\n",
    "    3. A call to action\n",
    "\n",
    "    Product Description:\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# Input variables that will be used to fill in the prompt template\n",
    "input_variables = {\n",
    "    \"product\": \"smart water bottle\",\n",
    "    \"target_audience\": \"health-conscious millennials\",\n",
    "    \"tone\": \"casual and friendly\",\n",
    "    \"word_limit\": \"75\"\n",
    "}\n",
    "\n",
    "# Chain the prompt with the language model\n",
    "chain = constrained_prompt | llm\n",
    "# Generate the constrained output\n",
    "output = chain.invoke(input_variables).content\n",
    "display_output(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dAigj0q5VL7p"
   },
   "source": [
    "This section introduces a constrained prompt template designed to generate a short and targeted product description. The goal is to guide the language model toward producing output that satisfies explicit structural and stylistic constraints.\n",
    "- Prompt structuring: The prompt specifies the expected components of the output (headline, features, call to action), as well as stylistic constraints such as tone and word count. This serves to narrow the modelâ€™s generative scope and reduce variance.\n",
    "- Templated input: By using `PromptTemplate`, the content becomes dynamic and reusable. Input values can be easily modified to support different use cases without changing the underlying prompt logic.\n",
    "- Prompt chaining: The prompt is combined with the language model using the LangChain operator (`|`) to form a processing pipeline. This composition allows the prompt to act as a pre-processor to the LLM.\n",
    "- Controlled generation: The `.invoke()` method executes the chain, passing in specific input values and retrieving the modelâ€™s response. The output adheres to the structure and tone defined in the prompt.\n",
    "\n",
    "This technique is particularly valuable in scenarios where outputs must follow predefined business rules, maintain a specific voice, or fit within a strict formatâ€”such as product copy, summaries, UI text, or catalog entries. By formalizing the output requirements within the prompt itself, this approach offers a simple but powerful way to ensure content quality and consistency in LLM-driven workflows.\n",
    "\n",
    "\n",
    "## Implementing rule-based generation\n",
    "In many real-world applications, it is not enough for a language model to simply generate fluent or creative text â€” the output often needs to follow specific rules or formatting conventions. This is where rule-based generation becomes essential.\n",
    "\n",
    "In this section, we implement a generation system that produces structured job postings based on clearly defined constraints. By encoding rules directly into the prompt â€” such as formatting, required sections, and sentence structure â€” we ensure the output is consistent, predictable, and easy to parse.\n",
    "\n",
    "This approach is particularly useful when outputs are consumed by other systems or need to adhere to regulatory or editorial standards. It enables greater control over the language model's behavior while preserving its generative capabilities.\n",
    "\n",
    "The following code demonstrates how to use LangChainâ€™s `PromptTemplate` to design and apply a rule-based prompt that guides the model to generate a formatted job description with clearly delineated sections and standardized language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "7QKufcs3Nisx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Output:\n",
      "----------------------------------------\n",
      "COMPANY: TechInnovate Solutions is a leading technology firm based in San Francisco, CA, dedicated to delivering cutting-edge software solutions that drive innovation and efficiency for our clients. We foster a collaborative and dynamic work environment that encourages creativity and professional growth.\n",
      "\n",
      "RESPONSIBILITIES:\n",
      "- Design and implement scalable software solutions that meet business requirements.\n",
      "- Collaborate with cross-functional teams to define, design, and ship new features.\n",
      "- Mentor junior engineers and contribute to their professional development.\n",
      "- Conduct code reviews to ensure high-quality standards and best practices.\n",
      "- Troubleshoot and debug applications to optimize performance and reliability.\n",
      "\n",
      "QUALIFICATIONS:\n",
      "- A minimum of 5 years of experience in software development with a strong portfolio of completed projects. \n",
      "- Proficiency in at least one programming language, such as Java, Python, or JavaScript. \n",
      "- Experience with cloud services like AWS, Google Cloud, or Azure is highly desirable. \n",
      "- Strong understanding of software development methodologies, including Agile and DevOps practices. \n",
      "- Excellent problem-solving skills and the ability to work effectively in a team-oriented environment.\n",
      "\n",
      "EEO: TechInnovate Solutions is an equal opportunity employer and values diversity. We do not discriminate based on race, color, religion, gender, sexual orientation, national origin, age, disability, or any other legally protected status.\n",
      "----------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define a prompt for generating structured job postings based on explicit formatting rules\n",
    "job_posting_prompt = PromptTemplate(\n",
    "    input_variables=[\"job_title\", \"company\", \"location\", \"experience\"],\n",
    "    template=\"\"\"Create a job posting for a {job_title} position at {company} in {location}.\n",
    "    The candidate should have {experience} years of experience.\n",
    "    Follow these rules:\n",
    "    1. Start with a brief company description (2 sentences)\n",
    "    2. List 5 key responsibilities, each starting with an action verb\n",
    "    3. List 5 required qualifications, each in a single sentence\n",
    "    4. End with a standardized equal opportunity statement\n",
    "\n",
    "    Format the output as follows:\n",
    "    COMPANY: [Company Description]\n",
    "\n",
    "    RESPONSIBILITIES:\n",
    "    - [Responsibility 1]\n",
    "    - [Responsibility 2]\n",
    "    - [Responsibility 3]\n",
    "    - [Responsibility 4]\n",
    "    - [Responsibility 5]\n",
    "\n",
    "    QUALIFICATIONS:\n",
    "    - [Qualification 1]\n",
    "    - [Qualification 2]\n",
    "    - [Qualification 3]\n",
    "    - [Qualification 4]\n",
    "    - [Qualification 5]\n",
    "\n",
    "    EEO: [Equal Opportunity Statement]\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# Define the specific input values for the generation task\n",
    "input_variables = {\n",
    "    \"job_title\": \"Senior Software Engineer\",\n",
    "    \"company\": \"TechInnovate Solutions\",\n",
    "    \"location\": \"San Francisco, CA\",\n",
    "    \"experience\": \"5+\"\n",
    "}\n",
    "\n",
    "# Chain the prompt with the LLM and invoke it to generate the output\n",
    "chain = job_posting_prompt | llm\n",
    "output = chain.invoke(input_variables).content\n",
    "display_output(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qCHeUaeiWHxJ"
   },
   "source": [
    "This section demonstrates how to implement rule-based generation by embedding explicit structural and content rules into the prompt. The objective is to guide the language model to output a job posting that adheres to a predefined schema â€” suitable for automated pipelines or downstream systems requiring structured content.\n",
    "- Prompt as specification: The prompt doubles as both an instruction and a formatting template. By describing exact rules (e.g. â€œ5 responsibilitiesâ€, â€œ1 sentence eachâ€), it constrains the output shape and helps reduce variability and noise in the model's response.\n",
    "- Structured formatting: The use of consistent headings (`COMPANY:`, `RESPONSIBILITIES:`, etc.) makes the output easier to parse programmatically. This becomes critical when generating content for applications such as automated publishing systems, resume screeners, or HR platforms.\n",
    "- Input-driven generation: The use of templated variables (`job_title`, `location`, etc.) allows this prompt to be reused flexibly for different job roles or organizations, supporting scalable content generation.\n",
    "- Prompt chaining and invocation: The prompt is connected to the language model using LangChain's composability operator (`|`), forming a generation chain. The `.invoke()` method is then used to produce the response from the LLM based on the specified inputs.\n",
    "- Use case alignment: This approach ensures not just grammatical correctness but also conformance to business logic, which is crucial in many enterprise applications where freeform text generation can lead to formatting errors or policy violations.\n",
    "\n",
    "By clearly encoding both the structure and the output requirements into the prompt, this method ensures reliable, repeatable, and interpretable results from a generative model â€” effectively bridging the gap between open-ended generation and production-grade structured content.\n",
    "\n",
    "\n",
    "## Using regex parser for structured output\n",
    "When working with LLM outputs, especially those intended for downstream processing or integration, itâ€™s important not only to guide the generation format, but also to verify and extract specific parts of the output programmatically.\n",
    "\n",
    "This is where regular expression (regex) parsing becomes useful. In this section, we demonstrate how to apply a `RegexParser` from LangChain to extract structured components from model output â€” ensuring that the generated text conforms to a predefined schema.\n",
    "\n",
    "By combining a structured prompt format with a regex-based parser, we move closer to reliable, machine-readable generations â€” a crucial step for tasks like report generation, automated documentation, and form filling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "uXI6M4K6Nh_y"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed Output:\n",
      "COMPANY_DESCRIPTION:\n",
      "TechInnovate Solutions is a leading technology firm based in San Francisco, CA, specializing in cutting-edge software development and innovative technology solutions. Our mission is to empower businesses through advanced technology that drives efficiency and growth.\n",
      "\n",
      "RESPONSIBILITIES:\n",
      "- Design and implement scalable software solutions to enhance user experience.\n",
      "- Collaborate with cross-functional teams to define project requirements and specifications.\n",
      "- Mentor junior engineers and foster a culture of continuous improvement and learning.\n",
      "- Conduct code reviews to ensure quality and adherence to best practices.\n",
      "- Troubleshoot and resolve complex technical issues in a timely manner.\n",
      "\n",
      "QUALIFICATIONS:\n",
      "- A minimum of 5 years of professional software engineering experience is required.\n",
      "- Proficiency in programming languages such as Java, Python, or JavaScript is essential.\n",
      "- Experience with cloud platforms such as AWS, Azure, or Google Cloud is preferred.\n",
      "- Strong understanding of software development methodologies and agile practices is necessary.\n",
      "- Excellent problem-solving skills and the ability to work independently in a fast-paced environment are a must.\n",
      "\n",
      "EEO_STATEMENT:\n",
      "TechInnovate Solutions is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all employees.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define a regex parser to extract structured sections from the model's output\n",
    "regex_parser = RegexParser(\n",
    "    regex=r\"COMPANY:\\s*([\\s\\S]*?)\\n\\s*RESPONSIBILITIES:\\s*([\\s\\S]*?)\\n\\s*QUALIFICATIONS:\\s*([\\s\\S]*?)\\n\\s*EEO:\\s*([\\s\\S]*)\",\n",
    "    output_keys=[\"company_description\", \"responsibilities\", \"qualifications\", \"eeo_statement\"]\n",
    ")\n",
    "# This regex pattern captures the company description, responsibilities, qualifications, and EEO statement from the output text.\n",
    "\n",
    "# Create a prompt that enforces strict formatting in the model's output\n",
    "parsed_job_posting_prompt = PromptTemplate(\n",
    "    input_variables=[\"job_title\", \"company\", \"location\", \"experience\"],\n",
    "    template=\"\"\"Create a job posting for a {job_title} position at {company} in {location}.\n",
    "    The candidate should have {experience} years of experience.\n",
    "    Follow these rules:\n",
    "    1. Start with a brief company description (2 sentences)\n",
    "    2. List 5 key responsibilities, each starting with an action verb\n",
    "    3. List 5 required qualifications, each in a single sentence\n",
    "    4. End with a standardized equal opportunity statement\n",
    "\n",
    "    Format the output EXACTLY as follows:\n",
    "    COMPANY: [Company Description]\n",
    "\n",
    "    RESPONSIBILITIES:\n",
    "    - [Responsibility 1]\n",
    "    - [Responsibility 2]\n",
    "    - [Responsibility 3]\n",
    "    - [Responsibility 4]\n",
    "    - [Responsibility 5]\n",
    "\n",
    "    QUALIFICATIONS:\n",
    "    - [Qualification 1]\n",
    "    - [Qualification 2]\n",
    "    - [Qualification 3]\n",
    "    - [Qualification 4]\n",
    "    - [Qualification 5]\n",
    "\n",
    "    EEO: [Equal Opportunity Statement]\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# Helper function to clean the parsed output (strip whitespace, normalize line breaks)\n",
    "def clean_output(output):\n",
    "    for key, value in output.items():\n",
    "        if isinstance(value, str):\n",
    "            # Remove leading/trailing whitespace and normalize newlines\n",
    "            output[key] = re.sub(r'\\n\\s*', '\\n', value.strip())\n",
    "    return output\n",
    "\n",
    "# Generate the output from the model using the structured job posting prompt\n",
    "chain = parsed_job_posting_prompt | llm\n",
    "raw_output = chain.invoke(input_variables).content\n",
    "\n",
    "# Parse the model's response using the defined regex pattern\n",
    "parsed_output = regex_parser.parse(raw_output)\n",
    "# Clean and normalize the extracted content\n",
    "cleaned_output = clean_output(parsed_output)\n",
    "\n",
    "# Display each section in a readable format\n",
    "print(\"Parsed Output:\")\n",
    "for key, value in cleaned_output.items():\n",
    "    print(f\"{key.upper()}:\")\n",
    "    print(value)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B7auy9RGZYnC"
   },
   "source": [
    "1. Regex definition: A `RegexParser` is created with a custom pattern to extract four expected sections from the generated text. The pattern looks for labeled blocks â€” `COMPANY`, `RESPONSIBILITIES`, `QUALIFICATIONS`, and `EEO` â€” and captures everything under each header using non-greedy matches.\n",
    "2. Prompt enforcement: The `PromptTemplate` enforces exact formatting instructions for the language model. This ensures the output will contain the sections in a predictable order, which makes the regex parsing reliable.\n",
    "3. Text generation: The model is invoked with the formatted prompt and job-related input variables. The generated output is expected to follow the given format exactly.\n",
    "4. Parsing and cleaning: The raw model output is parsed using the regex, extracting each section into a dictionary. The `clean_output` function is then used to trim whitespace and normalize line breaks for cleaner presentation and easier downstream processing.\n",
    "5. Output presentation: Finally, each extracted section is printed in uppercase, mimicking structured display formatting that could be further exported or logged.\n",
    "\n",
    "This method demonstrates a powerful pattern in constrained generation: combining prompt-level control with post-generation validation and parsing. It enhances the reliability of LLMs in structured content generation tasks, especially when the outputs must be consumed by other systems or meet compliance standards."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BkIOYEV0Ng-D"
   },
   "source": [
    "## Implementing additional constraints\n",
    "This section demonstrates how to define multi-layered constraints in a text generation task. By embedding multiple detailed requirements into the prompt, it is possible to guide the language model toward producing tightly structured outputs with specific form, style, and content limits.\n",
    "\n",
    "This technique is particularly useful for tasks like review generation, summarization, or template-based content creation, where both layout and semantics must follow well-defined rules. By explicitly enumerating expectations â€” such as content count, sentence length, tone, or word count â€” the prompt becomes a robust instruction set for the model to follow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "R0ZkGH1iNgug"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Output:\n",
      "----------------------------------------\n",
      "Rating: 4 out of 5 stars\n",
      "\n",
      "Pros:\n",
      "1. The camera quality on Smartphone X is impressive, capturing vibrant and detailed images even in low light. The advanced features like night mode and optical zoom elevate photography to a professional level.\n",
      "2. Battery life is outstanding, lasting a full day with heavy usage. Quick charging capabilities also mean you can get back to using your phone without long waits.\n",
      "3. The sleek design and high-quality display make using the Smartphone X a pleasure. The vibrant colors and sharp resolution enhance everything from gaming to streaming videos.\n",
      "\n",
      "Cons:\n",
      "1. The price point is a bit high compared to similar models on the market, which may deter budget-conscious buyers. While it offers great features, some might find better value elsewhere.\n",
      "2. The lack of expandable storage can be limiting for users who store a lot of media. This could lead to potential frustrations as the device fills up quickly.\n",
      "\n",
      "Recommendation: Overall, Smartphone X is a solid choice for those seeking a high-performance device with excellent camera capabilities.\n",
      "----------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a prompt template with detailed constraints for a structured product review\n",
    "review_prompt = PromptTemplate(\n",
    "    input_variables=[\"product\", \"rating\", \"pros\", \"cons\", \"word_limit\"],\n",
    "    template=\"\"\"Write a product review for {product} with the following constraints:\n",
    "    1. The review should have a {rating}-star rating (out of 5)\n",
    "    2. Include exactly {pros} pros and {cons} cons\n",
    "    3. Use between 2 and 3 sentences for each pro and con\n",
    "    4. The entire review should be under {word_limit} words\n",
    "    5. End with a one-sentence recommendation\n",
    "\n",
    "    Format the review as follows:\n",
    "    Rating: [X] out of 5 stars\n",
    "\n",
    "    Pros:\n",
    "    1. [Pro 1]\n",
    "    2. [Pro 2]\n",
    "    ...\n",
    "\n",
    "    Cons:\n",
    "    1. [Con 1]\n",
    "    2. [Con 2]\n",
    "    ...\n",
    "\n",
    "    Recommendation: [One-sentence recommendation]\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# Define specific inputs for the review\n",
    "input_variables = {\n",
    "    \"product\": \"Smartphone X\",      # Product name\n",
    "    \"rating\": \"4\",                  # Star rating\n",
    "    \"pros\": \"3\",                    # Number of pros to include\n",
    "    \"cons\": \"2\",                    # Number of cons to include\n",
    "    \"word_limit\": \"200\"            # Maximum allowed word count\n",
    "}\n",
    "\n",
    "# Build the chain: prompt -> LLM\n",
    "chain = review_prompt | llm\n",
    "# Invoke the chain and get the model's output\n",
    "output = chain.invoke(input_variables).content\n",
    "# Display the generated review\n",
    "display_output(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8wN3U5WNNgd4"
   },
   "source": [
    "1. Prompt construction with multi-step constraints: The prompt includes detailed rules governing the structure, quantity, and length of the generated review content. The constraints apply not only to the sections (e.g., number of pros and cons), but also to the sentence count per item and total word count. A clear format is enforced so the model knows exactly how to arrange its output.\n",
    "2. Input customization: The dictionary `input_variables` defines the parameters for a particular product review. This makes the template reusable â€” the same prompt logic can be applied to any product by simply changing the inputs.\n",
    "3. Chain execution: The prompt is connected to the language model via a LangChain `Runnable` (represented by `| llm`), and the final output is generated using `.invoke()` with the defined parameters.\n",
    "\n",
    "This example illustrates how to simulate programmatic control over free-form generation by using prompt engineering alone â€” no post-processing or external validators are needed to enforce rules. With clear formatting and quantified constraints, models like GPT can reliably produce content that fits highly structured specifications.\n",
    "\n",
    "This technique can be extended to more complex domains, such as report generation, automated assessments, or personalized recommendations â€” any case where the output must satisfy a format contract or domain-specific checklist."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
