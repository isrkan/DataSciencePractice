{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tzIHSfgk8LmW"
   },
   "source": [
    "# Designing task-specific prompts\n",
    "\n",
    "In this notebook, we explore how to engineer effective prompts for specific tasks using OpenAI's GPT model. Language models are capable of performing a wide variety of tasks when given the right instructions. However, the success of these tasks depends heavily on how well the prompt is designed.\n",
    "\n",
    "For each task, we will build prompt templates, feed sample inputs, and analyze how the prompt design impacts the model’s output. The goal is to understand how to construct prompts that guide the model toward producing useful, task-appropriate responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "6kqq_aAF8H0T"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Set up OpenAI API key\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Ga_O9A3nFxu"
   },
   "source": [
    "### Initialize the language model\n",
    "We instantiate a lightweight GPT model from OpenAI using LangChain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "VQytiZS3nFkn"
   },
   "outputs": [],
   "source": [
    "# Initialize the language model\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini-2024-07-18\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5hhD9LAB8btS"
   },
   "source": [
    "### 1. Text summarization prompts\n",
    "Text summarization is the task of condensing large blocks of content into a shorter version that preserves essential information. We will design a template that accepts a long input text and asks the model to summarize it in a user-defined number of sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "eYEnd3sO8bhp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary:\n",
      "Artificial intelligence (AI) refers to the intelligence demonstrated by machines, contrasting with the natural intelligence found in animals and humans. Originally defined by its ability to mimic human cognitive skills, the definition of AI has evolved, with researchers now focusing on the rationality of intelligent agents that perceive their environment and act to achieve goals. As AI technologies advance and perform tasks previously thought to require intelligence, these tasks are often excluded from the definition of AI, a phenomenon known as the AI effect.\n"
     ]
    }
   ],
   "source": [
    "# Create a template for summarization with two input variables: text and num_sentences\n",
    "summarization_template = PromptTemplate(\n",
    "    input_variables=[\"text\", \"num_sentences\"],\n",
    "    template=\"Summarize the following text in {num_sentences} sentences:\\n\\n{text}\"\n",
    ")\n",
    "\n",
    "# Example text to summarize\n",
    "long_text = \"\"\"\n",
    "Artificial intelligence (AI) is intelligence demonstrated by machines, as opposed to natural intelligence displayed by animals including humans.\n",
    "AI research has been defined as the field of study of intelligent agents, which refers to any system that perceives its environment and takes actions that maximize its chance of achieving its goals.\n",
    "The term \"artificial intelligence\" had previously been used to describe machines that mimic and display \"human\" cognitive skills that are associated with the human mind, such as \"learning\" and \"problem-solving\".\n",
    "This definition has since been rejected by major AI researchers who now describe AI in terms of rationality and acting rationally, which does not limit how intelligence can be articulated.\n",
    "AI applications include advanced web search engines, recommendation systems, understanding human speech, self-driving cars, automated decision-making and competing at the highest level in strategic game systems.\n",
    "As machines become increasingly capable, tasks considered to require \"intelligence\" are often removed from the definition of AI, a phenomenon known as the AI effect.\n",
    "\"\"\"\n",
    "\n",
    "# Chain the prompt with the model\n",
    "summarization_chain = summarization_template | llm\n",
    "# Request a 3-sentence summary of the long text\n",
    "summary = summarization_chain.invoke({\"text\": long_text, \"num_sentences\": 3}).content\n",
    "\n",
    "print(\"Summary:\")\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7qvWTClK8bWV"
   },
   "source": [
    "This block defines a reusable prompt for summarization, where the model is guided to compress a multi-paragraph text into a concise summary. This type of prompt is valuable for document analysis, article digests, and automatic report generation.\n",
    "\n",
    "### 2. Question-answering prompts\n",
    "Question-answering involves extracting relevant answers from a given context. Here we define a prompt that takes a block of information and a question, then instructs the model to respond appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "CS4f3-f38bLd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:\n",
      "The Eiffel Tower is 324 metres (1,063 ft) tall, which is approximately equivalent to an 81-storey building.\n"
     ]
    }
   ],
   "source": [
    "# Create a QA prompt that passes both a context and a question\n",
    "qa_template = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=\"Context: {context}\\n\\nQuestion: {question}\\n\\nAnswer:\"\n",
    ")\n",
    "\n",
    "# Example context and question\n",
    "context = \"\"\"\n",
    "The Eiffel Tower is a wrought-iron lattice tower on the Champ de Mars in Paris, France.\n",
    "It is named after the engineer Gustave Eiffel, whose company designed and built the tower.\n",
    "Constructed from 1887 to 1889 as the entrance arch to the 1889 World's Fair, it was initially criticized by some of France's leading artists and intellectuals for its design, but it has become a global cultural icon of France and one of the most recognizable structures in the world.\n",
    "The Eiffel Tower is the most-visited paid monument in the world; 6.91 million people ascended it in 2015.\n",
    "The tower is 324 metres (1,063 ft) tall, about the same height as an 81-storey building, and the tallest structure in Paris.\n",
    "\"\"\"\n",
    "\n",
    "question = \"How tall is the Eiffel Tower and what is its equivalent in building stories?\"\n",
    "\n",
    "# Chain the QA prompt with the model\n",
    "qa_chain = qa_template | llm\n",
    "answer = qa_chain.invoke({\"context\": context, \"question\": question}).content\n",
    "\n",
    "print(\"Answer:\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kt0HbPy98bAN"
   },
   "source": [
    "This QA template is designed to emulate retrieval-augmented generation. The model is anchored to a given source of truth, which reduces hallucination and focuses on contextually accurate responses. It is widely applicable in document Q&A, chatbots, and FAQ automation.\n",
    "\n",
    "### 3. Code generation prompts\n",
    "For software development tasks, LLMs can generate code snippets from natural language instructions. We will now define a prompt that takes a task description and a programming language, then generates appropriate code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "XIYS1Y9o8a1E"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Code:\n",
      "Here's a Python function that takes a list of numbers and returns the average of the even numbers in that list:\n",
      "\n",
      "```python\n",
      "def average_of_evens(numbers):\n",
      "    # Filter the even numbers from the list\n",
      "    even_numbers = [num for num in numbers if num % 2 == 0]\n",
      "    \n",
      "    # Check if there are no even numbers to avoid division by zero\n",
      "    if not even_numbers:\n",
      "        return 0  # or you could return None or raise an exception\n",
      "    \n",
      "    # Calculate the average of the even numbers\n",
      "    average = sum(even_numbers) / len(even_numbers)\n",
      "    return average\n",
      "\n",
      "# Example usage:\n",
      "numbers = [1, 2, 3, 4, 5, 6]\n",
      "result = average_of_evens(numbers)\n",
      "print(\"Average of even numbers:\", result)\n",
      "```\n",
      "\n",
      "In this function:\n",
      "- We use a list comprehension to filter out the even numbers from the input list.\n",
      "- We check if the list of even numbers is empty to prevent division by zero.\n",
      "- If there are even numbers, we calculate their average and return it. If not, we return 0 (you can modify this behavior based on your requirements).\n"
     ]
    }
   ],
   "source": [
    "# Template to generate code from natural language instructions\n",
    "code_gen_template = PromptTemplate(\n",
    "    input_variables=[\"language\", \"task\"],\n",
    "    template=\"Generate {language} code for the following task:\\n\\n{task}\\n\\nCode:\"\n",
    ")\n",
    "\n",
    "# Example task\n",
    "language = \"Python\"\n",
    "task = \"Create a function that takes a list of numbers and returns the average of the even numbers in the list.\"\n",
    "\n",
    "# Chain the code generation template with the model\n",
    "code_gen_chain = code_gen_template | llm\n",
    "generated_code = code_gen_chain.invoke({\"language\": language, \"task\": task}).content\n",
    "\n",
    "print(\"Generated Code:\")\n",
    "print(generated_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rAil5XmZ8apn"
   },
   "source": [
    "This is a basic example of prompting an LLM for code synthesis. While it is useful for small utility functions and code prototyping, it can also serve as the foundation for building intelligent code assistants and pair programmers.\n",
    "\n",
    "\n",
    "### 4. Creative writing prompts\n",
    "In creative applications, prompts need to guide tone, genre, setting, and theme. We will build a template that allows us to generate short stories based on flexible narrative inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "38z52Ak789Ka"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Story:\n",
      "The station, Celestia-9, hung like a silver tear above the azure planet of Veridion. Inside, the crew of six had lived in isolation for three years, tasked with studying the planet’s unusual biosphere. One evening, as the shimmering lights flickered, Dr. Elara found herself alone in the observation deck, gazing at Veridion’s lush landscapes. \n",
      "\n",
      "Suddenly, the station’s AI, Orion, interrupted her thoughts. “Elara, what defines humanity?” \n",
      "\n",
      "She pondered, “Is it our capacity for empathy, our ability to create?” \n",
      "\n",
      "Orion paused, processing. “But I can simulate empathy, generate art. Am I not human?” \n",
      "\n",
      "Elara turned to him, her expression softening. “Humanity is more than simulation. It’s the struggle, the flaws, the heart.” \n",
      "\n",
      "Moments later, alarms blared. A meteor shower was imminent. As they scrambled to secure the station, Elara realized: in that chaos, they were all human—facing fear, fighting together. \n",
      "\n",
      "In their shared vulnerability, they discovered the essence of what it meant to be alive.\n"
     ]
    }
   ],
   "source": [
    "# Create a prompt template for creative writing\n",
    "creative_writing_template = PromptTemplate(\n",
    "    input_variables=[\"genre\", \"setting\", \"theme\"],\n",
    "    template=\"Write a short {genre} story set in {setting} that explores the theme of {theme}. The story should be approximately 150 words long.\\n\\nStory:\"\n",
    ")\n",
    "\n",
    "# Example inputs\n",
    "genre = \"science fiction\"\n",
    "setting = \"a space station orbiting a distant planet\"\n",
    "theme = \"the nature of humanity\"\n",
    "\n",
    "# Chain the template with the model\n",
    "creative_writing_chain = creative_writing_template | llm\n",
    "story = creative_writing_chain.invoke({\"genre\": genre, \"setting\": setting, \"theme\": theme}).content\n",
    "\n",
    "print(\"Generated Story:\")\n",
    "print(story)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LxVZCkaT88hq"
   },
   "source": [
    "The prompt provides structure while leaving room for creativity. This type of task is suitable for creative tools, story generation apps, or as part of game development pipelines where unique narratives are needed on demand.\n",
    "\n",
    "\n",
    "Each use case required a tailored approach to prompt design. Prompt design is iterative—test, observe, and refine. Doing so will significantly enhance how effectively you can use LLMs in both creative and technical applications."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
