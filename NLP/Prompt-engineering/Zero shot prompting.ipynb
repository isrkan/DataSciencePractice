{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MIrikifec4zo"
   },
   "source": [
    "# Zero-shot prompting\n",
    "\n",
    "This notebook introduces zero-shot prompting, a powerful technique in prompt engineering that enables language models to perform tasks without being given any examples beforehand. Zero-shot prompting allows AI models to generalize across many different tasks with minimal setup and without the need for training or fine-tuning on specific examples. It’s effective, scalable, and easy to implement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "bzMi1sC_c0iS"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Set up OpenAI API key\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fvh3Y9qCc8RV"
   },
   "source": [
    "### Initialize the language model\n",
    "We instantiate a lightweight GPT model from OpenAI using LangChain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "-UVJOutdc8d5"
   },
   "outputs": [],
   "source": [
    "# Initialize the language model\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini-2024-07-18\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eCtL68QYc8qi"
   },
   "source": [
    "- `ChatOpenAI` from LangChain is used to interact with OpenAI's chat models.\n",
    "- We use `gpt-4o-mini` for fast and cost-efficient completions.\n",
    "\n",
    "### Direct task specification\n",
    "We now define a prompt that explicitly instructs the model to classify text sentiment, without providing any examples. This is a classic zero-shot setup: clear task description but no examples of how to complete it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "waN85xYic84G"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: I absolutely loved the movie! The acting was superb.\n",
      "Sentiment: Positive\n",
      "Text: The weather today is quite typical for this time of year.\n",
      "Sentiment: Neutral\n",
      "Text: I'm disappointed with the service I received at the restaurant.\n",
      "Sentiment: Negative\n"
     ]
    }
   ],
   "source": [
    "# Define the prompt\n",
    "direct_task_prompt = \"\"\"Classify the sentiment of the following text as positive, negative, or neutral.\n",
    "Do not explain your reasoning, just provide the classification.\n",
    "\n",
    "Text: {text}\n",
    "\n",
    "Sentiment:\"\"\"\n",
    "\n",
    "# Create a LangChain PromptTemplate from the string\n",
    "prompt = PromptTemplate.from_template(direct_task_prompt)\n",
    "# Create a prompt chain by connecting the prompt template to the language model\n",
    "direct_task_chain = prompt | llm\n",
    "\n",
    "# Test the direct task specification\n",
    "texts = [\n",
    "    \"I absolutely loved the movie! The acting was superb.\",\n",
    "    \"The weather today is quite typical for this time of year.\",\n",
    "    \"I'm disappointed with the service I received at the restaurant.\"\n",
    "]\n",
    "\n",
    "# Loop through the test texts and classify each one\n",
    "for text in texts:\n",
    "    result = direct_task_chain.invoke({\"text\": text}).content  # Pass the input text and get model output\n",
    "    print(f\"Text: {text}\")\n",
    "    print(f\"Sentiment: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n0BDVjtQc9Fm"
   },
   "source": [
    "We will use LangChain’s `PromptTemplate` to define a parameterized prompt, which will be dynamically filled in with different input texts. Then we will pass each completed prompt to the OpenAI model using a LangChain prompt chain.\n",
    "- The `{text}` placeholder makes the prompt reusable across different inputs.\n",
    "- `PromptTemplate.from_template(...)`: This converts the raw string into a structured prompt object, enabling variable substitution. In this case, we only have one variable: `text`.\n",
    "- Prompt Chain (`prompt | llm`): This constructs a LangChain pipeline where the input text is first inserted into the prompt, and the resulting prompt is then passed to the GPT model for generation. This sets up the pipeline: input text -> prompt template -> model.\n",
    "- We loop through different input texts and classify their sentiment.\n",
    "- The `invoke` method passes variables to the template and executes the model.\n",
    "\n",
    "# Format specification\n",
    "Next, we focus not just on what task the model should perform (writing a news article), but also on how the output should be structured. This type of prompting is known as format specification—an effective zero-shot technique where the prompt clearly defines the format or structure expected in the model’s response. We define a prompt that instructs the model to follow a specific output format: headline, lead, body, and conclusion. This improves consistency, readability, and control, especially when using outputs in downstream applications. This technique is especially useful in real-world applications where structured outputs are necessary—such as generating reports, summaries, blog drafts, or templates for automated communication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "NZyiw75_c9Rs"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Headline:** Astronomers Unveil New Earth-Like Exoplanet in Habitable Zone\n",
      "\n",
      "**Lead:** In a groundbreaking discovery, a team of astronomers has identified a new Earth-like exoplanet located within the habitable zone of its star, raising hopes for the potential of extraterrestrial life. Named Kepler-452d, this distant world is reminiscent of our own planet in size and atmospheric conditions, igniting excitement in the scientific community.\n",
      "\n",
      "**Body:** The exoplanet, located approximately 1,400 light-years away in the constellation Cygnus, is roughly 1.6 times the size of Earth and orbits its sun-like star in a region where temperatures could allow for liquid water to exist. Researchers utilized advanced telescopic technology and data analysis techniques to confirm its existence and assess its potential for supporting life.\n",
      "\n",
      "Further studies suggest that Kepler-452d has a rocky composition and may possess a similar atmosphere to Earth, making it an ideal candidate for future exploration. The discovery highlights the ongoing advancements in astrophysics and the quest to find habitable worlds beyond our solar system.\n",
      "\n",
      "**Conclusion:** As scientists continue to study Kepler-452d, the search for life beyond Earth takes on new urgency, reminding us of the vast possibilities that lie within the cosmos.\n"
     ]
    }
   ],
   "source": [
    "# Define a prompt template\n",
    "format_spec_prompt = \"\"\"Generate a short news article about {topic}.\n",
    "Structure your response in the following format:\n",
    "\n",
    "Headline: [A catchy headline for the article]\n",
    "\n",
    "Lead: [A brief introductory paragraph summarizing the key points]\n",
    "\n",
    "Body: [2-3 short paragraphs providing more details]\n",
    "\n",
    "Conclusion: [A concluding sentence or call to action]\"\"\"\n",
    "\n",
    "# Create a PromptTemplate from the raw template string\n",
    "prompt = PromptTemplate.from_template(format_spec_prompt)\n",
    "# Combine the prompt template with the language model into a chain\n",
    "format_spec_chain = prompt | llm\n",
    "\n",
    "# Test the format specification prompting\n",
    "topic = \"The discovery of a new earth-like exoplanet\"\n",
    "# Pass the topic into the chain and get the formatted output\n",
    "result = format_spec_chain.invoke({\"topic\": topic}).content\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hlaoFAkNc9dn"
   },
   "source": [
    "This prompt not only asks the model to write an article but explicitly defines four sections: `Headline`, `Lead`, `Body`, and `Conclusion`. This communicates clear formatting expectations to the model.\n",
    "- LangChain PromptTemplate: As in the previous example, `PromptTemplate.from_template(...)` is used to dynamically inject values—in this case, the `{topic}`—into the structured prompt.\n",
    "- Prompt chain: The chain `prompt | llm` links the formatted prompt to the GPT model, forming a callable pipeline for inference.\n",
    "- The model receives the full prompt and generates a news-style article, adhering to the requested structure.\n",
    "  \n",
    "Providing output format guidelines in the prompt can help structure the AI's response in a zero-shot scenario. By specifying output format, we gain control over not just the content of the model’s response but also its structure, which is often just as important.\n",
    "\n",
    "### Multi-step reasoning\n",
    "In this example, we apply a multi-step reasoning prompt—a structured technique that guides the language model to analyze complex content in a systematic way. Instead of asking for a generic response, the prompt explicitly breaks down the task into distinct steps: identifying the main argument, presenting supporting evidence, and considering possible counterarguments. This method enhances the reliability and depth of the model's response, especially for analytical tasks involving nuanced content or critical thinking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "GTih1xV3c9pb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. **Main Argument:** The primary claim of the text is that while electric vehicles (EVs) are promoted as a solution to climate change, their overall environmental impact is complex and potentially negative due to the consequences of battery production and the source of electricity used for charging.\n",
      "\n",
      "2. **Supporting Evidence:**\n",
      "   - The production of batteries for electric vehicles involves extensive mining operations, which can result in habitat destruction and water pollution.\n",
      "   - If the electricity used to charge electric vehicles is generated from fossil fuel sources, the reduction in carbon footprint may not be significant.\n",
      "   - There is potential for electric vehicles to contribute positively to climate change efforts as renewable energy sources become more widely adopted and battery technology advances.\n",
      "\n",
      "3. **Potential Counterarguments:**\n",
      "   - Advocates for electric vehicles might argue that, despite the environmental costs of battery production and fossil fuel electricity, EVs still typically have a lower overall carbon footprint compared to traditional gasoline vehicles over their entire lifecycle.\n",
      "   - Another counterargument could be that advancements in battery recycling and sustainable mining practices are being developed, which could mitigate the environmental impact of battery production.\n",
      "   - Supporters may also claim that the transition to renewable energy sources for electricity generation is already underway and may soon make the charging of EVs significantly cleaner.\n",
      "   - Some might argue that focusing solely on the drawbacks of electric vehicles distracts from the greater urgency of reducing greenhouse gas emissions and that transitioning to EVs is a necessary step in that direction.\n"
     ]
    }
   ],
   "source": [
    "# Define a prompt that guides the model to reason through multiple analytical steps\n",
    "multi_step_prompt = \"\"\"Analyze the following text for its main argument, supporting evidence, and potential counterarguments.\n",
    "Provide your analysis in the following steps:\n",
    "\n",
    "1. Main Argument: Identify and state the primary claim or thesis.\n",
    "2. Supporting Evidence: List the key points or evidence used to support the main argument.\n",
    "3. Potential Counterarguments: Suggest possible objections or alternative viewpoints to the main argument.\n",
    "\n",
    "Text: {text}\n",
    "\n",
    "Analysis:\"\"\"\n",
    "\n",
    "# Create a PromptTemplate from the string\n",
    "prompt = PromptTemplate.from_template(multi_step_prompt)\n",
    "# Create a chain that links the prompt with the language model\n",
    "multi_step_chain = prompt | llm\n",
    "\n",
    "# Test the multi-step reasoning approach\n",
    "text = \"\"\"While electric vehicles are often touted as a solution to climate change, their environmental impact is not as straightforward as it seems.\n",
    "The production of batteries for electric cars requires significant mining operations, which can lead to habitat destruction and water pollution.\n",
    "Moreover, if the electricity used to charge these vehicles comes from fossil fuel sources, the overall carbon footprint may not be significantly reduced.\n",
    "However, as renewable energy sources become more prevalent and battery technology improves, electric vehicles could indeed play a crucial role in combating climate change.\"\"\"\n",
    "\n",
    "# Invoke the chain with the input text\n",
    "result = multi_step_chain.invoke({\"text\": text}).content\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fXElRkLHdW-c"
   },
   "source": [
    "The prompt includes clear instructions for the model to follow three specific reasoning steps. By structuring the task this way, we help the model avoid vague or unfocused answers.\n",
    "- PromptTemplate construction: `PromptTemplate.from_template(...)` dynamically prepares the prompt with a specific `{text}` input that the model will analyze.\n",
    "- Chain assembly: As before, `prompt | llm` creates a simple and composable LangChain chain that feeds the rendered prompt into the model.\n",
    "- Input text: The text discusses the pros and cons of electric vehicles and is intentionally complex, making it a good candidate for multi-step analysis.\n",
    "- Model invocation: The `.invoke(...)` method fills in the `{text}` placeholder with the real input and sends the prompt to the model. The result is a well-structured breakdown of the argument, supporting details, and counterpoints.\n",
    "\n",
    "By guiding the model through explicit reasoning steps, this technique can significantly improve both the structure and quality of analytical responses—useful for tasks like policy analysis, critical essays, argument mapping, and educational applications. It also reduces ambiguity by clearly framing the model’s thinking process.\n",
    "\n",
    "## Comparative analysis\n",
    "We now test two different prompt formats for the same task. Both prompts ask the model to explain the concept of blockchain technology, but they do so in different ways:\n",
    "- Basic prompt: A minimal instruction—simply ask for an explanation.\n",
    "- Structured prompt: A more detailed format that instructs the model to break down the explanation into specific subcomponents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "RPnImaIFdXPx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic Prompt Result:\n",
      "Blockchain technology is a decentralized digital ledger system that records transactions across multiple computers in a way that ensures security, transparency, and immutability. Each transaction is grouped into a block, and these blocks are linked together in chronological order to form a chain. Once a block is added to the chain, altering it becomes nearly impossible without consensus from the network participants. This technology underpins cryptocurrencies like Bitcoin, but it also has applications in various fields, including supply chain management, healthcare, and voting systems, due to its ability to provide secure and verifiable records without a central authority.\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Structured Prompt Result:\n",
      "### 1. Definition\n",
      "Blockchain technology is a decentralized digital ledger that records transactions across many computers in a way that the registered transactions cannot be altered retroactively. This ensures transparency, security, and trust among users without the need for a central authority.\n",
      "\n",
      "### 2. Key Features\n",
      "- **Decentralization**: No single entity controls the network; it is maintained by multiple participants.\n",
      "- **Immutability**: Once recorded, data cannot be changed or deleted, ensuring a permanent record.\n",
      "- **Transparency**: All transactions are visible to participants, promoting accountability.\n",
      "- **Consensus Mechanisms**: Processes like Proof of Work or Proof of Stake validate transactions to maintain network integrity.\n",
      "- **Smart Contracts**: Self-executing contracts with the terms directly written into code, automating processes.\n",
      "\n",
      "### 3. Real-world Applications\n",
      "- **Cryptocurrencies**: Bitcoin and Ethereum are the most notable examples, enabling peer-to-peer financial transactions.\n",
      "- **Supply Chain Management**: Enhances tracking and traceability of products from origin to consumer.\n",
      "- **Healthcare**: Securely shares patient records among authorized parties while maintaining privacy.\n",
      "- **Voting Systems**: Provides secure and transparent voting processes that can reduce fraud.\n",
      "- **Digital Identity Verification**: Offers secure methods for verifying identities online.\n",
      "\n",
      "### 4. Potential Impact on Industries\n",
      "- **Finance**: Reduces transaction costs and speeds up processes by eliminating intermediaries.\n",
      "- **Supply Chain**: Increases efficiency and reduces fraud through enhanced tracking and transparency.\n",
      "- **Legal**: Streamlines contract execution and reduces disputes with smart contracts.\n",
      "- **Healthcare**: Improves data sharing and patient privacy, leading to better care coordination.\n",
      "- **Government**: Enhances transparency in public services and reduces corruption by providing immutable records. \n",
      "\n",
      "Overall, blockchain has the potential to revolutionize various sectors by increasing efficiency, security, and trust in digital interactions.\n",
      "\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the task for both prompts\n",
    "task = \"Explain conciesly the concept of blockchain technology\"\n",
    "\n",
    "# Define two different prompt templates for comparison\n",
    "prompt_templates = {\n",
    "    # Simple one-line instruction\n",
    "    \"Basic\": \"Explain {task}.\",\n",
    "    # Detailed, step-by-step structure to guide the model\n",
    "    \"Structured\": \"\"\"Explain {task} by addressing the following points:\n",
    "1. Definition\n",
    "2. Key features\n",
    "3. Real-world applications\n",
    "4. Potential impact on industries\"\"\"\n",
    "}\n",
    "\n",
    "# Loop through each prompt variant and run the model\n",
    "for name, template in prompt_templates.items():\n",
    "    # Create a prompt template from the string\n",
    "    prompt = PromptTemplate.from_template(template)\n",
    "    # Combine the prompt with the language model\n",
    "    chain = prompt | llm\n",
    "    # Invoke the chain with the input task\n",
    "    result = chain.invoke({\"task\": task}).content\n",
    "    print(f\"{name} Prompt Result:\\n{result}\")\n",
    "    print(\"\\n\" + \"-\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I0sgCAC6dYBj"
   },
   "source": [
    "We define a single, consistent task—explaining blockchain technology concisely—so we can objectively compare outputs.\n",
    "- Two prompt variants:\n",
    "  - The basic prompt provides minimal structure, leaving it to the model to decide how to present the information.\n",
    "  - The structured prompt gives explicit headings, which encourages the model to return an organized and comprehensive explanation.\n",
    "- Each prompt is passed through `PromptTemplate.from_template(...)` to allow the insertion of the `{task}` variable.\n",
    "- Each prompt is piped (`|`) into the language model, and the `.invoke(...)` method is used to run the prompt.\n",
    "\n",
    "This comparative analysis helps determine which prompt format is more effective for a given use case. Often, even small changes in prompt phrasing or structure can lead to significantly better results.\n",
    "\n",
    "This experiment gives us a practical sense of how prompt design influences model behavior—an essential skill when building real-world AI applications."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
