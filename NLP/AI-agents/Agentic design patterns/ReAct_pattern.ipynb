{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W-YGE7y-aQnG"
   },
   "source": [
    "# ReAct pattern\n",
    "\n",
    "In many real-world problems, an AI system needs more than just text generation. It must reason about a user request, decide if external information or computation is required, and then act by using tools (APIs, databases, calculators, search engines, etc.). This is where the ReAct (Reason + Act) pattern comes in.\n",
    "\n",
    "ReAct is a simple, powerful way to build agents that alternate between reasoning (thinking / planning, using the LLM) and acting (calling tools, APIs, or environment functions), then using the tool outputs to continue reasoning.\n",
    "- Reason: The LLM reasons about what it needs to do.\n",
    "- Act: If needed, it calls a tool (e.g., Wikipedia, calculator).\n",
    "- Loop: It may continue reasoning with new knowledge from tools until it’s ready to give the final answer.\n",
    "\n",
    "The pattern suits open-ended QA, tool-enabled search, multi-step reasoning that requires external data and many agentic workflows.\n",
    "\n",
    "In this notebook, we will implement a ReAct pattern, giving our agent access to both:\n",
    "- A Wikipedia search tool for factual knowledge.\n",
    "- A Calculator tool for math.\n",
    "\n",
    "This design helps us understand how reasoning and acting can be orchestrated systematically in agentic workflows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "9pdR_g16ZDNr"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import TypedDict, Sequence, Annotated\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_core.messages import BaseMessage, SystemMessage, ToolMessage, HumanMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.runnables.graph import MermaidDrawMethod\n",
    "from IPython.display import Image, display\n",
    "import wikipedia\n",
    "import math\n",
    "import json\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Configure OpenAI API key for AI model access\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cl3y8J-mekpT"
   },
   "source": [
    "### Initialize the language model\n",
    "The language model serves as the core intelligence of our conversational agent. Here we will configure the AI model with specific parameters that balance response quality, cost and performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "gLeYsJ9Jend6"
   },
   "outputs": [],
   "source": [
    "# Initialize the OpenAI language model\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini-2024-07-18\", temperature=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vXGMD73JetKW"
   },
   "source": [
    "This configuration creates our AI model instance using OpenAI's GPT model. Using `temperature=0.0` encourages consistent reasoning behavior across loop iterations (helpful for reproducibility in agent loops).\n",
    "\n",
    "### Define the agent state\n",
    "Before we can run a ReAct-style loop, we need a way to track the full message history between the agent (LLM), user, and tools. Since the ReAct pattern involves multiple back-and-forth interactions - including the model's reasoning steps and tool calls - we must persist all intermediate messages across the workflow.\n",
    "\n",
    "In LangGraph, this is done using a custom state dictionary. Each node in the graph returns new messages (model output or tool result), and the framework automatically appends these to the evolving state under the hood.\n",
    "\n",
    "To define this state, we use Python's `TypedDict` and LangGraph’s message reducer utility `add_messages`. The key idea is to keep a list of `BaseMessage` objects representing the evolving conversation, which will be passed from one node to the next as the loop executes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "uoNdW3ejgwV5"
   },
   "outputs": [],
   "source": [
    "# Define a dictionary structure for the agent's evolving state\n",
    "class AgentState(TypedDict):\n",
    "    \"\"\"State of the agent for one turn or conversation.\"\"\"\n",
    "    # The `messages` field stores the entire chat history (LLM thoughts, tool responses, user input, etc.)\n",
    "    messages: Annotated[Sequence[BaseMessage], add_messages]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xQsr5dnAh3iq"
   },
   "source": [
    "This defines the `AgentState` class, a dictionary used to represent the current state of the agent at any point in the workflow.\n",
    "* The `messages` field is a list of `BaseMessage` objects from LangChain. These can include:\n",
    "  * `HumanMessage` (user input)\n",
    "  * `AIMessage` (LLM output)\n",
    "  * `ToolMessage` (tool result)\n",
    "  * `SystemMessage` (system prompt or internal instruction)\n",
    "* The `Annotated[..., add_messages]` part instructs LangGraph how to merge or update the `messages` field when nodes return additional messages. Specifically, `add_messages` means new messages are appended to the existing list instead of replacing it.\n",
    "\n",
    "This pattern gives us a clean and structured way to maintain a full memory of each interaction cycle inside the ReAct loop.\n",
    "\n",
    "### Define tools\n",
    "ReAct shines when the LLM can request tools. It enables LLMs to alternate between reasoning steps and external tool use. Tools are core to this pattern - they allow the model to act in the world, rather than merely respond. We define two external tools that the LLM can call to demonstrate this capability.\n",
    "\n",
    "#### Wikipedia search tool\n",
    "This tool uses the `wikipedia` Python package to fetch a short summary based on a query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "oNfKt6ZOjeYW"
   },
   "outputs": [],
   "source": [
    "@tool\n",
    "def wiki_search(query: str) -> str:\n",
    "    \"\"\"Search Wikipedia for the query and return a brief summary of the top result.\"\"\"\n",
    "    try:\n",
    "        # Fetches summary from Wikipedia for the given query (limited to 5 sentences)\n",
    "        summary = wikipedia.summary(query, sentences=5)\n",
    "        return summary\n",
    "    except Exception as e:\n",
    "        # Return error if the query fails (e.g., disambiguation, page not found)\n",
    "        return f\"Error: {e}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XlUnZagkjfCM"
   },
   "source": [
    "This function is decorated with `@tool`, making it callable from an LLM within a LangGraph flow. If the model decides it needs to \"look something up,\" it can trigger this tool. The function’s docstring becomes the tool’s description exposed to the LLM. This is how the model knows what each tool does and how to use it properly.\n",
    "\n",
    "#### Calculator tool\n",
    "Next, we provide a tool for computing mathematical expressions. This is especially useful when the model wants to offload calculation to a deterministic backend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "ul84kAx7jgPR"
   },
   "outputs": [],
   "source": [
    "@tool\n",
    "def calculator(expression: str) -> str:\n",
    "    \"\"\"Safely evaluate a basic mathematical expression (e.g., '2 + 2 * 5').\"\"\"\n",
    "    try:\n",
    "        # Use eval in a restricted environment — no access to Python built-ins\n",
    "        result = eval(expression, {\"__builtins__\": {}}, {\"math\": math})\n",
    "        return str(result)\n",
    "    except Exception as e:\n",
    "        # Return error message if evaluation fails\n",
    "        return f\"Error: {e}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rrKqXPWPhAV5"
   },
   "source": [
    "This tool is also marked with `@tool` and leverages `eval()` securely. We explicitly disable Python built-ins to prevent dangerous evaluations, allowing only access to the `math` module.\n",
    "\n",
    "These are intentionally minimal tools to illustrate the flow. In production we could add HTTP fetchers, databases, environment controls, or proprietary APIs.\n",
    "\n",
    "#### Expose tools to the model\n",
    "The agent's LLM needs to \"know\" about tools (names and signatures). Many LLM wrappers allow binding tools so that the model can emit structured tool-call messages that the runtime interprets. After defining our tools, we expose them to the model in two steps:\n",
    "- First, create a mapping of tool names to actual tool functions. This will be used later to execute tool calls emitted by the model.\n",
    "- Then, use `llm.bind_tools()` to let the LLM know which tools are available. This enables it to request tools by name and argument structure in its output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "0_JbjE6vkYmL"
   },
   "outputs": [],
   "source": [
    "# Collect tools into a list\n",
    "tools = [wiki_search, calculator]\n",
    "# Build a name → tool dictionary for runtime use\n",
    "tools_by_name = {tool.name: tool for tool in tools}\n",
    "\n",
    "# Bind tools to the LLM (so it knows what it can call)\n",
    "llm = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V-auWejUk07D"
   },
   "source": [
    "- The `tools_by_name` dictionary is key when interpreting tool calls during graph execution.\n",
    "- `bind_tools()` effectively informs the LLM: \"You can call these tools during your reasoning — here is what they are, what they do, and what arguments they need.\"\n",
    "\n",
    "With these pieces in place, the agent is now capable of reasoning about a user query, deciding when it needs help, and using external tools to get it. This is the operational core of the ReAct pattern.\n",
    "\n",
    "### Crate nodes\n",
    "The ReAct pattern stands for Reasoning + Acting. In this section, we implement two key nodes in our agent's loop. This two-node loop allows the model to iteratively reason, act, observe, and reason again - mimicking how a human would interact with external tools while solving a problem.\n",
    "\n",
    "#### Model call node (reason step)\n",
    "This node represents the reason step. It’s where the language model processes the current state (i.e., the full history of the conversation), and decides what to do next — either generate a direct answer or request an external tool. The node should send the system prompt describing tool capabilities plus the current conversation. The node returns the new assistant message(s), which will be appended to the state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "c5fHNEbjvAem"
   },
   "outputs": [],
   "source": [
    "def call_model(state: AgentState):\n",
    "    \"\"\"LLM reasoning node: call the chat model with system prompt + conversation.\"\"\"\n",
    "\n",
    "    # System prompt helps the agent knows its role and available tools\n",
    "    system_prompt = SystemMessage(\n",
    "        content=\"You are a helpful AI assistant. You can use wiki_search or calculator if needed.\"\n",
    "    )\n",
    "\n",
    "    # Pass system + history messages (user, assistant, tool) to LLM\n",
    "    response = llm.invoke([system_prompt] + list(state[\"messages\"]))\n",
    "\n",
    "    # Append the model's response to the state messages\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tU5XOlTMvA--"
   },
   "source": [
    "- A `SystemMessage` sets the behavior and tool awareness of the agent.\n",
    "- The model is called with a list of prior messages including that system message and all user/model/tool messages so far.\n",
    "- The return value is a dictionary with a single new assistant message, which will be appended to the state by the graph runtime.\n",
    "\n",
    "This is the core thinking step of the agent.\n",
    "\n",
    "#### Tool execution node (act step)\n",
    "This node represents the act step. It checks if the LLM to use one or more tools and executes the tool(s). Then, it converts their results into `ToolMessage` objects, which are then appended back into the messages stream so the LLM can read tool outputs in the next reasoning step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "VLmIXSkuvBkE"
   },
   "outputs": [],
   "source": [
    "def tool_node(state: AgentState):\n",
    "    \"\"\"Tool execution node: run any tools the LLM requested.\"\"\"\n",
    "\n",
    "    outputs = []  # Store results of tool calls\n",
    "    last_message = state[\"messages\"][-1]  # The most recent model message\n",
    "\n",
    "    # Check if the model made any tool calls\n",
    "    if hasattr(last_message, \"tool_calls\") and last_message.tool_calls:\n",
    "        for tool_call in last_message.tool_calls:\n",
    "            tool_name = tool_call[\"name\"]  # Name of the tool\n",
    "            tool_args = tool_call[\"args\"]  # Arguments for the tool\n",
    "\n",
    "            # Execute tool if available\n",
    "            if tool_name in tools_by_name:\n",
    "                result = tools_by_name[tool_name].invoke(tool_args)\n",
    "            else:\n",
    "                result = f\"Tool '{tool_name}' not found.\"\n",
    "\n",
    "            # Wrap tool output into a ToolMessage so the LLM can read it\n",
    "            outputs.append(\n",
    "                ToolMessage(\n",
    "                    content=json.dumps(result),\n",
    "                    name=tool_name,\n",
    "                    tool_call_id=tool_call.get(\"id\")  # ID lets model link result to request\n",
    "                )\n",
    "            )\n",
    "\n",
    "    # Return the list of tool responses to be appended to message history\n",
    "    return {\"messages\": outputs}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UILdPEqywz2Y"
   },
   "source": [
    "- The function inspects the most recent message from the LLM. If it includes tool calls (structured requests emitted by the model), we parse and execute them.\n",
    "- We look up the correct tool function using its name via `tools_by_name`.\n",
    "- The results are wrapped in `ToolMessage` objects, including the tool name and optional ID - this makes it easy for the LLM to resolve tool outputs to the original requests.\n",
    "- These results are returned as new messages, added to the conversation timeline for the next reasoning step.\n",
    "\n",
    "This is the execution engine of the agent - it performs real-world operations on the model’s behalf.\n",
    "\n",
    "\n",
    "### Define loop continuation logic\n",
    "Now that we’ve implemented the reasoning and acting steps, we need a way to control the loop — that is, to decide whether the agent should keep going (e.g., because a tool was requested) or stop (because the agent has given a final answer).\n",
    "\n",
    "This logic is critical in the ReAct pattern. It inspects the most recent assistant message to check if the model is requesting tool execution. If so, we continue the loop by calling the tool node again. If not, the model must consider the response final — so we terminate the workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "76FoTvoZ1VPd"
   },
   "outputs": [],
   "source": [
    "def should_continue(state: AgentState) -> str:\n",
    "    \"\"\"Decide whether to continue the ReAct loop or stop.\"\"\"\n",
    "    # Inspect the most recent assistant message\n",
    "    last_message = state[\"messages\"][-1]\n",
    "\n",
    "    # If no tool calls are requested, we end the loop\n",
    "    if not (hasattr(last_message, \"tool_calls\") and last_message.tool_calls):\n",
    "        return \"end\"\n",
    "    else:\n",
    "        return \"continue\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4mCuh1yF1uty"
   },
   "source": [
    "- It takes in the current workflow `state`, which includes the full conversation history.\n",
    "- It fetches the last assistant message - typically this is either a direct answer or a message that includes tool requests.\n",
    "- If the message includes one or more `tool_calls`, we return `\"continue\"` to re-enter the `tool_node` (Act step).\n",
    "- If no tool calls are present, we assume the model has completed its reasoning and return `\"end\"` to stop the graph.\n",
    "\n",
    "This function enables dynamic control flow — allowing the agent to flexibly determine when more action is needed, and when it's confident enough to respond definitively.\n",
    "\n",
    "### Build the agent graph\n",
    "Now it’s time to connect everything into a working agentic workflow graph using LangGraph. The graph captures the iterative process of reason → act (if needed) → back to reason → until done.\n",
    "\n",
    "The workflow is represented as a stateful graph, where each node is a function and edges determine the flow of execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "AtXcrEIL3vn_"
   },
   "outputs": [],
   "source": [
    "# Build the ReAct workflow graph\n",
    "graph = StateGraph(AgentState)\n",
    "\n",
    "# Register the nodes (steps)\n",
    "graph.add_node(\"llm\", call_model)  # Reasoning step\n",
    "graph.add_node(\"tools\", tool_node)  # Acting step (tool use)\n",
    "\n",
    "# Define edges\n",
    "graph.add_edge(START, \"llm\")   # Set the entry point of the graph — where execution begins\n",
    "graph.add_conditional_edges(  # Add conditional routing from the LLM node\n",
    "    \"llm\",  # After the LLM runs\n",
    "    should_continue,  # Run this function to decide where to go next\n",
    "    {\n",
    "        \"continue\": \"tools\",  # If tools were requested → go to tools\n",
    "        \"end\": END,           # If done → terminate the workflow\n",
    "    },\n",
    ")\n",
    "\n",
    "graph.add_edge(\"tools\", \"llm\")  # Add normal edge: After tools are used, go back to the LLM for reasoning\n",
    "\n",
    "# Compile the graph\n",
    "agent = graph.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Ki-x8S96z_6"
   },
   "source": [
    "- `graph.add_edge(START, \"llm\")` declares the first node of execution.\n",
    "- `add_conditional_edges(...)` handles branching logic based on model output. It lets us decide at runtime whether to loop or exit.\n",
    "- The edge `\"tools\" → \"llm\"` ensures that once tools are used, the agent gets a chance to reason again — a core part of the ReAct (Reason → Act → Reason) cycle.\n",
    "- Finally, we compile the graph into a runnable object using `compile()`.\n",
    "\n",
    "#### Visualizing the workflow\n",
    "Let’s display the graph visually to better understand the chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "XutdcMUx7bWw"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the graph\n",
    "display(\n",
    "    Image(\n",
    "        agent.get_graph().draw_mermaid_png(\n",
    "            draw_method=MermaidDrawMethod.API,\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BmLlwwpu7amP"
   },
   "source": [
    "### Run an Example\n",
    "Let’s see the ReAct agent in action. We ask a composite question requiring both Wikipedia (population) and calculator (division)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "a2fB8LJx710m"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HUMAN: What is the population of Spain in 2025 divided by 2?\n",
      "AI: \n",
      "TOOL: \"As of 1 July 2025, Spain had a total population of 49,315,949. The modern Kingdom of Spain arose from the accretion of several independent Iberian realms, including the Kingdoms of Le\\u00f3n, Castile, Navarre, the Crown of Aragon and Granada,  all of which, together with the modern state of Portugal, were successor states to the late antique Christian Visigothic Kingdom after the Reconquista.\\nSpain's population surpassed 49 million inhabitants for the first time in history in 2025, with a total population of 49,315,949 people living in Spain. Its population density, at 97 inhabitants per square kilometre (250/sq mi), is much lower than other Western European countries, yet, with the exception of microstates, it has the highest real density population in Europe, based on density of inhabited areas. With the notable exception of Madrid, Spain's capital city, the most densely populated areas lie around the coast.\"\n",
      "AI: \n",
      "TOOL: \"24657974.5\"\n",
      "AI: The population of Spain in 2025 is projected to be 49,315,949. When divided by 2, that results in 24,657,974.5.\n"
     ]
    }
   ],
   "source": [
    "# Example user query\n",
    "user_question = \"What is the population of Spain in 2025 divided by 2?\"\n",
    "\n",
    "# Initial state: conversation starts with user message\n",
    "state = AgentState(messages=[HumanMessage(content=user_question)])\n",
    "\n",
    "# Run the ReAct agent\n",
    "result = agent.invoke(state)\n",
    "\n",
    "# Print the conversation history\n",
    "for msg in result[\"messages\"]:\n",
    "    print(f\"{msg.type.upper()}: {msg.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rBwRrnIG8T2D"
   },
   "source": [
    "The LLM should:\n",
    "- Reason: Identify it needs population → use Wikipedia.\n",
    "- Act: Call `wiki_search`.\n",
    "- Reason again: Take result, realize it needs math.\n",
    "- Act: Call `calculator`.\n",
    "- Reason finally: Give the user the answer."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (langgraph-env)",
   "language": "python",
   "name": "langgraph-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
