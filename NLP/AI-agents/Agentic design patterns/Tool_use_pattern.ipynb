{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W-YGE7y-aQnG"
   },
   "source": [
    "# Tool use pattern\n",
    "\n",
    "Modern AI systems often need to do things beyond pure text generation: fetch facts, compute values, convert units, or call business APIs - they must interact with external tools to access up-to-date information or perform computations. This ability to call tools is the tool use pattern.\n",
    "\n",
    "The tool use pattern is a foundational approach in agentic system design where an LLM can invoke external tools—APIs, functions or services — to augment its reasoning and actions. These tools allow the model to fetch up-to-date facts, perform calculations, retrieve structured data, call business logic, or interact with the outside world.\n",
    "\n",
    "Instead of relying solely on its internal knowledge, the LLM becomes a coordinator: it interprets user intent, decides what tools it needs, and incorporates tool outputs into its final response.\n",
    "\n",
    "In this notebook, we will implement a single-pass tool-use workflow:\n",
    "1. The model receives a user request.\n",
    "2. If the model decides it needs tools, it calls a tool once.\n",
    "3. We execute the tool, capture their outputs, and hand them back to the model.\n",
    "4. The model finalizes the answer using those results.\n",
    "\n",
    "Unlike more advanced patterns (e.g., multi-turn reasoning/acting loops), here we keep it to one tool-use phase then finalization—simple, reliable, and easy to productionize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "9pdR_g16ZDNr"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import TypedDict, Sequence, Annotated\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_core.messages import BaseMessage, SystemMessage, ToolMessage, HumanMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.runnables.graph import MermaidDrawMethod\n",
    "from IPython.display import Image, display\n",
    "import wikipedia\n",
    "import math\n",
    "import json\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Configure OpenAI API key for AI model access\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cl3y8J-mekpT"
   },
   "source": [
    "### Initialize the language model\n",
    "The language model serves as the core intelligence of our conversational agent. Here we will configure the AI model with specific parameters that balance response quality, cost and performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "gLeYsJ9Jend6"
   },
   "outputs": [],
   "source": [
    "# Initialize the OpenAI language model\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini-2024-07-18\", temperature=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vXGMD73JetKW"
   },
   "source": [
    "This configuration creates our AI model instance using OpenAI's GPT model.\n",
    "\n",
    "### Define the agent state\n",
    "To build a working tool-use system, we need to keep track of what has happened during the interaction: what the user asked, what the model said or requested, and what the tools returned. We do this by defining a simple state object that holds the conversation history. This lets us pass all the relevant context between steps in the workflow.\n",
    "\n",
    "In LangGraph, this is done using a custom state dictionary. Each node in the graph returns new messages (model output or tool result), and the framework automatically appends these to the evolving state under the hood.\n",
    "\n",
    "To define this state, we use Python's `TypedDict` and LangGraph’s message reducer utility `add_messages`. The key idea is to keep a list of `BaseMessage` objects representing the evolving conversation, which will be passed from one node to the next as the loop executes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "uoNdW3ejgwV5"
   },
   "outputs": [],
   "source": [
    "# Define a dictionary structure for the agent's evolving state\n",
    "class AgentState(TypedDict):\n",
    "    \"\"\"State of the agent for one turn or conversation.\"\"\"\n",
    "    # The `messages` field stores the entire chat history (LLM thoughts, tool responses, user input, etc.)\n",
    "    messages: Annotated[Sequence[BaseMessage], add_messages]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xQsr5dnAh3iq"
   },
   "source": [
    "This defines the `AgentState` class, a dictionary used to represent the current state of the agent at any point in the workflow.\n",
    "* The `messages` field tracks all messages in the interaction. Each message is a `BaseMessage` objects from LangChain. These can include:\n",
    "  * `HumanMessage` (user input)\n",
    "  * `AIMessage` (LLM output)\n",
    "  * `ToolMessage` (tool result)\n",
    "  * `SystemMessage` (system prompt or internal instruction)\n",
    "* The `Annotated[..., add_messages]` part instructs LangGraph how to merge or update the `messages` field when nodes return additional messages. Specifically, `add_messages` means new messages are appended to the existing list instead of replacing it.\n",
    "\n",
    "This pattern gives us a clean and structured way to maintain a full memory of each interaction cycle inside the ReAct loop.\n",
    "\n",
    "### Define tools\n",
    "In the tool use pattern, the most important step is to make external capabilities accessible to the LLM. Tools extend the model’s functionality beyond language - allowing it to fetch data, perform calculations, or interact with external systems. In this pattern, the model only has one chance to call tools before producing a final answer, so we define all tools it might need up front.\n",
    "\n",
    "\n",
    "#### Wikipedia search tool\n",
    "This tool uses the `wikipedia` Python package to fetch a short summary based on a query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "oNfKt6ZOjeYW"
   },
   "outputs": [],
   "source": [
    "@tool\n",
    "def wiki_search(query: str) -> str:\n",
    "    \"\"\"Search Wikipedia for the query and return a brief summary of the top result.\"\"\"\n",
    "    try:\n",
    "        # Fetches summary from Wikipedia for the given query (limited to 5 sentences)\n",
    "        summary = wikipedia.summary(query, sentences=5)\n",
    "        return summary\n",
    "    except Exception as e:\n",
    "        # Return error if the query fails (e.g., disambiguation, page not found)\n",
    "        return f\"Error: {e}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XlUnZagkjfCM"
   },
   "source": [
    "This function is decorated with `@tool`, making it callable from an LLM within a LangGraph flow. If the model decides it needs to \"look something up,\" it can trigger this tool. The function’s docstring becomes the tool’s description exposed to the LLM. This is how the model knows what each tool does and how to use it properly.\n",
    "\n",
    "#### Calculator tool\n",
    "Next, we provide a tool for computing mathematical expressions. This is especially useful when the model wants to offload calculation to a deterministic backend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "ul84kAx7jgPR"
   },
   "outputs": [],
   "source": [
    "@tool\n",
    "def calculator(expression: str) -> str:\n",
    "    \"\"\"Safely evaluate a basic mathematical expression (e.g., '2 + 2 * 5').\"\"\"\n",
    "    try:\n",
    "        # Use eval in a restricted environment — no access to Python built-ins\n",
    "        result = eval(expression, {\"__builtins__\": {}}, {\"math\": math})\n",
    "        return str(result)\n",
    "    except Exception as e:\n",
    "        # Return error message if evaluation fails\n",
    "        return f\"Error: {e}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rrKqXPWPhAV5"
   },
   "source": [
    "This tool is also marked with `@tool` and leverages `eval()` securely. We explicitly disable Python built-ins to prevent dangerous evaluations, allowing only access to the `math` module.\n",
    "\n",
    "These are intentionally minimal tools to illustrate the flow. In production we could add HTTP fetchers, databases, environment controls, or proprietary APIs.\n",
    "\n",
    "#### Expose tools to the model\n",
    "The agent's LLM needs to \"know\" about tools (names and signatures). Many LLM wrappers allow binding tools so that the model can emit structured tool-call messages that the runtime interprets. After defining our tools, we expose them to the model in two steps:\n",
    "- First, create a mapping of tool names to actual tool functions. This will be used later to execute tool calls emitted by the model.\n",
    "- Then, use `llm.bind_tools()` to let the LLM know which tools are available. This enables it to request tools by name and argument structure in its output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "0_JbjE6vkYmL"
   },
   "outputs": [],
   "source": [
    "# Collect tools into a list\n",
    "tools = [wiki_search, calculator]\n",
    "# Build a name → tool dictionary for runtime use\n",
    "tools_by_name = {tool.name: tool for tool in tools}\n",
    "\n",
    "# Bind tools to the LLM (so it knows what it can call)\n",
    "llm = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V-auWejUk07D"
   },
   "source": [
    "- The `tools_by_name` dictionary is key when interpreting tool calls during graph execution.\n",
    "- `bind_tools()` effectively informs the LLM: \"You can call these tools during your reasoning — here is what they are, what they do, and what arguments they need.\"\n",
    "\n",
    "With these pieces in place, the agent is now capable of reasoning about a user query, deciding when it needs help, and using external tools to get it. This is the operational core of the tool use pattern.\n",
    "\n",
    "### Crate nodes\n",
    "In this part, we’re setting up the key components (nodes) that define how the agent behaves in the tool-use workflow. This is where the agent thinks what to do, acts by calling tools, and then wraps things up with a final, user-friendly answer.\n",
    "\n",
    "#### Planning node\n",
    "The planning step is where the LLM decides what to do next. The LLM receives the entire conversation history plus a system prompt that clearly states the agent’s role and the tools it has at its disposal. The goal here is for the LLM to either answer the user’s query directly or to decide that a tool (or multiple tools) need to be called to fetch information or perform calculations. This step represents the agent’s core reasoning phase, where it plans how to respond intelligently based on available resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "c5fHNEbjvAem"
   },
   "outputs": [],
   "source": [
    "def call_model(state: AgentState):\n",
    "    \"\"\"Planner node: LLM decides if tools are needed or if it can answer directly.\"\"\"\n",
    "\n",
    "    # System prompt helps the agent knows its role and available tools\n",
    "    system_prompt = SystemMessage(\n",
    "        content=\"You are a helpful AI assistant. You can use wiki_search or calculator tools if needed.\"\n",
    "    )\n",
    "\n",
    "    # Pass system + history messages (user, assistant, tool) to LLM\n",
    "    response = llm.invoke([system_prompt] + list(state[\"messages\"]))\n",
    "\n",
    "    # Append the model's response to the state messages\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tU5XOlTMvA--"
   },
   "source": [
    "- A `SystemMessage` sets the behavior and tool awareness of the agent.\n",
    "- The model is called with a list of prior messages including that system message and all user/model/tool messages so far.\n",
    "- The return value is a dictionary with a single new assistant message, which will be appended to the state by the graph runtime.\n",
    "\n",
    "This is the core thinking step of the agent.\n",
    "\n",
    "#### Tool execution node\n",
    "Once the planner has decided which tools are needed and has issued tool calls, this node is responsible for actually executing those tools. The agent can handle multiple tool requests at once, running each and collecting their results. This execution step bridges the gap between abstract reasoning (what to do) and concrete action (actually doing it). It ensures tool outputs are returned in a consistent format, ready to be incorporated into the agent’s ongoing dialogue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "VLmIXSkuvBkE"
   },
   "outputs": [],
   "source": [
    "def tool_node(state: AgentState):\n",
    "    \"\"\"Tool execution node: executes all tools requested by the planner.\"\"\"\n",
    "\n",
    "    outputs = []  # Store results of tool calls\n",
    "    last_message = state[\"messages\"][-1]  # The most recent model message\n",
    "\n",
    "    # Check for tool calls and iterate through each\n",
    "    if hasattr(last_message, \"tool_calls\") and last_message.tool_calls:\n",
    "        for tool_call in last_message.tool_calls:\n",
    "            tool_name = tool_call[\"name\"]  # Name of the tool requested\n",
    "            tool_args = tool_call[\"args\"]  # Arguments passed to the tool\n",
    "\n",
    "            # Run the tool if found\n",
    "            if tool_name in tools_by_name:\n",
    "                result = tools_by_name[tool_name].invoke(tool_args)\n",
    "            else:\n",
    "                result = f\"Tool '{tool_name}' not found.\"\n",
    "\n",
    "            # Package result as ToolMessage\n",
    "            outputs.append(\n",
    "                ToolMessage(\n",
    "                    content=json.dumps(result),  # Serialize output to JSON string\n",
    "                    name=tool_name,  # Name for identification in history\n",
    "                    tool_call_id=tool_call.get(\"id\")  # Map output to specific tool call\n",
    "                )\n",
    "            )\n",
    "\n",
    "    # Return the list of tool responses to be appended to message history\n",
    "    return {\"messages\": outputs}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ChuE1b9U7-8t"
   },
   "source": [
    "- The function inspects the most recent message from the LLM. If it includes tool calls (structured requests emitted by the model), we parse and execute them.\n",
    "- We look up the correct tool function using its name via `tools_by_name`.\n",
    "- The results are wrapped in `ToolMessage` objects, including the tool name and optional ID - this makes it easy for the LLM to resolve tool outputs to the original requests.\n",
    "- These results are returned as new messages, added to the conversation timeline for the next reasoning step.\n",
    "\n",
    "This is the execution engine of the agent - it performs real-world operations on the model’s behalf.\n",
    "\n",
    "### Finalization node\n",
    "Once all tools have been executed, the finalizer prompts the LLM to synthesize a final, user-friendly answer. This is where everything comes together: the original user input, the model's reasoning, and the tool results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "pIPyo0bCwqs_"
   },
   "outputs": [],
   "source": [
    "def summarize_node(state: AgentState):\n",
    "    \"\"\"Finalizer node: LLM produces the final answer using tool outputs.\"\"\"\n",
    "\n",
    "    # Prompt the model to produce a summary based on tool results\n",
    "    system_prompt = SystemMessage(\n",
    "        content=\"You are a helpful assistant. Summarize results from the tools into a final user-friendly answer.\"\n",
    "    )\n",
    "\n",
    "    # Invoke model with full message history, including tool outputs\n",
    "    response = llm.invoke([system_prompt] + list(state[\"messages\"]))\n",
    "\n",
    "    # Return the assistant's final message\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UILdPEqywz2Y"
   },
   "source": [
    "This step transforms raw data from tool calls into natural, helpful output.\n",
    "- Like the planner, this node receives the full conversation history (including `ToolMessages`), giving the LLM full context.\n",
    "- The return is a single assistant message containing the agent's final response to the user - this concludes the workflow.\n",
    "\n",
    "\n",
    "### Define loop continuation logic\n",
    "Before we define how the flow of control moves through the graph, we need a mechanism to determine what should happen after the planner runs. Depending on what the LLM decides, we either go directly to the final response, or we need to run external tools first. That decision depends on whether the model made any tool calls.\n",
    "\n",
    "We now add conditional edges from the planner, to decide whether the agent should keep going (e.g., because a tool was requested) or stop (because the agent has given a final answer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "76FoTvoZ1VPd"
   },
   "outputs": [],
   "source": [
    "def needs_tools(state: AgentState) -> str:\n",
    "    \"\"\"Check if the planner requested tools or not.\"\"\"\n",
    "    # Get the most recent message from the assistant\n",
    "    last_message = state[\"messages\"][-1]\n",
    "\n",
    "    # If there are tool calls, continue to tool executor\n",
    "    if hasattr(last_message, \"tool_calls\") and last_message.tool_calls:\n",
    "        return \"tools\"\n",
    "    else:\n",
    "        # No tool calls -> go directly to finalizer\n",
    "        return \"direct\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4mCuh1yF1uty"
   },
   "source": [
    "- This function inspects the last message in the agent's message history - which is the planner’s output.\n",
    "- It checks if that message includes any tool_calls, which are structured indicators that the LLM wants to invoke a tool.\n",
    "  - If tool calls exist, the function returns \"tools\", instructing the graph to move to the tool execution node.\n",
    "  - If not, it returns \"direct\", skipping the tool phase and routing to the summarization node instead.\n",
    "\n",
    "This function is used as a conditional edge in the graph to decide the next step after the planning node runs.\n",
    "\n",
    "### Build the agent graph\n",
    "Now we wire the workflow together. This is where we assemble the graph that defines the agent’s logic. We are using LangGraph to construct this as a stateful, directed computation graph. Each node represents a phase in the agent’s reasoning process, and edges define how data (i.e., the agent’s state) flows between those nodes.\n",
    "\n",
    "The control flow will always start with planning. From there, it will branch conditionally: if the model has called tools, we route to the tool executor; if not, we go directly to finalization. After tool use, we also finalize the response. The graph ends there — one tool-use round, then done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "AtXcrEIL3vn_"
   },
   "outputs": [],
   "source": [
    "# Build the ReAct workflow graph\n",
    "graph = StateGraph(AgentState)\n",
    "\n",
    "# Register the nodes (steps)\n",
    "graph.add_node(\"planner\", call_model)  # Planning step\n",
    "graph.add_node(\"tool_executor\", tool_node)  # Tool execution\n",
    "graph.add_node(\"finalizer\", summarize_node)  # Summarization\n",
    "\n",
    "# Define edges\n",
    "graph.add_edge(START, \"planner\")  # Set the entry point of the graph — where execution begins\n",
    "graph.add_conditional_edges(  # Add conditional routing from the planner node\n",
    "    \"planner\",  # After the planner runs\n",
    "    needs_tools,  # Run this function to decide where to go next\n",
    "    {\n",
    "        \"tools\": \"tool_executor\",  # If tools were requested, go to tool executor\n",
    "        \"direct\": END,  # If not, skip to the end\n",
    "    },\n",
    ")\n",
    "\n",
    "graph.add_edge(\"tool_executor\", \"finalizer\")  # After tools are run, always proceed to finalizer\n",
    "graph.add_edge(\"finalizer\", END)  # Once final answer is generated, we're done\n",
    "\n",
    "# Compile the graph\n",
    "agent = graph.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Ki-x8S96z_6"
   },
   "source": [
    "- `StateGraph(AgentState)` creates a new LangGraph state machine that tracks the full conversation state throughout the workflow.\n",
    "- Each `add_node(...)` call registers a function that handles a specific part of the agent’s logic.\n",
    "- `add_edge(START, \"planner\")` defines the graph’s entry point — the planner node always runs first.\n",
    "- `add_conditional_edges(...)` attaches conditional logic that routes execution to different nodes depending on whether tool calls were made. The branching logic is handled by the previously defined `needs_tools` function.\n",
    "- `compile()` turns this structure into a runnable agent - ready to process user questions and dynamically decide what tools to use.\n",
    "\n",
    "\n",
    "#### Visualizing the workflow\n",
    "Let’s display the graph visually to better understand the chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "XutdcMUx7bWw"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the graph\n",
    "display(\n",
    "    Image(\n",
    "        agent.get_graph().draw_mermaid_png(\n",
    "            draw_method=MermaidDrawMethod.API,\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BmLlwwpu7amP"
   },
   "source": [
    "### Run examples\n",
    "Let’s see the tool-use agent in action. The examples below test various scenarios. Some require tool use, others only simple answers. This demonstrates how the agent dynamically decides when to invoke external tools versus when to answer directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "a2fB8LJx710m"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Example 1 ===\n",
      "HUMAN: What is the population of Spain in 2025?\n",
      "AI: \n",
      "TOOL: \"As of 1 July 2025, Spain had a total population of 49,315,949. The modern Kingdom of Spain arose from the accretion of several independent Iberian realms, including the Kingdoms of Le\\u00f3n, Castile, Navarre, the Crown of Aragon and Granada,  all of which, together with the modern state of Portugal, were successor states to the late antique Christian Visigothic Kingdom after the Reconquista.\\nSpain's population surpassed 49 million inhabitants for the first time in history in 2025, with a total population of 49,315,949 people living in Spain. Its population density, at 97 inhabitants per square kilometre (250/sq mi), is much lower than other Western European countries, yet, with the exception of microstates, it has the highest real density population in Europe, based on density of inhabited areas. With the notable exception of Madrid, Spain's capital city, the most densely populated areas lie around the coast.\"\n",
      "AI: As of July 1, 2025, the population of Spain is projected to be 49,315,949. This marks the first time in history that Spain's population has surpassed 49 million inhabitants.\n",
      "\n",
      "=== Example 2 ===\n",
      "HUMAN: What is (125 * 4) + 99?\n",
      "AI: \n",
      "TOOL: \"599\"\n",
      "AI: The result of (125 * 4) + 99 is 599.\n",
      "\n",
      "=== Example 3 ===\n",
      "HUMAN: What is the population of Spain in 2025? And what is (125 * 4) + 99?\n",
      "AI: \n",
      "TOOL: \"As of 1 July 2025, Spain had a total population of 49,315,949. The modern Kingdom of Spain arose from the accretion of several independent Iberian realms, including the Kingdoms of Le\\u00f3n, Castile, Navarre, the Crown of Aragon and Granada,  all of which, together with the modern state of Portugal, were successor states to the late antique Christian Visigothic Kingdom after the Reconquista.\\nSpain's population surpassed 49 million inhabitants for the first time in history in 2025, with a total population of 49,315,949 people living in Spain. Its population density, at 97 inhabitants per square kilometre (250/sq mi), is much lower than other Western European countries, yet, with the exception of microstates, it has the highest real density population in Europe, based on density of inhabited areas. With the notable exception of Madrid, Spain's capital city, the most densely populated areas lie around the coast.\"\n",
      "TOOL: \"599\"\n",
      "AI: As of July 1, 2025, the population of Spain is projected to be approximately **49,315,949** people. \n",
      "\n",
      "Additionally, the result of the calculation \\((125 * 4) + 99\\) is **599**.\n",
      "\n",
      "=== Example 4 ===\n",
      "HUMAN: How are you?\n",
      "AI: I'm just a computer program, so I don't have feelings, but I'm here and ready to help you! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "# Example 1: Wikipedia tool use\n",
    "user_question = \"What is the population of Spain in 2025?\"  # Example user query\n",
    "state = AgentState(messages=[HumanMessage(content=user_question)])  # Initial state: conversation starts with user message\n",
    "result = agent.invoke(state) # Run the agent\n",
    "print(\"=== Example 1 ===\")  # Print the conversation history\n",
    "for msg in result[\"messages\"]:\n",
    "    print(f\"{msg.type.upper()}: {msg.content}\")\n",
    "\n",
    "# Example 2: Calculator tool use\n",
    "user_question_2 = \"What is (125 * 4) + 99?\"\n",
    "state = AgentState(messages=[HumanMessage(content=user_question_2)])\n",
    "result = agent.invoke(state)\n",
    "print(\"\\n=== Example 2 ===\")\n",
    "for msg in result[\"messages\"]:\n",
    "    print(f\"{msg.type.upper()}: {msg.content}\")\n",
    "\n",
    "# Example 3: Combined Wikipedia and calculator\n",
    "user_question_3 = \"What is the population of Spain in 2025? And what is (125 * 4) + 99?\"\n",
    "state = AgentState(messages=[HumanMessage(content=user_question_3)])\n",
    "result = agent.invoke(state)\n",
    "print(\"\\n=== Example 3 ===\")\n",
    "for msg in result[\"messages\"]:\n",
    "    print(f\"{msg.type.upper()}: {msg.content}\")\n",
    "\n",
    "# Example 4: Direct answer, no tool needed\n",
    "user_question_4 = \"How are you?\"\n",
    "state = AgentState(messages=[HumanMessage(content=user_question_4)])\n",
    "result = agent.invoke(state)\n",
    "print(\"\\n=== Example 4 ===\")\n",
    "for msg in result[\"messages\"]:\n",
    "    print(f\"{msg.type.upper()}: {msg.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rBwRrnIG8T2D"
   },
   "source": [
    "These examples show how the agent dynamically reacts based on the question type - and make full use of the reasoning + tool use pattern."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (langgraph-env)",
   "language": "python",
   "name": "langgraph-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
