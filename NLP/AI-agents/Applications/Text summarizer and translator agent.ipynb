{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jOc7VX2N7np6"
   },
   "source": [
    "# Text summarizer and translator agent\n",
    "\n",
    "This notebook demonstrates how to build an intelligent agent that can automatically summarize English text and translate that summary into German. Rather than handling these tasks separately, we will create a unified system that orchestrates both operations seamlessly.\n",
    "\n",
    "Our approach centers on creating specialized tools that the agent can use autonomously, making decisions about when and how to apply each capability. This design pattern is particularly powerful because it mirrors how humans approach complex tasks - breaking them down into smaller, manageable steps and using the right tool for each job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "SR0IWDXf7gLT"
   },
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor, create_tool_calling_agent\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.tools import StructuredTool\n",
    "from pydantic import BaseModel, Field\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Configure OpenAI API key for AI model access\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mewlYPet79pg"
   },
   "source": [
    "### Language model initialization\n",
    "We will configure our language model with specific parameters that optimize it for our summarization and translation tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "-vFBqa7179Xx"
   },
   "outputs": [],
   "source": [
    "# Initialize the language model with optimized parameters\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini-2024-07-18\",\n",
    "    max_tokens=1000,  # Limit response length to control output size\n",
    "    temperature=0  # Set to 0 for deterministic and consistent outputs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nTKDVqvh79Lb"
   },
   "source": [
    "Here we instantiate our language model with carefully chosen parameters. The `temperature=0` setting ensures our outputs are deterministic and consistent, which is crucial for applications like summarization where we want predictable results. The token limit prevents excessively long responses while still allowing for comprehensive summaries and translations.\n",
    "\n",
    "### Core function definitions\n",
    "Now we will create the fundamental functions that perform our summarization and translation tasks. These functions encapsulate the logic for interacting with the language model and will later be wrapped as tools for our agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "edctQpkW78_I"
   },
   "outputs": [],
   "source": [
    "def summarize(text):\n",
    "    # Create a structured prompt template for summarization\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"text\"],  # Specify the input variable\n",
    "        template=\"Summarize the following text:\\n\\n{text}\\n\\nSummary:\"  # Define the template for summarization\n",
    "    )\n",
    "    chain = prompt | llm  # Create a chain by piping the prompt to the language model\n",
    "    return chain.invoke({\"text\": text}).content  # Invoke the chain with the input text and return the content of the response\n",
    "\n",
    "def translate(text):\n",
    "    # Create a structured prompt template for translation\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"text\"],  # Specify the input variable\n",
    "        template=\"Translate the following text to German:\\n\\n{text}\\n\\nTranslation:\"  # Define the template for translation\n",
    "    )\n",
    "    chain = prompt | llm  # Create a chain by piping the prompt to the language model\n",
    "    return chain.invoke({\"text\": text}).content  # Invoke the chain with the input text and return the content of the response\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wqldt5b5Avx5"
   },
   "source": [
    "These functions represent the core business logic of our application. Each function follows a consistent pattern: creating a prompt template, chaining it with the language model, and invoking the chain with input data. The use of `PromptTemplate` ensures consistent formatting and makes our prompts maintainable and reusable.\n",
    "\n",
    "### Input validation schema\n",
    "To ensure data integrity and provide clear interfaces for our tools, we will define a Pydantic model that validates input parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "yt3WaOCLAvU_"
   },
   "outputs": [],
   "source": [
    "class TextInput(BaseModel):\n",
    "    # Define a Pydantic model for input validation\n",
    "    text: str = Field(description=\"The text to summarize or translate\")  # Define a text field with a description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eliQcCOL78zi"
   },
   "source": [
    "This simple but important class provides input validation and documentation for our tools. Pydantic models automatically validate data types and can provide helpful error messages if invalid data is passed to our functions.\n",
    "\n",
    "#### Function testing\n",
    "Before integrating our functions into the agent framework, let's verify they work correctly with a simple test case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "ZUxKXVjm78mf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing summarization function:\n",
      "A fast brown fox leaps over a sluggish dog.\n",
      "\n",
      "Testing translation function:\n",
      "Die schnelle braune Füchsin springt über den faulen Hund.\n"
     ]
    }
   ],
   "source": [
    "# Test our core functions with a sample sentence\n",
    "test_text = \"The quick brown fox jumps over the lazy dog.\"\n",
    "\n",
    "print(\"Testing summarization function:\")\n",
    "print(summarize(test_text))\n",
    "print(\"\\nTesting translation function:\")\n",
    "print(translate(test_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XWjqts3T78Za"
   },
   "source": [
    "This testing step is used for ensuring our individual components work correctly before we integrate them into the more complex agent system. It allows us to catch and fix any issues early in the development process.\n",
    "\n",
    "### Tools definition for the agent\n",
    "Now we will transform our functions into structured tools that the agent can use autonomously. This involves wrapping our functions with metadata that helps the agent understand when and how to use each tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "W32lvLNU78MU"
   },
   "outputs": [],
   "source": [
    "# Transform our functions into structured tools for agent use - each tool includes metadata about its purpose and input requirements\n",
    "tools = [\n",
    "    StructuredTool.from_function(\n",
    "        func=summarize,  # The function to be wrapped as a tool\n",
    "        name=\"Summarize\",  # Name of the tool\n",
    "        description=\"Useful for summarizing text\",  # Description of what the tool does\n",
    "        args_schema=TextInput  # The Pydantic model defining the input schema\n",
    "    ),\n",
    "    StructuredTool.from_function(\n",
    "        func=translate,  # The function to be wrapped as a tool\n",
    "        name=\"Translate\",  # Name of the tool\n",
    "        description=\"Useful for translating text to German\",  # Description of what the tool does\n",
    "        args_schema=TextInput  # The Pydantic model defining the input schema\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ggRtYvZT77-D"
   },
   "source": [
    "By wrapping our functions as `StructuredTool` objects, we provide the agent with rich metadata about each capability. The descriptions are particularly important as they help the agent's reasoning process determine which tool to use in different situations.\n",
    "\n",
    "### Agent prompt engineering\n",
    "The prompt template is perhaps the most critical component of our agent system. It provides detailed instructions that guide the agent's behavior and ensure consistent and reliable operation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "gIDe2NLDCmzR"
   },
   "outputs": [],
   "source": [
    "# Create a comprehensive prompt template that guides agent behavior\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"input\", \"agent_scratchpad\"],  # Define the input variables for the prompt\n",
    "    template=\"\"\"Summarize the following text and then translate the summary to German:\n",
    "\n",
    "Text: {input}\n",
    "\n",
    "Use the following steps:\n",
    "1. Use the Summarize tool to summarize the text. Pass the entire text as the 'text' argument.\n",
    "2. Use the Translate tool to translate the summary to German. Pass the summary as the 'text' argument.\n",
    "3. Immediately after using both tools, respond with the final result in the following format:\n",
    "   Summary (English): [English summary]\n",
    "   Translation (German): [German translation]\n",
    "\n",
    "Do not use any tools after providing the formatted output.\n",
    "\n",
    "{agent_scratchpad}\"\"\"  # Define the template for the agent's instructions\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b7C2Is85CnVG"
   },
   "source": [
    "This prompt template serves as the agent's instruction manual. It clearly defines the workflow (summarize then translate), specifies the exact steps to follow, and establishes the expected output format. The `agent_scratchpad` variable allows the agent to track its progress and reasoning throughout the execution process.\n",
    "\n",
    "### Agent initialization and configuration\n",
    "With our tools and prompt ready, we can now create and configure the agent that will orchestrate our text processing workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "DHAVviwX8Zsz"
   },
   "outputs": [],
   "source": [
    "# Create an agent using the defined tools and prompt - the agent will use these components to make decisions about tool usage\n",
    "agent = create_tool_calling_agent(llm, tools, prompt)\n",
    "\n",
    "# Create an AgentExecutor to run the agent - the executor manages agent runtime behavior and constraints\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agent,  # The agent to execute\n",
    "    tools=tools,  # The tools available to the agent\n",
    "    verbose=True,  # Enable detailed logging of agent actions\n",
    "    max_iterations=3,  # Set maximum number of iterations\n",
    "    early_stopping_method=\"force\"  # Force stop after max_iterations\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l4rJrkFf8ZU3"
   },
   "source": [
    "The `AgentExecutor` acts as a runtime environment for our agent, providing important safeguards like iteration limits and verbose logging. These parameters help us monitor the agent's behavior and prevent runaway execution while maintaining transparency in the decision-making process.\n",
    "\n",
    "### Agent execution function\n",
    "To simplify the process of running our agent with different inputs, we will create a utility function that handles the execution details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "WR16UkOJ8lXK"
   },
   "outputs": [],
   "source": [
    "def run_agent_with_query(agent_executor, query):\n",
    "    \"\"\"\n",
    "    Execute the agent with a given query and return the output.\n",
    "\n",
    "    Args:\n",
    "        agent_executor (AgentExecutor): The configured AgentExecutor to run.\n",
    "        query (str): The input text to be processed by the agent.\n",
    "\n",
    "    Returns:\n",
    "        str: The output generated by the agent after processing the query.\n",
    "    \"\"\"\n",
    "    # Invoke the agent_executor with the query as input - the executor handles all the complexity of agent-tool interaction\n",
    "    result = agent_executor.invoke({\"input\": query})\n",
    "\n",
    "    # Extract and return the 'output' field from the result\n",
    "    return result['output']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bL_Uetlf8nou"
   },
   "source": [
    "This wrapper function abstracts away the details of agent invocation and provides a clean, simple interface for using our text processing system. It handles the execution mechanics and returns just the final result.\n",
    "\n",
    "### Demonstration and testing\n",
    "Finally, let's demonstrate our complete system with a realistic example that shows how all components work together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Kx3KPzJm8nZu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `Summarize` with `{'text': \"The quick brown fox jumps over the lazy dog. This sentence is often used as a pangram in typography to display font examples, as it contains every letter of the English alphabet. However, it's not the only pangram in existence. Another example is 'Pack my box with five dozen liquor jugs', which is shorter but less commonly used.\"}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mThe sentence \"The quick brown fox jumps over the lazy dog\" is a well-known pangram used in typography to showcase fonts, as it includes every letter of the English alphabet. Another, shorter pangram is \"Pack my box with five dozen liquor jugs,\" though it is less commonly used.\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `Translate` with `{'text': \"The quick brown fox jumps over the lazy dog. This sentence is often used as a pangram in typography to display font examples, as it contains every letter of the English alphabet. However, it's not the only pangram in existence. Another example is 'Pack my box with five dozen liquor jugs', which is shorter but less commonly used.\"}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mDer schnelle braune Fuchs springt über den faulen Hund. Dieser Satz wird oft als Pangramm in der Typografie verwendet, um Schriftbeispiele zu zeigen, da er jeden Buchstaben des englischen Alphabets enthält. Es ist jedoch nicht das einzige Pangramm, das existiert. Ein weiteres Beispiel ist „Pack meine Kiste mit fünf Dutzend Schnapskrügen“, das kürzer, aber weniger gebräuchlich ist.\u001b[0m\u001b[32;1m\u001b[1;3mSummary (English): The sentence \"The quick brown fox jumps over the lazy dog\" is a well-known pangram used in typography to showcase fonts, as it includes every letter of the English alphabet. Another, shorter pangram is \"Pack my box with five dozen liquor jugs,\" though it is less commonly used.\n",
      "\n",
      "Translation (German): Der Satz \"Der schnelle braune Fuchs springt über den faulen Hund\" ist ein bekanntes Pangramm, das in der Typografie verwendet wird, um Schriftarten zu präsentieren, da es jeden Buchstaben des englischen Alphabets enthält. Ein weiteres, kürzeres Pangramm ist \"Pack meine Kiste mit fünf Dutzend Schnapskrügen\", das jedoch weniger gebräuchlich ist.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Query:\n",
      "The quick brown fox jumps over the lazy dog. This sentence is often used as a pangram in typography\n",
      "to display font examples, as it contains every letter of the English alphabet. However, it's not the only pangram\n",
      "in existence. Another example is 'Pack my box with five dozen liquor jugs', which is shorter but less commonly used.\n",
      "\n",
      "Result:\n",
      "Summary (English): The sentence \"The quick brown fox jumps over the lazy dog\" is a well-known pangram used in typography to showcase fonts, as it includes every letter of the English alphabet. Another, shorter pangram is \"Pack my box with five dozen liquor jugs,\" though it is less commonly used.\n",
      "\n",
      "Translation (German): Der Satz \"Der schnelle braune Fuchs springt über den faulen Hund\" ist ein bekanntes Pangramm, das in der Typografie verwendet wird, um Schriftarten zu präsentieren, da es jeden Buchstaben des englischen Alphabets enthält. Ein weiteres, kürzeres Pangramm ist \"Pack meine Kiste mit fünf Dutzend Schnapskrügen\", das jedoch weniger gebräuchlich ist.\n"
     ]
    }
   ],
   "source": [
    "# Define the input query\n",
    "query = \"\"\"The quick brown fox jumps over the lazy dog. This sentence is often used as a pangram in typography\n",
    "to display font examples, as it contains every letter of the English alphabet. However, it's not the only pangram\n",
    "in existence. Another example is 'Pack my box with five dozen liquor jugs', which is shorter but less commonly used.\"\"\"\n",
    "\n",
    "# Run the agent with the query\n",
    "result = run_agent_with_query(agent_executor, query)\n",
    "\n",
    "# Print the original query\n",
    "print(\"\\nQuery:\")\n",
    "print(query)\n",
    "\n",
    "# Print the result from the agent\n",
    "print(\"\\nResult:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ThsVIcHu8nF3"
   },
   "source": [
    "This demonstration shows our complete system in action. The agent will automatically recognize that it needs to summarize the text first, then translate that summary into German, and finally present both results in a clear, formatted output. The verbose logging (enabled in our executor configuration) will show each step of the agent's reasoning and tool usage.\n",
    "\n",
    "Looking at our output, the agent made **4 tool calls** but only had **3 iterations** available. Here's the sequence:\n",
    "1. **First call**: `Summarize` with original text\n",
    "2. **Second call**: `Translate` with original text (WRONG - should be summary)\n",
    "3. **Third call**: `Summarize` with original text again (redundant)\n",
    "4. **Fourth call**: `Translate` with the summary (CORRECT)\n",
    "\n",
    "The issue stems from how the agent interpreted the prompt. Despite our clear instructions to:\n",
    "1. Summarize first\n",
    "2. Then translate the summary\n",
    "\n",
    "The agent got confused and made several mistakes:\n",
    "- It translated the **original text** instead of the **summary** in the second call\n",
    "- It repeated the summarization unnecessarily\n",
    "- It eventually figured out the correct workflow but wasted iterations\n",
    "\n",
    "The agent continues iterating when:\n",
    "1. It hasn't completed the task according to its prompt\n",
    "2. It needs to use multiple tools in sequence\n",
    "3. It makes mistakes and needs to correct them\n",
    "4. It hasn't reached the maximum iteration limit\n",
    "\n",
    "The multiple tool invocations show that the agent is reasoning through the problem step by step and it is ensuring it has the right inputs for each tool and providing the correct final output (summary in English + translation in German)."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (langgraph-env)",
   "language": "python",
   "name": "langgraph-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
