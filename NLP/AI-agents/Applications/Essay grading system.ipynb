{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NdtMod1DxTvH"
   },
   "source": [
    "# Essay grading system\n",
    "\n",
    "Essay grading is a time-intensive task that requires evaluating multiple dimensions of writing quality - from basic grammar and structure to more nuanced aspects like relevance and analytical depth. While human graders bring invaluable expertise to this process, they can also introduce inconsistency and are limited by time constraints when dealing with large volumes of essays.\n",
    "\n",
    "This notebook demonstrates how to build an intelligent essay grading agent that leverages LLMs and graph-based workflows to automate the evaluation process. Rather than treating essay grading as a single monolithic task, we break it down into distinct evaluation components - relevance, grammar, structure, and depth of analysis - each handled by specialized functions within a conditional workflow.\n",
    "\n",
    "Our goal is to simulate a nuanced and modular grading process that mirrors how a human evaluator might approach scoring essaysâ€”but built using a graph-based logic where the grading path adapts based on intermediate results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "A6jDk-RmxQBD"
   },
   "outputs": [],
   "source": [
    "from typing import TypedDict\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import re\n",
    "from IPython.display import display, Image\n",
    "from langchain_core.runnables.graph import MermaidDrawMethod\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Configure OpenAI API key for AI model access\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N2zEIDaxxeWu"
   },
   "source": [
    "### State definition\n",
    "The core of our grading system relies on maintaining state throughout the evaluation process. We define a structured state object that tracks both the essay content and all scoring components as the essay moves through different evaluation stages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Pta-dbt-xd7R"
   },
   "outputs": [],
   "source": [
    "# Define the shared state that flows through the graph\n",
    "class State(TypedDict):\n",
    "    \"\"\"Represents the state of the essay grading process.\"\"\"\n",
    "    essay: str  # The original essay text to be graded\n",
    "    relevance_score: float  # Score for topic relevance (0-1)\n",
    "    grammar_score: float  # Score for grammar and language usage (0-1)\n",
    "    structure_score: float  # Score for essay organization and flow (0-1)\n",
    "    depth_score: float  # Score for analytical depth and insight (0-1)\n",
    "    final_score: float  # Weighted final score combining all components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PYu2ev3zxdvB"
   },
   "source": [
    "The `State` class serves as our data container throughout the grading workflow. By using `TypedDict`, we get the benefits of type hints while maintaining the dictionary-like access patterns that work well with LangGraph. Each score field is initialized and updated as the essay progresses through different evaluation stages, creating a comprehensive assessment profile.\n",
    "\n",
    "### Language model initialization\n",
    "We initialize the OpenAI model that will serve as the \"expert grader\" for each component of our evaluation process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "zBj2mhXGxdiy"
   },
   "outputs": [],
   "source": [
    "# Initialize the language model\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini-2024-07-18\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hvSUdSEvxdWO"
   },
   "source": [
    "This model will be called multiple times during the grading process - once for each evaluation component\n",
    "\n",
    "### Define node functions for functions for grading\n",
    "We will create specialized functions for each stage of the essay evaluation. In LangGraph, each step of the process is encapsulated in a node, which performs a specific task like relevance, grammar, structure, and depth. Each function returns the updated state.\n",
    "\n",
    "- Each function takes the current State dictionary, performs a specific analysis on the essay text (e.g. grammar, structure), and updates the state with a corresponding score between 0 and 1.\n",
    "- Before each grading function can assign a score, we need to reliably extract the score from the language model's response. For this, we introduce a helper function, `extract_score`, which uses a regular expression to parse numeric scores prefixed by `Score:`.\n",
    "- Finally, we implement a function to compute the final weighted score, combining the individual scores using a custom weighting scheme: relevance and depth are weighted more heavily, as they often reflect higher-order thinking and topic engagement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "5TYdnQy4xdIq"
   },
   "outputs": [],
   "source": [
    "# Helper function to extract a numeric score from the LLM's response\n",
    "def extract_score(content: str) -> float:\n",
    "    \"\"\"Extract the numeric score from the LLM's response.\"\"\"\n",
    "    # Regex pattern looks for a float or integer following \"Score:\"\n",
    "    match = re.search(r'Score:\\s*(\\d+(\\.\\d+)?)', content)\n",
    "    if match:\n",
    "        return float(match.group(1))\n",
    "    # If no valid score is found, raise an error for graceful handling in caller functions.\n",
    "    raise ValueError(f\"Could not extract score from: {content}\")\n",
    "\n",
    "# Relevance scoring function\n",
    "def check_relevance(state: State) -> State:\n",
    "    \"\"\"Check the relevance of the essay.\"\"\"\n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "        \"Analyze the relevance of the following essay to the given topic. \"\n",
    "        \"Provide a relevance score between 0 and 1. \"\n",
    "        \"Your response should start with 'Score: ' followed by the numeric score, \"\n",
    "        \"then provide your explanation.\\n\\nEssay: {essay}\"\n",
    "    )\n",
    "    # Pass the formatted essay into the LLM and get its response\n",
    "    result = llm.invoke(prompt.format(essay=state[\"essay\"]))\n",
    "    try:\n",
    "        # Try to extract and save the relevance score\n",
    "        state[\"relevance_score\"] = extract_score(result.content)\n",
    "    except ValueError as e:\n",
    "        # Fallback in case of malformed or missing score\n",
    "        print(f\"Error in check_relevance: {e}\")\n",
    "        state[\"relevance_score\"] = 0.0\n",
    "    return state\n",
    "\n",
    "# Grammar scoring function\n",
    "def check_grammar(state: State) -> State:\n",
    "    \"\"\"Check the grammar of the essay.\"\"\"\n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "        \"Analyze the grammar and language usage in the following essay. \"\n",
    "        \"Provide a grammar score between 0 and 1. \"\n",
    "        \"Your response should start with 'Score: ' followed by the numeric score, \"\n",
    "        \"then provide your explanation.\\n\\nEssay: {essay}\"\n",
    "    )\n",
    "    result = llm.invoke(prompt.format(essay=state[\"essay\"]))\n",
    "    try:\n",
    "        state[\"grammar_score\"] = extract_score(result.content)\n",
    "    except ValueError as e:\n",
    "        print(f\"Error in check_grammar: {e}\")\n",
    "        state[\"grammar_score\"] = 0.0\n",
    "    return state\n",
    "\n",
    "# Structure analysis function\n",
    "def analyze_structure(state: State) -> State:\n",
    "    \"\"\"Analyze the structure of the essay.\"\"\"\n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "        \"Analyze the structure of the following essay. \"\n",
    "        \"Provide a structure score between 0 and 1. \"\n",
    "        \"Your response should start with 'Score: ' followed by the numeric score, \"\n",
    "        \"then provide your explanation.\\n\\nEssay: {essay}\"\n",
    "    )\n",
    "    result = llm.invoke(prompt.format(essay=state[\"essay\"]))\n",
    "    try:\n",
    "        state[\"structure_score\"] = extract_score(result.content)\n",
    "    except ValueError as e:\n",
    "        print(f\"Error in analyze_structure: {e}\")\n",
    "        state[\"structure_score\"] = 0.0\n",
    "    return state\n",
    "\n",
    "# Depth of analysis evaluation\n",
    "def evaluate_depth(state: State) -> State:\n",
    "    \"\"\"Evaluate the depth of analysis in the essay.\"\"\"\n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "        \"Evaluate the depth of analysis in the following essay. \"\n",
    "        \"Provide a depth score between 0 and 1. \"\n",
    "        \"Your response should start with 'Score: ' followed by the numeric score, \"\n",
    "        \"then provide your explanation.\\n\\nEssay: {essay}\"\n",
    "    )\n",
    "    result = llm.invoke(prompt.format(essay=state[\"essay\"]))\n",
    "    try:\n",
    "        state[\"depth_score\"] = extract_score(result.content)\n",
    "    except ValueError as e:\n",
    "        print(f\"Error in evaluate_depth: {e}\")\n",
    "        state[\"depth_score\"] = 0.0\n",
    "    return state\n",
    "\n",
    "# Aggregate scores into a single weighted final score\n",
    "def calculate_final_score(state: State) -> State:\n",
    "    \"\"\"Calculate the final score based on individual component scores.\"\"\"\n",
    "    # Weight distribution: Relevance (30%), Grammar (20%), Structure (20%), Depth (30%)\n",
    "    state[\"final_score\"] = (\n",
    "        state[\"relevance_score\"] * 0.3 +\n",
    "        state[\"grammar_score\"] * 0.2 +\n",
    "        state[\"structure_score\"] * 0.2 +\n",
    "        state[\"depth_score\"] * 0.3\n",
    "    )\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tKkb2-FGxc7t"
   },
   "source": [
    "Here, we define all the node functions that form the building blocks of our grading pipeline. Each function takes in a shared `state` dictionary, evaluates one aspect of the essay using a prompt fed into an LLM, and updates the respective score field in the state.\n",
    "- A template prompt is used to instruct the LLM to generate a score and a short justification.\n",
    "- The score is extracted using a regular expression that parses the modelâ€™s response text for the format `\"Score: X\"`.\n",
    "- If parsing fails (e.g., malformed output), the system defaults that score to `0.0` but does not stop the overall grading process.\n",
    "- The `calculate_final_score` function combines all valid scores using weighted averages, where relevance and depth are emphasized more heavily than grammar and structure. These weights can be adjusted based on specific grading requirements or educational contexts.\n",
    "\n",
    "### Workflow definition and graph construction\n",
    "Now that we have all our grading functions, we need to orchestrate them into an intelligent workflow. This section creates the graph structure that defines how essays flow through different evaluation stages based on conditional logic. Instead of evaluating every essay in the exact same way, we want to dynamically adapt the evaluation path based on intermediate results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "S0hKToxuxcs0"
   },
   "outputs": [],
   "source": [
    "# Create the graph by specifying the state type it operates on\n",
    "workflow = StateGraph(State)\n",
    "\n",
    "# Add each grading function as a node in the workflow graph\n",
    "workflow.add_node(\"check_relevance\", check_relevance)\n",
    "workflow.add_node(\"check_grammar\", check_grammar)\n",
    "workflow.add_node(\"analyze_structure\", analyze_structure)\n",
    "workflow.add_node(\"evaluate_depth\", evaluate_depth)\n",
    "workflow.add_node(\"calculate_final_score\", calculate_final_score)\n",
    "\n",
    "# Define conditional edges that determine workflow path based on scores\n",
    "# If relevance is too low (â‰¤0.5), skip detailed analysis and go straight to final scoring\n",
    "workflow.add_conditional_edges(\n",
    "    \"check_relevance\",\n",
    "    lambda x: \"check_grammar\" if x[\"relevance_score\"] > 0.5 else \"calculate_final_score\"\n",
    ")\n",
    "# If grammar is poor (â‰¤0.6), skip structure analysis\n",
    "workflow.add_conditional_edges(\n",
    "    \"check_grammar\",\n",
    "    lambda x: \"analyze_structure\" if x[\"grammar_score\"] > 0.6 else \"calculate_final_score\"\n",
    ")\n",
    "# If structure is poor (â‰¤0.7), skip depth analysis\n",
    "workflow.add_conditional_edges(\n",
    "    \"analyze_structure\",\n",
    "    lambda x: \"evaluate_depth\" if x[\"structure_score\"] > 0.7 else \"calculate_final_score\"\n",
    ")\n",
    "# After depth evaluation, always proceed to final scoring\n",
    "workflow.add_conditional_edges(\n",
    "    \"evaluate_depth\",\n",
    "    lambda x: \"calculate_final_score\"\n",
    ")\n",
    "\n",
    "# Set the entry point for the workflow\n",
    "workflow.set_entry_point(\"check_relevance\")\n",
    "\n",
    "# Connect final scoring to the end of the workflow\n",
    "workflow.add_edge(\"calculate_final_score\", END)\n",
    "\n",
    "# Compile the graph into an executable application\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tScq-lGByZSX"
   },
   "source": [
    "This workflow definition creates an intelligent grading system that can adapt its evaluation depth based on interim results. The conditional logic implements a practical approach: if an essay fails at a fundamental level (poor relevance), there is less value in detailed structural or depth analysis. The threshold values (0.5 for relevance, 0.6 for grammar, 0.7 for structure) can be adjusted based on grading standards and requirements.\n",
    "\n",
    "This logic is expressed using `add_conditional_edges`, which accepts a lambda function that inspects the current state and decides what node to go to next. Each evaluation step updates the shared `state`, which makes the logic clean and easy to trace.\n",
    "\n",
    "The graph structure allows for efficient processing - high-quality essays go through all evaluation stages, while essays with fundamental issues receive faster, but still fair, assessment. This mirrors how experienced human graders might triage essays during the grading process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "av_QBn22xcUJ"
   },
   "source": [
    "### Essay grading function\n",
    "Now that we have defined the full grading pipeline using LangGraphâ€”including the evaluation nodes and the adaptive workflowâ€”it is time to wrap the whole system into a single function: `grade_essay`.\n",
    "\n",
    "The purpose of this function is to provide a simple, clean interface to pass in an essay and receive a fully evaluated score breakdown. Internally, it constructs the initial state (with default scores), triggers the LangGraph `app` we previously compiled, and returns the final evaluated state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "GhOZ_wpqx99t"
   },
   "outputs": [],
   "source": [
    "def grade_essay(essay: str) -> dict:\n",
    "    \"\"\"Grade the given essay using the defined workflow.\"\"\"\n",
    "    # Initialize the state with the essay and zero scores\n",
    "    # All score fields start at 0.0 and will be updated as the workflow progresses.\n",
    "    initial_state = State(\n",
    "        essay=essay,\n",
    "        relevance_score=0.0,\n",
    "        grammar_score=0.0,\n",
    "        structure_score=0.0,\n",
    "        depth_score=0.0,\n",
    "        final_score=0.0\n",
    "    )\n",
    "\n",
    "    # Execute the grading workflow - invoke the LangGraph application with the initial state\n",
    "    result = app.invoke(initial_state)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I7OnNUfkx9rB"
   },
   "source": [
    "This function essentially acts as the entry point for the grading engine. It packages the input essay into a `State` object, initializes all score fields to 0, and runs it through the previously compiled LangGraph workflow.\n",
    "\n",
    "### Sample essay\n",
    "To demonstrate our grading system, we will use a sample essay that covers a relevant topic with reasonable structure and analysis. This allows us to see how the system evaluates a typical academic essay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "wxDw6VB-x9aY"
   },
   "outputs": [],
   "source": [
    "sample_essay = \"\"\"\n",
    "    The Impact of Artificial Intelligence on Modern Society\n",
    "\n",
    "    Artificial Intelligence (AI) has become an integral part of our daily lives,\n",
    "    revolutionizing various sectors including healthcare, finance, and transportation.\n",
    "    This essay explores the profound effects of AI on modern society, discussing both\n",
    "    its benefits and potential challenges.\n",
    "\n",
    "    One of the most significant impacts of AI is in the healthcare industry.\n",
    "    AI-powered diagnostic tools can analyze medical images with high accuracy,\n",
    "    often surpassing human capabilities. This leads to earlier detection of diseases\n",
    "    and more effective treatment plans. Moreover, AI algorithms can process vast\n",
    "    amounts of medical data to identify patterns and insights that might escape\n",
    "    human observation, potentially leading to breakthroughs in drug discovery and\n",
    "    personalized medicine.\n",
    "\n",
    "    In the financial sector, AI has transformed the way transactions are processed\n",
    "    and monitored. Machine learning algorithms can detect fraudulent activities in\n",
    "    real-time, enhancing security for consumers and institutions alike. Robo-advisors\n",
    "    use AI to provide personalized investment advice, democratizing access to\n",
    "    financial planning services.\n",
    "\n",
    "    The transportation industry is another area where AI is making significant strides.\n",
    "    Self-driving cars, powered by complex AI systems, promise to reduce accidents\n",
    "    caused by human error and provide mobility solutions for those unable to drive.\n",
    "    In logistics, AI optimizes routing and inventory management, leading to more\n",
    "    efficient supply chains and reduced environmental impact.\n",
    "\n",
    "    However, the rapid advancement of AI also presents challenges. There are concerns\n",
    "    about job displacement as AI systems become capable of performing tasks\n",
    "    traditionally done by humans. This raises questions about the need for retraining\n",
    "    and reskilling the workforce to adapt to an AI-driven economy.\n",
    "\n",
    "    Privacy and ethical concerns also arise with the increasing use of AI. The vast\n",
    "    amount of data required to train AI systems raises questions about data privacy\n",
    "    and consent. Additionally, there are ongoing debates about the potential biases\n",
    "    in AI algorithms and the need for transparent and accountable AI systems.\n",
    "\n",
    "    In conclusion, while AI offers tremendous benefits and has the potential to solve\n",
    "    some of humanity's most pressing challenges, it also requires careful consideration\n",
    "    of its societal implications. As we continue to integrate AI into various aspects\n",
    "    of our lives, it is crucial to strike a balance between technological advancement\n",
    "    and ethical considerations, ensuring that the benefits of AI are distributed\n",
    "    equitably across society.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "joYcZkWjx9Bg"
   },
   "source": [
    "### Grading the sample essay\n",
    "Finally, we will run our grading system on the sample essay and display the comprehensive results, showing both individual component scores and the final weighted grade.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "FI8VGWZRyNu4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Essay Score: 0.87\n",
      "\n",
      "Relevance Score: 1.00\n",
      "Grammar Score: 0.90\n",
      "Structure Score: 0.90\n",
      "Depth Score: 0.70\n"
     ]
    }
   ],
   "source": [
    "# Grade the sample essay\n",
    "result = grade_essay(sample_essay)\n",
    "\n",
    "# Display the results\n",
    "print(f\"Final Essay Score: {result['final_score']:.2f}\\n\")\n",
    "print(f\"Relevance Score: {result['relevance_score']:.2f}\")\n",
    "print(f\"Grammar Score: {result['grammar_score']:.2f}\")\n",
    "print(f\"Structure Score: {result['structure_score']:.2f}\")\n",
    "print(f\"Depth Score: {result['depth_score']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5kUnkLN-yNY0"
   },
   "source": [
    "This demonstration shows the grading output, providing both the final composite score and the breakdown of individual component scores. This transparency is crucial for educational applications, as it allows students and instructors to understand which aspects of the essay were strong and which areas might need improvement."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (langgraph-env)",
   "language": "python",
   "name": "langgraph-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
