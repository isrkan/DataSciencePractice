{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce2b45d5-b9f8-4b6a-b50b-72972585175e",
   "metadata": {},
   "source": [
    "# Introduction to TensorFlow\n",
    "\n",
    "TensorFlow is a library for numerical computation and deep learning. It is widely used for building deep learning models and it allows developers to create large-scale neural networks with many layers\n",
    "\n",
    "### Why use TensorFlow?\n",
    "\n",
    "- Flexibility: TensorFlow supports both high-level and low-level APIs, allowing to create models using predefined functions or customize them as needed. TensorFlow provides a high-level API (Keras) that makes building and training neural networks simple.\n",
    "- Performance: It can run on various platforms, including CPUs, GPUs, and TPUs, which allows for high performance in different environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9075afb8-f3dd-4cf7-837b-01d788168d6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Importing TensorFlow\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64b6d50-b204-4ce9-96a0-454324ef1983",
   "metadata": {},
   "source": [
    "It is common to import tensorflow with the alias `tf`\n",
    "\n",
    "### Creating tensors\n",
    "Tensors are the core data structures in TensorFlow. They are similar to NumPy arrays but have additional capabilities for GPU acceleration.\n",
    "\n",
    "#### Constant tensor\n",
    "Tensors created with `tf.constant()` are immutable, meaning their values cannot be changed once defined. They are ideal for fixed data that will not be modified during a program's execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e373917-3a88-4ef5-8d66-e48954e77e35",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor: tf.Tensor(\n",
      "[[1 2]\n",
      " [3 4]], shape=(2, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Creating a constant tensor\n",
    "tensor = tf.constant([[1, 2], [3, 4]])\n",
    "print(\"Tensor:\", tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ffebdc-eb22-4c09-9f26-4444f918862b",
   "metadata": {},
   "source": [
    "**Syntax**: `tf.constant(value, dtype=None, shape=None, name='Const')`\n",
    "  - `value`: The initial value of the tensor. This can be a Python list or a NumPy array.\n",
    "  - `dtype`: (Optional) The data type of the elements in the tensor. If not specified, it is inferred from the `value`.\n",
    "  - `shape`: (Optional) The desired shape of the tensor. If not specified, it is inferred from the `value`.\n",
    "  - `name`: (Optional) The name of the operation.\n",
    "  \n",
    "#### Variables\n",
    "Variables are used to store mutable state in TensorFlow. Tensors created with `tf.Variable()` are mutable, allowing their values to be updated. This makes them suitable for parameters that need to be adjusted during training, such as weights and biases in neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66f8421e-d2a6-471e-84b8-29531d1aa426",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\n",
      "array([[1., 2.],\n",
      "       [3., 4.]], dtype=float32)>\n"
     ]
    }
   ],
   "source": [
    "# Creating a variable tensor\n",
    "variable = tf.Variable([[1.0, 2.0], [3.0, 4.0]])\n",
    "print(variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026f659e-0b67-4119-aabd-4c09d0c61a0c",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Syntax**: `tf.Variable(initial_value, trainable=True, name=None, dtype=None)`\n",
    "  - `initial_value`: The initial value of the variable. It can be a constant or a tensor.\n",
    "  - `trainable`: (Optional) If `True`, the variable will be included in the gradient computations.\n",
    "  - `dtype`: (Optional) The data type of the elements in the variable.\n",
    "  \n",
    "Although variable behaves like a tensor in many respects, it has additional capabilities such as being updatable and trackable. The primary difference is that a variable can change its state (value) over time, while a tensor represents a fixed state.\n",
    "\n",
    "#### Random tensors\n",
    "Random tensors are often used for initializing weights in neural networks or generating synthetic data. TensorFlow provides several functions to create random tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eff437be-4736-486b-9274-d355ec209dec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.8434814 0.9683882]\n",
      " [0.5223029 3.1693513]], shape=(2, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[0.57607687 0.9728943 ]\n",
      " [0.09842479 0.9611082 ]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Creating a random tensor with a normal distribution\n",
    "random_tensor = tf.random.normal(shape=(2, 2), mean=0.0, stddev=1.0)\n",
    "print(random_tensor)\n",
    "\n",
    "# Creating a random tensor with a uniform distribution\n",
    "uniform_tensor = tf.random.uniform(shape=(2, 2), minval=0, maxval=1)\n",
    "print(uniform_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4beeb885-9bde-44ef-9c50-240b04b27012",
   "metadata": {},
   "source": [
    "**Syntax** for `tf.random.normal()`: `tf.random.normal(shape, mean=0.0, stddev=1.0, dtype=tf.float32, seed=None, name=None)`\n",
    "  - `shape`: The shape of the output tensor.\n",
    "  - `mean`: The mean of the normal distribution.\n",
    "  - `stddev`: The standard deviation of the normal distribution.\n",
    "  - `seed`: (Optional) A random seed for generating reproducible results.\n",
    "\n",
    "**Syntax** for `tf.random.uniform()`: `tf.random.uniform(shape, minval=0, maxval=None, dtype=tf.float32, seed=None, name=None)`\n",
    "  - `minval`: The lower bound of the uniform distribution.\n",
    "  - `maxval`: The upper bound of the uniform distribution.\n",
    "\n",
    "#### Using built-in functions\n",
    "\n",
    "TensorFlow provides several built-in functions for creating tensors with specific values, which are useful for initializing layers and models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17e09733-08c2-4972-b993-9755ad815719",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor filled with ones:\n",
      " tf.Tensor(\n",
      "[[1. 1. 1.]\n",
      " [1. 1. 1.]\n",
      " [1. 1. 1.]], shape=(3, 3), dtype=float32)\n",
      "Tensor filled with zeros:\n",
      " tf.Tensor(\n",
      "[[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]], shape=(3, 3), dtype=float32)\n",
      "Tensor filled with value 9:\n",
      " tf.Tensor(\n",
      "[[9 9]\n",
      " [9 9]], shape=(2, 2), dtype=int32)\n",
      "Identity matrix:\n",
      " tf.Tensor(\n",
      "[[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]], shape=(3, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Creating a tensor filled with ones\n",
    "ones_tensor = tf.ones(shape=(3, 3))\n",
    "print(\"Tensor filled with ones:\\n\", ones_tensor)\n",
    "\n",
    "# Creating a tensor filled with zeros\n",
    "zeros_tensor = tf.zeros(shape=(3, 3))\n",
    "print(\"Tensor filled with zeros:\\n\", zeros_tensor)\n",
    "\n",
    "# Creating a tensor filled with a specified value\n",
    "filled_tensor = tf.fill([2, 2], value=9)\n",
    "print(\"Tensor filled with value 9:\\n\", filled_tensor)\n",
    "\n",
    "# Creating an identity matrix\n",
    "identity_tensor = tf.eye(3)\n",
    "print(\"Identity matrix:\\n\", identity_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205bb108-9825-477f-bfdf-f33831a22d4e",
   "metadata": {},
   "source": [
    "### Setting the seed\n",
    "Setting a seed ensures that random operations produce the same results each time they are run. This is crucial for reproducibility in experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba284df9-0ee8-415c-9110-2d9e9fcf4367",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 0.3274685 -0.8426258]\n",
      " [ 0.3194337 -1.4075519]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Setting the global random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Creating a random tensor with a set seed\n",
    "random_tensor_seeded = tf.random.normal(shape=(2, 2))\n",
    "print(random_tensor_seeded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb28496d-65a2-47fc-aedf-b021a4c98c55",
   "metadata": {},
   "source": [
    "**Syntax**: `tf.random.set_seed(seed)`\n",
    "  - `seed`: An integer value used to initialize the random number generator. This value determines the sequence of random numbers generated.\n",
    "\n",
    "### Shuffling a tensor\n",
    "\n",
    "Shuffling is important in machine learning to prevent the model from learning patterns in the order of the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73e068dd-95cc-4db8-af48-f92a57cfc16d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[5 6]\n",
      " [1 2]\n",
      " [7 8]\n",
      " [3 4]], shape=(4, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Creating a tensor\n",
    "data_tensor = tf.constant([[1, 2], [3, 4], [5, 6], [7, 8]])\n",
    "\n",
    "# Shuffling the tensor\n",
    "shuffled_tensor = tf.random.shuffle(data_tensor)\n",
    "print(shuffled_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1388c4c3-9bbc-47ef-9865-144435d0f6a9",
   "metadata": {},
   "source": [
    "**Syntax**: `tf.random.shuffle(value, seed=None, name=None)`\n",
    "  - `value`: The input tensor to shuffle.\n",
    "  - `seed`: (Optional) An integer seed for the shuffle operation to produce reproducible results.\n",
    "  - `name`: (Optional) A name for the operation.\n",
    "\n",
    "We can set an operation-level seed to ensure specific operations produce the same result independently of global seeds. To achieve reproducibility, it's often necessary to set both a global seed and an operation-specific seed. This approach ensures that your random operations yield the same results across different runs.\n",
    "\n",
    "- Global seed: By setting a global seed using `tf.random.set_seed(42)`, we make sure that TensorFlow's random number generation is consistent across different runs.\n",
    "- Operation seed: An additional seed on specific operations (`seed=24` in `tf.random.shuffle`) ensures that particular operations behave consistently each time they are executed within the same global context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be12cebd-6823-450c-b903-99090ea7e57c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[3 4]\n",
      " [1 2]\n",
      " [5 6]\n",
      " [7 8]], shape=(4, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Setting the global random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Setting a random seed for the shuffle operation\n",
    "shuffled_tensor_seeded = tf.random.shuffle(data_tensor, seed=24)\n",
    "print(shuffled_tensor_seeded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f6ec1a-d366-4c43-ba95-f4fe40d05d6c",
   "metadata": {},
   "source": [
    "### Tensor attributes\n",
    "Tensors have several important attributes that provide information about their properties. Understanding these attributes is crucial for working effectively with TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c6494b8-d787-49c8-863e-25f6afe240b4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the tensor: (2, 3)\n",
      "Data type of the tensor: <dtype: 'int32'>\n",
      "Rank of the tensor: tf.Tensor(2, shape=(), dtype=int32)\n",
      "Rank of the tensor using ndim: 2\n",
      "Size of the tensor: 6\n"
     ]
    }
   ],
   "source": [
    "example_tensor = tf.constant([[1, 2, 3], [4, 5, 6]])\n",
    "\n",
    "# Shape\n",
    "print(\"Shape of the tensor:\", example_tensor.shape)\n",
    "\n",
    "# Data type\n",
    "print(\"Data type of the tensor:\", example_tensor.dtype)\n",
    "\n",
    "# Rank (number of dimensions)\n",
    "print(\"Rank of the tensor:\", tf.rank(example_tensor))\n",
    "# Rank using ndim\n",
    "print(\"Rank of the tensor using ndim:\", example_tensor.ndim)\n",
    "\n",
    "# Size (total number of elements)\n",
    "print(\"Size of the tensor:\", tf.size(example_tensor).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7698e262-d435-4e5f-ba30-59048822ff2b",
   "metadata": {},
   "source": [
    "- **Shape**: The shape of a tensor is a tuple of integers that describes the number of elements in each dimension. It can be accessed using the `shape` attribute. For example, the shape of a 2x3 matrix is `(2, 3)`.\n",
    "- **Data type**: The data type (`dtype`) of a tensor indicates the type of elements contained in the tensor, such as `tf.int32`, `tf.float32`, etc. It is important to ensure that operations are performed on compatible data types.\n",
    "- **Rank**: The rank of a tensor refers to the number of dimensions it has. For instance, a scalar has a rank of 0, a vector has a rank of 1, and a matrix has a rank of 2.\n",
    "- **Size**: The size of a tensor represents the total number of elements in the tensor. It can be determined using `tf.size()` and is useful for understanding the overall data volume.\n",
    "\n",
    "### Converting data types in tensors\n",
    "In TensorFlow, tensors can have different data types such as `float32`, `int32`, `int64`, etc. Converting tensors between these data types can be necessary for various reasons, such as ensuring compatibility with specific operations, reducing memory usage, or meeting the requirements of a model or algorithm.\n",
    "\n",
    "#### Casting\n",
    "The primary method to change the data type of a tensor is using the `tf.cast` function. This function casts a tensor to a specified data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "36c5e614-d76d-4c5a-9b55-7dc7fa004d20",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor (float32):\n",
      " tf.Tensor([1.5 2.5 3.5], shape=(3,), dtype=float32)\n",
      "Cast tensor (int32):\n",
      " tf.Tensor([1 2 3], shape=(3,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Original tensor with float32 data type\n",
    "tensor_float = tf.constant([1.5, 2.5, 3.5], dtype=tf.float32)\n",
    "print(\"Original tensor (float32):\\n\", tensor_float)\n",
    "\n",
    "# Casting tensor to int32\n",
    "tensor_int = tf.cast(tensor_float, dtype=tf.int32)\n",
    "print(\"Cast tensor (int32):\\n\", tensor_int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4beaa1-8797-443c-893a-830c9ee900fb",
   "metadata": {},
   "source": [
    "**Syntax**: `tf.cast(tensor, dtype)`\n",
    "  - `tensor`: The tensor whose data type you want to change.\n",
    "  - `dtype`: The desired data type.\n",
    "  \n",
    "When converting from a higher precision data type (e.g., `float64`) to a lower precision data type (e.g., `float32` or `int32`), there may be a loss of precision.\n",
    "\n",
    "#### Converting to floating-point types\n",
    "Converting integers to floating-point types can be necessary for computations that require decimal precision, such as in neural network training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8dd66e9-222e-454e-8813-f19d9f134c51",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor (int32):\n",
      " tf.Tensor([1 2 3], shape=(3,), dtype=int32)\n",
      "Cast tensor (float32):\n",
      " tf.Tensor([1. 2. 3.], shape=(3,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Original tensor with int32 data type\n",
    "tensor_int = tf.constant([1, 2, 3], dtype=tf.int32)\n",
    "print(\"Original tensor (int32):\\n\", tensor_int)\n",
    "\n",
    "# Casting tensor to float32\n",
    "tensor_float = tf.cast(tensor_int, dtype=tf.float32)\n",
    "print(\"Cast tensor (float32):\\n\", tensor_float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2dcf4f-8e69-4f35-8ec5-81e4cf54201c",
   "metadata": {},
   "source": [
    "#### Converting to boolean type\n",
    "Boolean type conversion is useful for conditions or mask operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d047bae-9a56-4dfd-a401-4bf402d7917e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor (float32):\n",
      " tf.Tensor([0. 1. 2.], shape=(3,), dtype=float32)\n",
      "Cast tensor (bool):\n",
      " tf.Tensor([False  True  True], shape=(3,), dtype=bool)\n"
     ]
    }
   ],
   "source": [
    "# Original tensor with float32 data type\n",
    "tensor_float = tf.constant([0.0, 1.0, 2.0], dtype=tf.float32)\n",
    "print(\"Original tensor (float32):\\n\", tensor_float)\n",
    "\n",
    "# Casting tensor to boolean\n",
    "tensor_bool = tf.cast(tensor_float, dtype=tf.bool)\n",
    "print(\"Cast tensor (bool):\\n\", tensor_bool)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bac160a-5c60-4bac-b5d8-8c060388aca1",
   "metadata": {},
   "source": [
    "### Tensor operations\n",
    "We can perform various mathematical operations with tensors. TensorFlow operations are functions that take tensors as input and produce tensors as output.\n",
    "\n",
    "#### Element-wise operations\n",
    "Element-wise operations are performed on corresponding elements of tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0147c787-4a42-4e57-a93d-34020b29ce3e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Addition:\n",
      " tf.Tensor(\n",
      "[[ 6 -4]\n",
      " [10 12]], shape=(2, 2), dtype=int32)\n",
      "Subtraction:\n",
      " tf.Tensor(\n",
      "[[-4  8]\n",
      " [-4 -4]], shape=(2, 2), dtype=int32)\n",
      "Multiplication:\n",
      " tf.Tensor(\n",
      "[[  5 -12]\n",
      " [ 21  32]], shape=(2, 2), dtype=int32)\n",
      "Division:\n",
      " tf.Tensor(\n",
      "[[ 0.2        -0.33333333]\n",
      " [ 0.42857143  0.5       ]], shape=(2, 2), dtype=float64)\n",
      "Exponentiation:\n",
      " tf.Tensor(\n",
      "[[ 1  4]\n",
      " [ 9 16]], shape=(2, 2), dtype=int32)\n",
      "Absolute value:\n",
      " tf.Tensor(\n",
      "[[5 6]\n",
      " [7 8]], shape=(2, 2), dtype=int32)\n",
      "Cumulative sum:\n",
      " tf.Tensor(\n",
      "[[1 2]\n",
      " [4 6]], shape=(2, 2), dtype=int32)\n",
      "Cumulative product:\n",
      " tf.Tensor(\n",
      "[[1 2]\n",
      " [3 8]], shape=(2, 2), dtype=int32)\n",
      "Square root:\n",
      " tf.Tensor(\n",
      "[[1.        1.4142135]\n",
      " [1.7320508 2.       ]], shape=(2, 2), dtype=float32)\n",
      "Logarithm:\n",
      " tf.Tensor(\n",
      "[[0.        0.6931472]\n",
      " [1.0986123 1.3862944]], shape=(2, 2), dtype=float32)\n",
      "Exponential:\n",
      " tf.Tensor(\n",
      "[[ 2.7182817  7.389056 ]\n",
      " [20.085537  54.59815  ]], shape=(2, 2), dtype=float32)\n",
      "Reciprocal (1/x):\n",
      " tf.Tensor(\n",
      "[[1.         0.5       ]\n",
      " [0.33333334 0.25      ]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Arithmetic operations\n",
    "a = tf.constant([[1, 2], [3, 4]])\n",
    "b = tf.constant([[5, -6], [7, 8]])\n",
    "\n",
    "print(\"Addition:\\n\", tf.add(a, b))\n",
    "print(\"Subtraction:\\n\", tf.subtract(a, b))\n",
    "print(\"Multiplication:\\n\", tf.multiply(a, b))\n",
    "print(\"Division:\\n\", tf.divide(a, b))\n",
    "print(\"Exponentiation:\\n\", tf.math.pow(a, 2))\n",
    "print(\"Absolute value:\\n\", tf.math.abs(b))\n",
    "print(\"Cumulative sum:\\n\", tf.math.cumsum(a, axis=0))\n",
    "print(\"Cumulative product:\\n\", tf.math.cumprod(a, axis=0))\n",
    "\n",
    "print(\"Square root:\\n\", tf.math.sqrt(tf.cast(a, dtype=tf.float32)))\n",
    "print(\"Logarithm:\\n\", tf.math.log(tf.cast(a, dtype=tf.float32)))\n",
    "print(\"Exponential:\\n\", tf.math.exp(tf.cast(a, dtype=tf.float32)))\n",
    "print(\"Reciprocal (1/x):\\n\", tf.math.reciprocal(tf.cast(a, dtype=tf.float32)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400c6f25-befb-4cfa-8ee1-a3b3508832a2",
   "metadata": {},
   "source": [
    "#### Matrix operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d44fa33-5171-46b2-9d1c-c6f0f71f7df1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix multiplication using 'matmul':\n",
      " tf.Tensor(\n",
      "[[19 22]\n",
      " [43 50]], shape=(2, 2), dtype=int32)\n",
      "Matrix multiplication using 'tensordot':\n",
      " tf.Tensor(\n",
      "[[19 22]\n",
      " [43 50]], shape=(2, 2), dtype=int32)\n",
      "Transpose:\n",
      " tf.Tensor(\n",
      "[[1 3]\n",
      " [2 4]], shape=(2, 2), dtype=int32)\n",
      "Inverse matrix:\n",
      " tf.Tensor(\n",
      "[[-2.0000002   1.0000001 ]\n",
      " [ 1.5000001  -0.50000006]], shape=(2, 2), dtype=float32)\n",
      "Determinant:\n",
      " tf.Tensor(-2.0, shape=(), dtype=float32)\n",
      "Trace:\n",
      " tf.Tensor(5, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant([[1, 2], [3, 4]])\n",
    "b = tf.constant([[5, 6], [7, 8]])\n",
    "\n",
    "print(\"Matrix multiplication using 'matmul':\\n\", tf.matmul(a, b))\n",
    "print(\"Matrix multiplication using 'tensordot':\\n\", tf.tensordot(a, b, axes=1))\n",
    "print(\"Transpose:\\n\", tf.transpose(a))\n",
    "print(\"Inverse matrix:\\n\", tf.linalg.inv(tf.cast(a, dtype=tf.float32)))\n",
    "print(\"Determinant:\\n\", tf.linalg.det(tf.cast(a, dtype=tf.float32)))\n",
    "print(\"Trace:\\n\", tf.linalg.trace(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8967fb-4f58-42ac-a47f-ebd3049bc76c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Indexing and slicing tensors\n",
    "\n",
    "* Indexing allows us to access specific elements or sub-tensors within a larger tensor. TensorFlow supports various indexing techniques similar to those used in NumPy.\n",
    "* Slicing allows us to extract a sub-tensor from a larger tensor based on specified ranges of indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f756c82e-356f-4846-b12c-a13b47334e88",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Element:\n",
      " tf.Tensor(2, shape=(), dtype=int32)\n",
      "Row:\n",
      " tf.Tensor([5 6 7 8], shape=(4,), dtype=int32)\n",
      "Column:\n",
      " tf.Tensor([3 7], shape=(2,), dtype=int32)\n",
      "Selected elements:\n",
      " tf.Tensor(\n",
      "[[2 1]\n",
      " [6 5]], shape=(2, 2), dtype=int32)\n",
      "Sliced tensor:\n",
      " tf.Tensor([2 3], shape=(2,), dtype=int32)\n",
      "Sliced tensor with step:\n",
      " tf.Tensor(\n",
      "[[1 3]\n",
      " [5 7]], shape=(2, 2), dtype=int32)\n",
      "Sliced tensor with tf.slice:\n",
      " tf.Tensor([[2 3]], shape=(1, 2), dtype=int32)\n",
      "Multi-Dimensional Sliced Tensor:\n",
      " tf.Tensor(\n",
      "[[[1 2 3]]\n",
      "\n",
      " [[7 8 9]]], shape=(2, 1, 3), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Creating a tensor\n",
    "tensor = tf.constant([[1, 2, 3, 4], [5, 6, 7, 8]])\n",
    "\n",
    "# Indexing\n",
    "print(\"Element:\\n\", tensor[0, 1]) # Accessing a specific element - element at row 0, column 1\n",
    "print(\"Row:\\n\", tensor[1]) # Accessing a row - entire row 1\n",
    "print(\"Column:\\n\", tensor[:, 2]) # Accessing a column - entire column 2\n",
    "print(\"Selected elements:\\n\", tf.gather(tensor, [1, 0], axis=1)) # Indexing with a list\n",
    "\n",
    "# Slicing\n",
    "print(\"Sliced tensor:\\n\", tensor[0, 1:3]) # Slicing a sub-tensor - elements from index 1 to 2 in row 0\n",
    "print(\"Sliced tensor with step:\\n\", tensor[:, 0:4:2]) # Slicing with step size - every second element in each row\n",
    "print(\"Sliced tensor with tf.slice:\\n\", tf.slice(tensor, begin=[0, 1], size=[1, 2])) # Slicing with tf.slice - starting from (0, 1) with size (1, 2)\n",
    "\n",
    "# Multi-dimensional slicing\n",
    "tensor = tf.constant([[[1, 2, 3], [4, 5, 6]], [[7, 8, 9], [10, 11, 12]]])\n",
    "print(\"Multi-Dimensional Sliced Tensor:\\n\", tensor[0:2, 0:1, :]) # Slicing in 3D tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13113ca8-7e31-4b1c-9f87-eb56130f1fcf",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Indexing\n",
    "- Access individual elements or slices of a tensor using Python indexing.\n",
    "    - **Syntax**: `tensor[index]`\n",
    "      - `index`: The position of the element or slice to access.\n",
    "\n",
    "- `tf.gather()` allows for advanced indexing by gathering slices from the tensor along a specified axis.\n",
    "    - **Syntax**: `tf.gather(params, indices, axis)`\n",
    "      - `params`: The tensor to gather slices from.\n",
    "      - `indices`: The indices of the slices to gather.\n",
    "      - `axis`: The axis along which to gather slices.\n",
    "      \n",
    "##### Slicing\n",
    "- Extract sub-tensors by specifying ranges for each dimension.\n",
    "    - **Syntax**: `tensor[start:stop:step]`\n",
    "      - `start`: The starting index.\n",
    "      - `stop`: The ending index.\n",
    "      - `step`: (Optional) The step size between indices.\n",
    "\n",
    "- The `tf.slice()` function provides more explicit control over slicing by specifying offsets and sizes for each dimension.\n",
    "    - **Syntax**: `tf.slice(input_, begin, size)`\n",
    "      - `input_`: The tensor to slice.\n",
    "      - `begin`: A list or tensor specifying the starting indices.\n",
    "      - `size`: A list or tensor specifying the size of the slice.\n",
    "      \n",
    "### Broadcasting\n",
    "Broadcasting is a feature in TensorFlow (and in other numerical computing libraries like NumPy) that allows for element-wise operations on tensors of different shapes. Broadcasting enables us to perform arithmetic operations on tensors without requiring explicit reshaping or replication of data, simplifying code and improving performance.\n",
    "\n",
    "When tensors with different shapes are involved in an operation, TensorFlow automatically adjusts their shapes to make them compatible. This adjustment is done according to specific rules, which involve expanding dimensions and replicating data where necessary.\n",
    "\n",
    "The broadcasting rules are:\n",
    "1. If the tensors have different ranks (number of dimensions), the shape of the tensor with fewer dimensions is padded with ones on the left side until both shapes have the same length.\n",
    "2. Tensors are compatible when:\n",
    "   - The sizes of the dimensions are equal, or\n",
    "   - One of the sizes is 1.\n",
    "3. If the dimensions of the tensors are not compatible according to these rules, broadcasting is not possible, and an error will be raised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "970309ec-93e3-4a3a-8da6-9b907d5f6814",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Broadcasting scalar:\n",
      " tf.Tensor(\n",
      "[[6 7]\n",
      " [8 9]], shape=(2, 2), dtype=int32)\n",
      "\n",
      "Broadcasting vector:\n",
      " tf.Tensor(\n",
      "[[11 22 33]\n",
      " [14 25 36]], shape=(2, 3), dtype=int32)\n",
      "\n",
      "Broadcasting different shapes:\n",
      " tf.Tensor(\n",
      "[[11 21 31]\n",
      " [12 22 32]\n",
      " [13 23 33]], shape=(3, 3), dtype=int32)\n",
      "\n",
      "Broadcasting with explicit reshaping:\n",
      " tf.Tensor(\n",
      "[[11 12]\n",
      " [23 24]], shape=(2, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "### Example 1: Scalar and tensor\n",
    "tensor = tf.constant([[1, 2], [3, 4]])\n",
    "scalar = tf.constant(5)\n",
    "\n",
    "# Broadcasting scalar to add to each element of the tensor\n",
    "result = tensor + scalar\n",
    "print(\"Broadcasting scalar:\\n\", result)\n",
    "\n",
    "\n",
    "### Example 2: Vector and matrix\n",
    "matrix = tf.constant([[1, 2, 3], [4, 5, 6]])\n",
    "vector = tf.constant([10, 20, 30])\n",
    "\n",
    "# Broadcasting vector to add to each row of the matrix\n",
    "result = matrix + vector\n",
    "print(\"\\nBroadcasting vector:\\n\", result)\n",
    "\n",
    "\n",
    "### Example 3: Different shapes\n",
    "tensor1 = tf.constant([[1], [2], [3]])   # Shape (3, 1)\n",
    "tensor2 = tf.constant([10, 20, 30])      # Shape (3,)\n",
    "\n",
    "# Broadcasting tensor2 to add to each column of tensor1\n",
    "result = tensor1 + tensor2\n",
    "print(\"\\nBroadcasting different shapes:\\n\", result)\n",
    "\n",
    "\n",
    "### Example 4: Broadcasting with explicit reshaping\n",
    "tensor1 = tf.constant([[1, 2], [3, 4]])          # Shape (2, 2)\n",
    "tensor2 = tf.constant([10, 20])                  # Shape (2,)\n",
    "# Reshaping tensor2 to match tensor1 for broadcasting\n",
    "tensor2_reshaped = tf.reshape(tensor2, shape=(2, 1))\n",
    "\n",
    "# Broadcasting reshaped tensor2 to add to tensor1\n",
    "result = tensor1 + tensor2_reshaped\n",
    "print(\"\\nBroadcasting with explicit reshaping:\\n\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78301718-8693-44ca-9c96-8766fcb0e743",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Explanations\n",
    "\n",
    "1. Example 1: scalar and tensor\n",
    "   - Rule applied: Scalars are automatically broadcast to any shape. This is because a scalar can be thought of as a tensor with shape `()`, and it can expand to match any tensor’s shape.\n",
    "   - Explanation: The scalar `5` is broadcast to match the shape of the tensor `[[1, 2], [3, 4]]`, which has a shape of `(2, 2)`. The scalar is conceptually expanded to a 2x2 tensor `[[5, 5], [5, 5]]` and then added element-wise, resulting in `[[6, 7], [8, 9]]`.\n",
    "\n",
    "2. Example 2: Vector and matrix\n",
    "\n",
    "   - Rule applied: When the dimensions are different, the smaller tensor (vector) is padded with ones on the left, turning `(3,)` into `(1, 3)`. The vector can then be broadcast across the matrix rows.\n",
    "   - Explanation: The vector `[10, 20, 30]` with shape `(3,)` is effectively reshaped to `(1, 3)` to match the shape of the matrix `(2, 3)`. It is then broadcast to match the matrix dimensions by replicating the vector along the new axis. This results in each row of the matrix having `[10, 20, 30]` added to it, yielding `[[11, 22, 33], [14, 25, 36]]`.\n",
    "\n",
    "3. Example 3: Different shapes\n",
    "\n",
    "   - Rule applied: One of the dimensions is 1. This allows `tensor2` to be broadcast along the second dimension of `tensor1`.\n",
    "   - Explanation: `tensor1` has shape `(3, 1)`, and `tensor2` has shape `(3,)`. The shape `(3,)` is interpreted as `(1, 3)`. The first dimension of `tensor1` matches, and the second dimension is broadcast by expanding `tensor2` across each row. This results in adding `tensor2` to each row of `tensor1`, resulting in a shape of `(3, 3)`, where the output is `[[11, 12, 13], [22, 23, 24], [33, 34, 35]]`.\n",
    "\n",
    "4. Example 4: Broadcasting with explicit reshaping\n",
    "\n",
    "   - Rule applied: Reshaping helps manually adjust dimensions to fit broadcasting rules.\n",
    "   - Explanation: `tensor1` has shape `(2, 2)`, and `tensor2` has shape `(2,)`, which we reshape to `(2, 1)` to align with the first dimension of `tensor1`. Now `tensor2_reshaped` can be broadcast to `(2, 2)`. Each element of `tensor2_reshaped` is broadcasted across the columns of `tensor1`. The operation adds the reshaped `tensor2` to each column, resulting in `[[11, 12], [23, 24]]`.\n",
    "   \n",
    "### Reshaping tensors\n",
    "Reshaping tensors allows us to change the shape of a tensor without altering its data. Reshaping is often necessary when preparing data for model input or when manipulating data to perform specific operations. A tensor's shape describes the size of each dimension. Reshaping involves changing the dimensions while keeping the total number of elements constant. This means the product of the dimensions before and after reshaping must be the same. The primary function for reshaping tensors in TensorFlow is `tf.reshape()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "81d30fce-6322-403d-8282-e427eb9ded40",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flattened tensor:\n",
      " tf.Tensor([1 2 3 4 5 6], shape=(6,), dtype=int32)\n",
      "Reshaped tensor to 2D:\n",
      " tf.Tensor(\n",
      "[[1 2 3]\n",
      " [4 5 6]], shape=(2, 3), dtype=int32)\n",
      "3D Tensor with added dimension:\n",
      " tf.Tensor(\n",
      "[[[1]\n",
      "  [2]\n",
      "  [3]]\n",
      "\n",
      " [[4]\n",
      "  [5]\n",
      "  [6]]], shape=(2, 3, 1), dtype=int32)\n",
      "Reshaped tensor with inferred dimension:\n",
      " tf.Tensor(\n",
      "[[1 2 3 4]\n",
      " [5 6 7 8]], shape=(2, 4), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "#### Example 1: Flattening a tensor\n",
    "# Creating a 2D tensor\n",
    "tensor_2d = tf.constant([[1, 2], [3, 4], [5, 6]])\n",
    "\n",
    "# Reshaping to a 1D tensor (flattening)\n",
    "flattened_tensor = tf.reshape(tensor_2d, [-1])\n",
    "print(\"Flattened tensor:\\n\", flattened_tensor)\n",
    "\n",
    "\n",
    "#### Example 2: Changing dimensions\n",
    "# Creating a 1D tensor\n",
    "tensor_1d = tf.constant([1, 2, 3, 4, 5, 6])\n",
    "\n",
    "# Reshaping to a 2D tensor\n",
    "reshaped_tensor = tf.reshape(tensor_1d, [2, 3])\n",
    "print(\"Reshaped tensor to 2D:\\n\", reshaped_tensor)\n",
    "\n",
    "\n",
    "#### Example 3: Adding a dimension\n",
    "# Creating a 2D tensor\n",
    "tensor_2d = tf.constant([[1, 2, 3], [4, 5, 6]])\n",
    "\n",
    "# Adding a new dimension to create a 3D tensor\n",
    "reshaped_tensor = tf.reshape(tensor_2d, [2, 3, 1])\n",
    "print(\"3D Tensor with added dimension:\\n\", reshaped_tensor)\n",
    "\n",
    "\n",
    "#### Example 4: Using `-1` for automatic inference\n",
    "# Creating a 3D tensor\n",
    "tensor_3d = tf.constant([[[1, 2], [3, 4]], [[5, 6], [7, 8]]])\n",
    "\n",
    "# Reshaping using -1 for automatic inference\n",
    "reshaped_tensor = tf.reshape(tensor_3d, [2, -1])\n",
    "print(\"Reshaped tensor with inferred dimension:\\n\", reshaped_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ade4254-6c52-4d2e-8663-5c3ad21ef7d5",
   "metadata": {},
   "source": [
    "- **Syntax**: `tf.reshape(tensor, shape)`\n",
    "  - `tensor`: The tensor to reshape.\n",
    "  - `shape`: A list or tuple specifying the new shape.\n",
    "  \n",
    "##### Explanations\n",
    "1. Example 1: Flattening a tensor involves converting a multi-dimensional tensor into a 1D tensor. This is useful when we need to feed data into a neural network layer that requires a vector input. The shape `[-1]` automatically infers the size needed to flatten the tensor into a 1D array, resulting in `[1, 2, 3, 4, 5, 6]`.\n",
    "2. Example 2: We can change the dimensions of a tensor, provided the total number of elements remains the same. The original tensor with shape `(6,)` is reshaped to `(2, 3)`, resulting in a 2D tensor `[[1, 2, 3], [4, 5, 6]]`.\n",
    "3. Example 3: Adding a new dimension can be useful for adjusting the shape to fit model input requirements. The tensor is reshaped from `(2, 3)` to `(2, 3, 1)`, adding a new dimension without changing the total number of elements.\n",
    "4. Example 4: The `-1` in the shape allows TensorFlow to infer the appropriate size for that dimension. The original tensor with shape `(2, 2, 2)` is reshaped to `(2, 4)`, where `-1` infers the second dimension.\n",
    "\n",
    "### Squeezing a tensor\n",
    "Squeezing a tensor involves removing dimensions of size 1 from its shape. This operation is useful when we need to simplify the tensor's shape, often to make it compatible with certain operations or layers. The `tf.squeeze()` function removes all dimensions with size 1 from a tensor's shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "de9c1654-ba8e-4300-901a-2449b0ceb713",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Squeezed tensor:\n",
      " tf.Tensor([1 2 3], shape=(3,), dtype=int32)\n",
      "Tensor squeezed at axis 0:\n",
      " tf.Tensor(\n",
      "[[1]\n",
      " [2]\n",
      " [3]], shape=(3, 1), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "#### Example 1: Squeezing all single dimensions\n",
    "# Creating a tensor with single dimensions\n",
    "tensor = tf.constant([[[1], [2], [3]]])  # Shape (1, 3, 1)\n",
    "\n",
    "# Squeezing all dimensions of size 1\n",
    "squeezed_tensor = tf.squeeze(tensor)\n",
    "print(\"Squeezed tensor:\\n\", squeezed_tensor)\n",
    "\n",
    "\n",
    "#### Example 2: Squeezing specific dimensions\n",
    "# Creating a tensor with single dimensions\n",
    "tensor = tf.constant([[[1], [2], [3]]])  # Shape (1, 3, 1)\n",
    "\n",
    "# Squeezing a specific dimension (e.g., axis 0)\n",
    "squeezed_tensor_axis = tf.squeeze(tensor, axis=0)\n",
    "print(\"Tensor squeezed at axis 0:\\n\", squeezed_tensor_axis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48fb7f00-beec-4a25-bb01-d96a98aefbe2",
   "metadata": {},
   "source": [
    "- **Syntax**: `tf.squeeze(tensor, axis=None)`\n",
    "  - `tensor`: The tensor to squeeze.\n",
    "  - `axis`: (Optional) An integer or list of integers specifying which specific dimensions to squeeze. If not specified, all dimensions with size 1 will be removed.\n",
    "\n",
    "##### Explanations\n",
    "1. Example 1: The tensor with shape `(1, 3, 1)` is squeezed to `(3,)`, removing both dimensions with size 1.\n",
    "2. Example 2: By specifying `axis=0`, only the dimension at position 0 is removed, resulting in a shape of `(3, 1)`.\n",
    "\n",
    "### One-hot encoding\n",
    "One-hot encoding is a technique used to convert categorical data into a format suitable for machine learning models. It transforms each category into a vector where only one element is \"hot\" (set to 1), and all others are \"cold\" (set to 0). The `tf.one_hot()` function creates a one-hot representation of a tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ca71966d-76bf-43ce-9c06-d3148a0ef484",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-hot encoded tensor:\n",
      " tf.Tensor(\n",
      "[[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]], shape=(4, 3), dtype=float32)\n",
      "One-hot encoded tensor with custom axis:\n",
      " tf.Tensor(\n",
      "[[1. 0. 0. 0.]\n",
      " [0. 1. 0. 1.]\n",
      " [0. 0. 1. 0.]], shape=(3, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#### Example 1: Basic one-hot encoding\n",
    "# Indices representing categories\n",
    "indices = tf.constant([0, 1, 2, 1])\n",
    "\n",
    "# One-hot encode with depth of 3\n",
    "one_hot_encoded = tf.one_hot(indices, depth=3)\n",
    "print(\"One-hot encoded tensor:\\n\", one_hot_encoded)\n",
    "\n",
    "\n",
    "#### Example 2: Custom axis for one-hot encoding\n",
    "# Indices representing categories\n",
    "indices = tf.constant([0, 1, 2, 1])\n",
    "\n",
    "# One-hot encode with depth of 3, placing vectors along a new first axis\n",
    "one_hot_encoded_axis = tf.one_hot(indices, depth=3, axis=0)\n",
    "print(\"One-hot encoded tensor with custom axis:\\n\", one_hot_encoded_axis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80a3347-3656-4c83-9097-6075050c19cc",
   "metadata": {},
   "source": [
    "- **Syntax**: `tf.one_hot(indices, depth, axis=None, dtype=tf.float32)`\n",
    "  - `indices`: A tensor of indices to be converted into one-hot vectors.\n",
    "  - `depth`: The number of categories (i.e., the length of the one-hot vectors).\n",
    "  - `axis`: (Optional) The axis to place the one-hot vectors. Defaults to the last axis.\n",
    "  - `dtype`: The data type of the output tensor (default is `tf.float32`).\n",
    "\n",
    "##### Explanations\n",
    "1. Example 1: The `depth` is set to `3`, meaning there are three possible categories (0, 1 and 2). This specifies the length of each one-hot vector. The `indices` tensor `[0, 1, 2, 1]` is one-hot encoded with a `depth` of 3, resulting in a tensor where each index is represented as a one-hot vector. The resulting tensor has a shape of `(4, 3)` because there are four indices and each one is converted to a vector of length `3`.\n",
    "2. Example 2: By setting `axis=0`, the one-hot vectors are arranged along the first axis, resulting in a different tensor structure.\n",
    "\n",
    "### Manipulating variable tensors\n",
    "`tf.Variable` allows us to change the value of the tensor, making it ideal for representing model parameters like weights and biases that need to be updated during training. We can update the value of a `tf.Variable` using TensorFlow operations such as `assign()`, `assign_add()`, and `assign_sub()`. These operations change the state of the variable in place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b527032a-6043-4d64-ad8f-c96166735554",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial variable:\n",
      " <tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\n",
      "array([[1., 2.],\n",
      "       [3., 4.]], dtype=float32)>\n",
      "Updated variable with assign:\n",
      " <tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\n",
      "array([[5., 6.],\n",
      "       [7., 8.]], dtype=float32)>\n",
      "Updated variable with assign_add:\n",
      " <tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\n",
      "array([[6., 7.],\n",
      "       [8., 9.]], dtype=float32)>\n",
      "Updated variable with assign_sub:\n",
      " <tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\n",
      "array([[4., 5.],\n",
      "       [6., 7.]], dtype=float32)>\n"
     ]
    }
   ],
   "source": [
    "# Creating a variable with an initial value\n",
    "variable = tf.Variable([[1.0, 2.0], [3.0, 4.0]])\n",
    "print(\"Initial variable:\\n\", variable)\n",
    "\n",
    "# Assign a new value to the variable\n",
    "variable.assign([[5.0, 6.0], [7.0, 8.0]])\n",
    "print(\"Updated variable with assign:\\n\", variable)\n",
    "\n",
    "# Add to the variable\n",
    "variable.assign_add([[1.0, 1.0], [1.0, 1.0]])\n",
    "print(\"Updated variable with assign_add:\\n\", variable)\n",
    "\n",
    "# Subtract from the variable\n",
    "variable.assign_sub([[2.0, 2.0], [2.0, 2.0]])\n",
    "print(\"Updated variable with assign_sub:\\n\", variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9992014c-46da-407c-a338-149d7e6e8e0f",
   "metadata": {},
   "source": [
    "Methods for updating variables:\n",
    "1. **assign()**: Assigns a new value to the variable.\n",
    "   - **Syntax**: `variable.assign(new_value)`\n",
    "\n",
    "2. **assign_add()**: Adds a value to the current variable.\n",
    "   - **Syntax**: `variable.assign_add(value)`\n",
    "\n",
    "3. **assign_sub()**: Subtracts a value from the current variable.\n",
    "   - **Syntax**: `variable.assign_sub(value)`\n",
    "   \n",
    "The new value assigned to a variable must have the same shape and data type as the variable.\n",
    "   \n",
    "#### Converting variables to tensors\n",
    "A `tf.Variable` can be easily converted to a tensor using the `tf.convert_to_tensor()` function. This is useful for performing tensor operations on variables. When we convert a variable to a tensor, we are creating a tensor that reflects the current value of the variable. This conversion allows us to use the variable's current value in tensor operations that specifically require tensors, such as mathematical operations or when passing data to layers in a neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "58fc5990-120f-46d7-9e7c-07e38332215d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor version:\n",
      " tf.Tensor(\n",
      "[[4. 5.]\n",
      " [6. 7.]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Convert variable to tensor\n",
    "tensor_version = tf.convert_to_tensor(variable)\n",
    "print(\"Tensor version:\\n\", tensor_version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bee2bb9-633e-4e31-a54e-1f1f1e2de456",
   "metadata": {},
   "source": [
    "### TensorFlow interaction with NumPy\n",
    "TensorFlow and NumPy are both libraries for numerical computation in Python, but they are optimized for different tasks. NumPy is excellent for general-purpose numerical computing, while TensorFlow is designed for deep learning and GPU acceleration. TensorFlow and NumPy can interact seamlessly, allowing us to leverage the strengths of both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "635ca84e-6b56-4720-bbc0-9d41c0880518",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy array:\n",
      " [[1 2]\n",
      " [3 4]]\n",
      "TensorFlow tensor from NumPy array:\n",
      " tf.Tensor(\n",
      "[[1 2]\n",
      " [3 4]], shape=(2, 2), dtype=int32)\n",
      "NumPy array from TensorFlow tensor:\n",
      " [[1 2]\n",
      " [3 4]]\n",
      "Using NumPy function on TensorFlow tensor:\n",
      " [[11 12]\n",
      " [13 14]]\n",
      "Using TensorFlow function on NumPy array:\n",
      " tf.Tensor(\n",
      "[[11 12]\n",
      " [13 14]], shape=(2, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Convert the NumPy array to a TensorFlow tensor\n",
    "array = np.array([[1, 2], [3, 4]])\n",
    "print(\"NumPy array:\\n\", array)\n",
    "tensor = tf.convert_to_tensor(array)\n",
    "print(\"TensorFlow tensor from NumPy array:\\n\", tensor)\n",
    "\n",
    "# Convert a TensorFlow tensor to a NumPy array\n",
    "array_from_tensor = tensor.numpy()\n",
    "print(\"NumPy array from TensorFlow tensor:\\n\", array_from_tensor)\n",
    "\n",
    "\n",
    "# Use a NumPy function on a TensorFlow tensor\n",
    "np_result = np.add(tensor, 10)\n",
    "print(\"Using NumPy function on TensorFlow tensor:\\n\", np_result)\n",
    "\n",
    "# Use a TensorFlow function on a NumPy array\n",
    "tf_result = tf.add(array, 10)\n",
    "print(\"Using TensorFlow function on NumPy array:\\n\", tf_result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
