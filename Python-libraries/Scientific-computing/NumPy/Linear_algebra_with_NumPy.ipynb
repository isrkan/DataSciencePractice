{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0167937-d2fb-4f24-ae6f-90a07c5ab390",
   "metadata": {},
   "source": [
    "# Linear algebra with NumPy\n",
    "\n",
    "This notebook will cover linear algebra operations using NumPy. NumPy provides a comprehensive set of linear algebra functions that enable efficient manipulation and computation of matrices and vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad02f34f-e0c5-4065-a129-c8824579bc0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf900911-4c5f-428c-b649-78d6aa1e059a",
   "metadata": {},
   "source": [
    "### Creating vectors and matrices\n",
    "\n",
    "NumPy arrays are used to represent vectors and matrices. We can create them using the `np.array` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9e82c72-2063-4f4a-94ca-64563871dacf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector: [1 2 3]\n",
      "Matrix:\n",
      " [[1 2]\n",
      " [3 4]]\n"
     ]
    }
   ],
   "source": [
    "# Creating a vector\n",
    "vector = np.array([1, 2, 3])\n",
    "print(\"Vector:\", vector)\n",
    "\n",
    "# Creating a matrix\n",
    "matrix = np.array([[1, 2], [3, 4]])\n",
    "print(\"Matrix:\\n\", matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d19686-d669-42d9-8ee8-4dbbf3604b45",
   "metadata": {},
   "source": [
    "## Vector operations\n",
    "\n",
    "- **Dot product**: Computes a scalar value from two arrays. For 1D arrays, it is the inner product. For 2D arrays, it is matrix multiplication.\n",
    "- **Inner product**: Computes a scalar value or a reduced result from higher-dimensional arrays. For 1-D arrays, it is equivalent to the dot product. For higher dimensions, it reduces the last axis of the first array with the second array.\n",
    "- **Outer product**: Produces a matrix from two vectors.\n",
    "- **Vdot product**: Similar to the dot product, but with conjugation for complex numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "403744ab-47cf-4ecd-8362-9ca6c34fbebf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dot product: 32\n",
      "Inner product: 32\n",
      "Outer product:\n",
      " [[ 4  5  6]\n",
      " [ 8 10 12]\n",
      " [12 15 18]]\n",
      "Vdot product: (70-8j)\n"
     ]
    }
   ],
   "source": [
    "# Dot product\n",
    "a = np.array([1, 2, 3])\n",
    "b = np.array([4, 5, 6])\n",
    "dot_product = np.dot(a, b)\n",
    "print(\"Dot product:\", dot_product)\n",
    "\n",
    "# Inner product\n",
    "inner_product = np.inner(a, b)\n",
    "print(\"Inner product:\", inner_product)\n",
    "\n",
    "# Outer product\n",
    "outer_product = np.outer(a, b)\n",
    "print(\"Outer product:\\n\", outer_product)\n",
    "\n",
    "# Vdot product\n",
    "a = np.array([1 + 2j, 3 + 4j])\n",
    "b = np.array([5 + 6j, 7 + 8j])\n",
    "vdot_product = np.vdot(a, b)\n",
    "print(\"Vdot product:\", vdot_product)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1603a4a-5e31-4e89-a413-621bd41fd990",
   "metadata": {},
   "source": [
    "## Vector properties\n",
    "\n",
    "### Norms\n",
    "\n",
    "Norms are used to measure the size or length of vectors and matrices. The most common is the L2 norm, or Euclidean norm. The L2 norm is calculated as the square root of the sum of the squares of the vector's elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64f39efc-c950-459f-afd1-e4cb66ca5977",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2 Norm: 5.0\n"
     ]
    }
   ],
   "source": [
    "# Calculating the norm\n",
    "vector = np.array([3, 4])\n",
    "norm = np.linalg.norm(vector)\n",
    "print(\"L2 Norm:\", norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc17664-40e4-43d9-8f05-6bc7e5813869",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Matrix operations\n",
    "\n",
    "### Matrix multiplication\n",
    "We can perform matrix multiplication using `np.dot`, `@` operator, or `np.matmul`. Each element in the resulting matrix is the dot product of the corresponding row from the first matrix and the column from the second matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e69d342-8181-4205-9c25-b835f7eecf46",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix product using np.dot:\n",
      " [[19 22]\n",
      " [43 50]]\n",
      "Matrix product using @ operator:\n",
      " [[19 22]\n",
      " [43 50]]\n",
      "Matrix product using np.matmul:\n",
      " [[19 22]\n",
      " [43 50]]\n"
     ]
    }
   ],
   "source": [
    "# Matrix multiplication\n",
    "matrix1 = np.array([[1, 2], [3, 4]])\n",
    "matrix2 = np.array([[5, 6], [7, 8]])\n",
    "\n",
    "# Using np.dot\n",
    "product = np.dot(matrix1, matrix2)\n",
    "print(\"Matrix product using np.dot:\\n\", product)\n",
    "\n",
    "# Using @ operator\n",
    "product = matrix1 @ matrix2\n",
    "print(\"Matrix product using @ operator:\\n\", product)\n",
    "\n",
    "# Using np.matmul\n",
    "product_matmul = np.matmul(matrix1, matrix2)\n",
    "print(\"Matrix product using np.matmul:\\n\", product_matmul)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71849b73-8d09-4a42-b9b3-3d2028eb27a4",
   "metadata": {},
   "source": [
    "### Matrix power\n",
    "Matrix power computes the matrix raised to an integer power."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0f44415-1a27-43e0-b376-187395d3aac0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix to the power of 2:\n",
      " [[ 7 10]\n",
      " [15 22]]\n"
     ]
    }
   ],
   "source": [
    "# Matrix power\n",
    "matrix = np.array([[1, 2], [3, 4]])\n",
    "powered_matrix = np.linalg.matrix_power(matrix, 2)\n",
    "print(\"Matrix to the power of 2:\\n\", powered_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c699bef-ba67-4858-bc8c-f5ef94c3b86b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Transpose of a matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4985f9e-fff6-4bbb-9793-5f9f817d80f5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original matrix:\n",
      " [[1 2 3]\n",
      " [4 5 6]]\n",
      "Transposed matrix:\n",
      " [[1 4]\n",
      " [2 5]\n",
      " [3 6]]\n",
      "\n",
      "Original 3D array:\n",
      " [[[1 2]\n",
      "  [3 4]]\n",
      "\n",
      " [[5 6]\n",
      "  [7 8]]]\n",
      "Transposed 3D array:\n",
      " [[[1 2]\n",
      "  [5 6]]\n",
      "\n",
      " [[3 4]\n",
      "  [7 8]]]\n"
     ]
    }
   ],
   "source": [
    "# 2D array transpose\n",
    "matrix = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "print(\"Original matrix:\\n\", matrix)\n",
    "transposed_matrix = matrix.T\n",
    "print(\"Transposed matrix:\\n\", transposed_matrix)\n",
    "\n",
    "# Higher-dimensional array transpose\n",
    "array_3d = np.array([[[1, 2], [3, 4]], [[5, 6], [7, 8]]])\n",
    "print(\"\\nOriginal 3D array:\\n\", array_3d)\n",
    "transposed_3d = array_3d.transpose(1, 0, 2)\n",
    "print(\"Transposed 3D array:\\n\", transposed_3d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b697c4-4f57-45b1-b410-895755c6f372",
   "metadata": {},
   "source": [
    "## Matrix properties\n",
    "\n",
    "### Determinant of a matrix\n",
    "\n",
    "The determinant is a scalar value that can be computed from the elements of a square matrix. It provides important properties about the matrix, such as invertibility. A non-zero determinant indicates the matrix is invertible.\n",
    "\n",
    "We also can compute the sign and natural logarithm of the determinant of a matrix with `np.linalg.slogdet`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "506cdcf5-8e13-426b-ac9d-0be2ed2d8af7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Determinant: -2.0000000000000004\n",
      "Sign: -1.0\n",
      "Log-determinant: 0.6931471805599455\n"
     ]
    }
   ],
   "source": [
    "# Calculating the determinant\n",
    "matrix = np.array([[1, 2], [3, 4]])\n",
    "determinant = np.linalg.det(matrix)\n",
    "print(\"Determinant:\", determinant)\n",
    "\n",
    "sign, logdet = np.linalg.slogdet(matrix)\n",
    "print(\"Sign:\", sign)\n",
    "print(\"Log-determinant:\", logdet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e91f777-6ca5-43e4-bcbf-ed495ae41081",
   "metadata": {},
   "source": [
    "### Inverse of a matrix\n",
    "\n",
    "The inverse of a matrix is another matrix such that when multiplied together, they yield the identity matrix. Not all matrices have inverses. Exists only for square matrices with a non-zero determinant. It \"undoes\" the transformation represented by the original matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13cc1261-3c77-42be-aad8-967257e9eb34",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inverse of the matrix:\n",
      " [[-2.   1. ]\n",
      " [ 1.5 -0.5]]\n"
     ]
    }
   ],
   "source": [
    "# Calculating the inverse\n",
    "matrix = np.array([[1, 2], [3, 4]])\n",
    "inverse = np.linalg.inv(matrix)\n",
    "print(\"Inverse of the matrix:\\n\", inverse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aefe6fab-583d-4847-86d3-2f41b5af54bb",
   "metadata": {},
   "source": [
    "### Rank\n",
    "Computes the rank of a matrix, i.e., the number of linearly independent rows or columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec1082e9-3741-4eb1-940c-71c51ee65cbf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix rank: 2\n"
     ]
    }
   ],
   "source": [
    "# Matrix rank\n",
    "matrix = np.array([[1, 2], [3, 4]])\n",
    "rank = np.linalg.matrix_rank(matrix)\n",
    "print(\"Matrix rank:\", rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd4069e-a99e-408a-b48e-235c898c0f30",
   "metadata": {},
   "source": [
    "### Trace\n",
    "Computes the sum of the diagonal elements of a matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1bfc722f-2271-4a4d-ae61-3351be48946e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trace: 5\n"
     ]
    }
   ],
   "source": [
    "# Trace of a matrix\n",
    "matrix = np.array([[1, 2], [3, 4]])\n",
    "trace = np.trace(matrix)\n",
    "print(\"Trace:\", trace)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7d28e2-9aa1-4ccd-9693-c0a64526ca03",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Diagonal elements of a matrix\n",
    "Extracts the diagonal elements of a matrix or a 2D slice of a higher-dimensional array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ffba599-2bd6-49a0-b1af-e39b84ef7ad2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main diagonal: [1 5 9]\n",
      "Upper diagonal: [2 6]\n"
     ]
    }
   ],
   "source": [
    "matrix = np.array([[1, 2, 3],\n",
    "                   [4, 5, 6],\n",
    "                   [7, 8, 9]])\n",
    "\n",
    "# Extracting the main diagonal\n",
    "main_diagonal = np.diagonal(matrix)\n",
    "print(\"Main diagonal:\", main_diagonal)\n",
    "\n",
    "# Extracting the diagonal above the main diagonal\n",
    "upper_diagonal = np.diagonal(matrix, offset=1)\n",
    "print(\"Upper diagonal:\", upper_diagonal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c77064-b1e3-4558-91f3-0d97ab2df088",
   "metadata": {},
   "source": [
    "**Syntax**: \n",
    "```python\n",
    "diagonal_elements = np.diagonal(array, offset=0, axis1=0, axis2=1)\n",
    "```\n",
    "\n",
    "- `offset`: The diagonal offset; `0` is the main diagonal, positive values are above, and negative values are below the main diagonal.\n",
    "- `axis1` and `axis2`: The two axes to consider; by default, it looks at the first two dimensions.\n",
    "\n",
    "### Eigenvalues and eigenvectors\n",
    "\n",
    "Provide information about the behavior of linear transformations. An eigenvector is a direction that remains unchanged, while an eigenvalue is a factor by which it is scaled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "220b38c2-9dd5-4752-a8d9-3a0f7e3b5d2e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eigenvalues: [3. 2.]\n",
      "Eigenvectors:\n",
      " [[0.89442719 0.70710678]\n",
      " [0.4472136  0.70710678]]\n"
     ]
    }
   ],
   "source": [
    "# Calculating eigenvalues and eigenvectors\n",
    "matrix = np.array([[4, -2], [1, 1]])\n",
    "eigenvalues, eigenvectors = np.linalg.eig(matrix)\n",
    "print(\"Eigenvalues:\", eigenvalues)\n",
    "print(\"Eigenvectors:\\n\", eigenvectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c57fea-0978-429c-9a6e-4986866eed77",
   "metadata": {},
   "source": [
    "## Matrix decompositions\n",
    "\n",
    "- ***Singular value decomposition (SVD)*** - SVD is a factorization of a matrix into three matrices, often used in dimensionality reduction and data compression. It decomposes a matrix into three other matrices (`U`, `S`, `Vt`).\n",
    "\n",
    "- ***Cholesky decomposition*** - The Cholesky decomposition factors a positive-definite matrix into a lower triangular matrix and its transpose. It used for solving linear systems and in various optimization problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "43e86c87-294e-48f9-8d57-31624db2f7ee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVD decomposition:\n",
      "U matrix:\n",
      " [[-0.3863177  -0.92236578]\n",
      " [-0.92236578  0.3863177 ]]\n",
      "Singular values: [9.508032   0.77286964]\n",
      "Vt matrix:\n",
      " [[-0.42866713 -0.56630692 -0.7039467 ]\n",
      " [ 0.80596391  0.11238241 -0.58119908]\n",
      " [ 0.40824829 -0.81649658  0.40824829]]\n",
      "\n",
      "Cholesky decomposition:\n",
      "Cholesky factor L:\n",
      " [[2. 0.]\n",
      " [1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# Singular Value Decomposition\n",
    "matrix = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "U, S, Vt = np.linalg.svd(matrix)\n",
    "print(\"SVD decomposition:\")\n",
    "print(\"U matrix:\\n\", U)\n",
    "print(\"Singular values:\", S)\n",
    "print(\"Vt matrix:\\n\", Vt)\n",
    "\n",
    "# Cholesky Decomposition\n",
    "matrix = np.array([[4, 2], [2, 2]])\n",
    "L = np.linalg.cholesky(matrix)\n",
    "print(\"\\nCholesky decomposition:\")\n",
    "print(\"Cholesky factor L:\\n\", L)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac57a40-44f7-4356-ad6d-331562484647",
   "metadata": {},
   "source": [
    "## Tensor operations\n",
    "\n",
    "### Tensor dot product\n",
    "\n",
    "The tensor dot product generalizes the concept of dot products to arrays with more than two dimensions. It computes the sum of the product of elements across specified axes of the tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "85126aa2-1de6-481e-bcb9-13b2d014e97c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor dot product:\n",
      " [[19 22]\n",
      " [43 50]]\n"
     ]
    }
   ],
   "source": [
    "# Tensor dot product\n",
    "a = np.array([[1, 2], [3, 4]])\n",
    "b = np.array([[5, 6], [7, 8]])\n",
    "\n",
    "# Perform tensor dot product over specified axes\n",
    "result = np.tensordot(a, b, axes=([1], [0]))\n",
    "print(\"Tensor dot product:\\n\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381eb81d-1e60-4a9c-92e3-5c5ae3c89f99",
   "metadata": {},
   "source": [
    "- **Syntax**: `result = np.tensordot(a, b, axes=([axis1], [axis2]))`\n",
    "\n",
    "  - `a` and `b` are the input arrays (tensors).\n",
    "  - `axes` specifies the axes over which the sum of products is computed. It is a tuple of two sequences, each containing the axes for each input array."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a926ec8e-46eb-4f76-ac3f-7688920bf9ca",
   "metadata": {},
   "source": [
    "## Solving linear systems\n",
    "\n",
    "In linear algebra, solving a system of linear equations involves finding the values of variables that satisfy all the given equations simultaneously. For instance, given a system of equations in matrix form: \n",
    "$$ Ax = b $$ \n",
    "Where:\n",
    "\n",
    "- A is a matrix of coefficients.\n",
    "- x is the vector of unknowns we want to find.\n",
    "- b is the vector of constants on the right-hand side of the equations.\n",
    "\n",
    "The goal is to find the vector `x`. We can solve systems of linear equations using NumPy's `np.linalg.solve` function.\n",
    "\n",
    "To ensure that the solution is correct, we can substitute the solution back into the original equations and verify if `Ax` equals `b`. This can be done using `np.allclose` to handle floating-point precision issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c90a298e-0cdb-4d85-90e2-c08d981aaa23",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution: [3. 2.]\n",
      "Is the solution correct? True\n"
     ]
    }
   ],
   "source": [
    "# Solving a system of equations\n",
    "A = np.array([[1, 1], [1, -1]])\n",
    "b = np.array([5, 1])\n",
    "\n",
    "solution = np.linalg.solve(A, b)\n",
    "print(\"Solution:\", solution)\n",
    "\n",
    "# Verify the solution\n",
    "is_correct = np.allclose(np.dot(A, solution), b)\n",
    "print(\"Is the solution correct?\", is_correct)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf2e397-3f36-41fd-a97d-70127b7a5671",
   "metadata": {},
   "source": [
    "The matrix `A` contains coefficients, while vector `b` contains constants.\n",
    "\n",
    "- Syntax: `np.linalg.solve(A, b)`\n",
    "- Parameters:\n",
    "    - `A`: A square matrix representing the coefficients of the linear equations. The shape of `A` should be `(n, n)`.\n",
    "    - `b`: A vector or matrix representing the constants on the right side of the equations. The shape of `b` should be `(n,)` for a vector or `(n, m)` for a matrix with multiple right-hand sides.\n",
    "    \n",
    "Here, `np.allclose` checks if the computed values are close enough to the actual values, accounting for numerical precision. If `is_correct` is `True`, it means the solution is accurate.\n",
    "\n",
    "While `np.linalg.solve` is used to find exact solutions to a system of linear equations (when the system is square and has a unique solution), `np.linalg.lstsq` is used to find the least squares solution to a system that may be overdetermined or underdetermined.\n",
    "\n",
    "## Linear regression - Least squares method\n",
    "When dealing with linear systems, sometimes the number of equations does not exactly match the number of unknowns. In such cases, we might not have a perfect solution that satisfies all equations. Instead, we can find the best possible solution that minimizes the discrepancy between the left and right sides of the equations. This is where the least squares method comes in.\n",
    "\n",
    "In matrix form, the problem can be expressed as:\n",
    "$$ A \\cdot x \\approx b $$\n",
    "\n",
    "where:\n",
    "- A is an $(m \\times n)$ matrix (with $(m \\geq n)$ for an overdetermined system, or $(m \\leq n)$ for an underdetermined system).\n",
    "- x is an $(n \\times 1)$ vector of unknowns.\n",
    "- b is an $(m \\times 1)$ vector of constants.\n",
    "\n",
    "The goal is to find \\(x\\) that minimizes the sum of squared residuals:\n",
    "$$\\text{minimize} \\|A \\cdot x - b\\|^2$$\n",
    "\n",
    "In linear regression, we typically have a model of the form:\n",
    "\n",
    "$$ y = A \\cdot \\beta + \\epsilon $$\n",
    "\n",
    "Where:\n",
    "- y is the vector of observed values.\n",
    "- A is the matrix of predictor variables (including a column for the intercept if necessary).\n",
    "- $\\beta$ is the vector of coefficients to be estimated.\n",
    "- $\\epsilon$ is the error term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5c71ad90-0122-4fa3-824e-d1ce19f73667",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Least squares solution: [0.75 1.39]\n",
      "Residuals: [0.027]\n",
      "Rank of matrix: 2\n",
      "Singular values: [7.69121313 0.91936964]\n",
      "Equation of the best fit line: y = 0.7500x + 1.3900\n"
     ]
    }
   ],
   "source": [
    "# Coefficient matrix\n",
    "A = np.array([1, 2, 3, 4, 5])\n",
    "# Prepare matrix A with an intercept term\n",
    "A = np.vstack([A, np.ones(len(A))]).T\n",
    "\n",
    "# Constants vector\n",
    "b = np.array([2.2, 2.8, 3.6, 4.5, 5.1])\n",
    "\n",
    "# Solve for the least squares solution\n",
    "coefficients_linear, residuals, rank, s = np.linalg.lstsq(A, b, rcond=None)\n",
    "\n",
    "# Compute the predicted values\n",
    "best_fit_linear = A @ coefficients_linear\n",
    "\n",
    "equation = f\"y = {coefficients_linear[0]:.4f}x + {coefficients_linear[1]:.4f}\"\n",
    "print(\"Least squares solution:\", coefficients_linear)\n",
    "print(\"Residuals:\", residuals)\n",
    "print(\"Rank of matrix:\", rank)\n",
    "print(\"Singular values:\", s)\n",
    "print(\"Equation of the best fit line:\", equation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2dc081-4511-42dd-834f-bda74a641c8f",
   "metadata": {},
   "source": [
    "**Explanation:**\n",
    "\n",
    "- **Syntax**: `coefficients, residuals, rank, singular_values = np.linalg.lstsq(A, b, rcond=None)`\n",
    "\n",
    "- **Parameters**:\n",
    "  - `A`: The input matrix representing the system of equations. In the context of linear regression, this is typically the design matrix containing the features (and possibly a column of ones for the intercept).\n",
    "  - `b`: The dependent variable vector (e.g., the `y` values you are trying to predict).\n",
    "  - `rcond`: A cutoff for small singular values. It helps determine the effective rank of `A`. Values smaller than this are considered zero. If set to `None`, a default value is used.\n",
    "\n",
    "- **Returns**:\n",
    "  - `coefficients`: The solution array containing the coefficients that minimize the squared differences between the observed values (`b`) and the predicted values (`A @ coefficients`).\n",
    "  - `residuals`: The sum of the squared residuals of the solution. This is only returned if `A` is of full rank and `b` has more rows than columns.\n",
    "  - `rank`: The effective rank of the matrix `A`.\n",
    "  - `singular_values`: The singular values of `A`, which provide information about the stability and condition of the matrix."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
